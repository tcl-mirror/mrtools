// vim:set syntax=asciidoc:

= Runtime Support

[partintro]
.Runtime Support
--
In the previous part of the book,
we described the domain specific language (DSL) that is used to
describe a domain to `micca`.
From that description,
code is generated and the generated code targets the run time
environment that is explained in this part of the book.

When translating an executable model,
parts of the model can be mapped directly onto the implementation language.
For example in a `micca` translation,
class instances are referred to using a ``C'' pointer to the instance
memory.
This allows attribute access by simple indirection on the pointer,
_e.g._ for a state activity, `self->Temp = 27`, can be used to update the
`Temp` attribute of the instance.

Other aspects of mapping model execution to the implementation are not
directly supported in the implementation language.
Consider the execution of a state model.
There is no intrinsic support for state machines in the ``C'' language.
To dispatch events to state machines requires that we write additional
``C'' code to implement the execution rules of Moore state machines.
We will gather that code into ``C'' functions and the functions will require
data that must be structured in a particular way.

This part of the book is primarily concerned with showing the functions
and data structures required to map model execution rules onto the
implementation.
Taken together,
they define the details of how execution happens in a `micca` translated
domain.
We have purposely chosen a simple scheme of execution, namely,
single threaded and event driven with callbacks to handle the domain specific
computations.
This choice enables this translation scheme to be used in small,
embedded, ``bare metal'' computing technology.
We will also produce a flavor of the run time that can execute in a POSIX
environment.
This will allow us to target POSIX,
if that is appropriate to the application,
and also to use POSIX as a simulation environment for testing an embedded
system.
This turns out to be very useful since debugging and other facilities
tend to be much richer in the POSIX world than in the bare metal embedded
world.

Once we know how to interface to the run time code,
we can show the code generation that takes the platform model data and
converts it to ``C'' code.
That is the subject of the next part of the book.
--

== Introduction

To start,
we want to enumerate the characteristics of `micca` run time architecture.

* The implementation language is ``C''.
* All data is held in primary memory and there is no persistent storage.
* All classes and other resources are allocated fixed size memory pools
whose size is known at compile time. There is no use of dynamically allocated
memory or of any generic system heap by the run time code.
* The address in memory of a class instance serves as an architecturally
generated identifier for the instance and we use that identifier exclusively
in the interfaces of the run time code.
* The only support for asynchronous execution is that of an interrupt.
Facilities are provided to allow interrupt service code to synchronize
to the running background.
There is no notion of semaphores, condition variables or any other
mutual exclusion locking scheme other than that required to prevent
interrupts from executing during small critical sections of code.
* Background execution is single threaded.
There is no notion of _task_ or _process_ or _thread_ as those terms are
usually defined for computer operating systems.
There is no notion of processor context, context switching or process
preemption.
All execution is run-to-completion except as preempted by interrupts.
* The execution pattern is event driven with callbacks that run to completion
and perform the required computation.
Given the single threaded nature of sequencing execution,
callbacks that run for longer than the desired response latency time of the
system can be problematic.
This scheme is targeted at applications that are _reactive_ in nature,
sensing external stimulus and responding to that stimulus,
and _not_ long-running computationally intensive transformations.
The execution scheme is very similar to that used for most graphical
user interface applications.
* There is no notion of event priority.
Events are dispatched in the order they are signaled.
There is, however, a notion of thread of control and threads of control
have an implicit relationship with transactions on the domain data.
* Referential integrity is enforced at the end of each data transaction.
This implies that any changes in the stored data for relationships is
verified against the constraints implied by the relationship
conditionality and multiplicity.
* Some of the constructs for the run time depend upon the target processor.
We will show three implementations, namely, the ARM V7-M architecture,
the TI MSP430 architecture and the POSIX architecture.

As we have said before,
this execution scheme is _not_ intended for all applications.
The computational demands of some applications are such that the
single threaded, event driven, callback nature is simply inappropriate
and another execution scheme should be used.
However,
for a large class of applications,
this scheme works very well and has many advantages in terms of simplicity
and the lack of shared state information between concurrent execution
threads.

== The Main Program

In ``C'',
execution begins with the function called, `main`.
`Micca` does _not_ provide this function.
Each system will have to construct a custom `main` function.
The goals of this function are to perform any required initialization
and then to enter the event loop.
Below we show an outline of what a `main` function would do.
The only hard and fast requirements are that `mrt_Initialize` must be called
before any run time facilities are used and `mrt_EventLoop` must
be invoked to cause the system to run.

[source,c]
----
int
main(void)
{
    /*
     * Hardware and other low level system initialization is usually done
     * first.
     */

    /*
     * Initialize the run time code itself.
     */
    mrt_Initialize() ;

    /*
     * Initialize domains, bridges and any other code that might require access
     * to the facilities of the run time code. Typically, each domain in the
     * system would have an "init()" domain operation and these can be invoked
     * here. Sometimes domain interactions are such that a second round of
     * initialization is required.  Bridges between domains may also require
     * that the initialization for a domain be done before the bridge can be
     * initialized.  Since the run time initialization has been done by this
     * point, domains may generate events and do other model level activities.
     * Regardless of how the initialization is accomplished, it is system
     * specific and, unfortunately, only temporally cohesive.
     */

    /*
     * Entering the event loop causes the system to dispatch events.
     */
    mrt_EventLoop() ;
}
----

[source,c]
----
<<mrt external interfaces>>=
extern void mrt_Initialize(void) ;
----

=== Event Loop

To a first approximation,
the run time event loop is an infinite loop.
Most applications will enter the event loop after their initialization
phase and remain there forever.
However,
testing and other considerations mean that we may want to exit the
event loop to gain control of the program.

(((micca,Run Time,mrt_EventLoop)))
[source,c]
----
<<mrt external interfaces>>=
extern void mrt_EventLoop(void) ;

<<mrt external functions>>=
void
mrt_EventLoop(void)
{
    for (mrtExitEventLoop = false ; !mrtExitEventLoop ; ) {
        if (!mrt_ProcessOneEvent()) {
            mrtWait() ;
        }
    }
}
----

As we see,
the flow of control loops,
processing one event at a time as long as it has not been requested to exit the
loop.

Exiting the event loop is controlled by a boolean variable.

(((micca,Run Time,mrtExitEventLoop)))
[source,c]
----
<<mrt static data>>=
static bool mrtExitEventLoop ;
----

Rather than expose the variable directly,
we provide a function to set it.
One use case for this function is in test code where the main
test application will enter the event loop and some state activity
will execute `mrt_SyncToEventLoop()` to return control back to the test
application.
There are other uses.
For example, if the system detects a catastrophic situation,
it may want to exit the event loop and allow the subsequent code to
gracefully bring down the system or force the system to reset.
The exact details are system specific,
but this provides the means to gain control of the run time execution
for exceptional situations.

[source,c]
----
<<mrt external interfaces>>=
extern bool mrt_SyncToEventLoop() ;
----

(((micca,Run Time,mrt_SyncToEventLoop)))
[source,c]
----
<<mrt external functions>>=
bool
mrt_SyncToEventLoop(void)
{
    bool exitControl = mrtExitEventLoop ;
    mrtExitEventLoop = true ;
    return exitControl ;
}
----

=== Process a Single Event

A public interface is also provided to process a single event.

[source,c]
----
<<mrt external interfaces>>=
extern bool mrt_ProcessOneEvent(void) ;
----

This is used by the event loop but can also be invoked on it own.
This is _not_ the recommended mechanism of running a `micca` based
applications, but sometimes it is necessary.
Again,
testing is sometimes best accomplished by letting a test program
control event by event dispatch.
Another use case involves situations where `micca` generated domains
must be integrated with legacy code.
The legacy code will probably have its own execution loop and
we will have to dispatch `micca` events under control of the legacy
execution scheme.
This is not an ideal situation,
but when migrating an older system to a `micca` translated system
a transition period is unavoidable.
We provide the ability to micro-manage the event dispatch with the full
realization that the facility will be abused by some projects.

(((micca,Run Time,mtr_ProcessOneEvent)))
[source,c]
----
<<mrt external functions>>=
bool
mrt_ProcessOneEvent(void)
{
    <<EventLoop: background sync>>

    return mrtDispatchOneEvent() ;
}
----

The return value for `mrt_ProcessOneEvent` indictes if an event
was actually dispatched.
A return value of `false` indicates that there is no additional work
that needs to be done at this time.

We will discuss the internal logic of processing an event later.
For now, we make two points.

. If interrupts have occurred,
we deal with their background synchronization first and completely.
The exact process to synchronize between interrupts and the background
is processor architecture dependent.
. Only one event is dispatched after synchronizing with interrupts.
Because we deal with all the interrupts before dispatching a single event,
interrupt synchronization has an effective higher priority than event dispatch.

We also note that the exact manner in which background synchronization
functions are executed is dependent upon the processor architecture.
We will discuss this later, but for now,
it is only important to remember that all requests for background
synchronization are executed before dispatching at most one event.

== Managing Data

Before we discuss the details of how execution is sequenced,
we will show how data is managed by the run time.
Execution sequencing is directed at class instances and it will be
helpful to understand how instances are stored before we get to
discussing how they are operated upon.

The run time provides functions to support the basic lifetime of
instances.
We need to be able to:

* Create instances synchronously as part of an activity.
* Create instances asynchronously as part of a event dispatch.
* Delete instances synchronously as part of an activity.
* Delete instances asynchronously when the instance enters a terminal state.

=== Instance Data

The structure of the instances of each class is, in general, different.
Each class can have different attributes and relationships and this
is reflected in the ``C'' structure that is used for each class.
However from the point of view of the run time and the operations provided by
the run time,
instances can be treated the same.
The view of a class instance by the run time is shown below.

[source,c]
----
<<mrt interface aggregate types>>=
typedef struct mrtinstance {
    struct mrtclass const *classDesc ;
    AllocStatus alloc ;
    MRT_StateCode currentState ;
    unsigned refCount ;

#       ifndef MRT_NO_NAMES
    char const *name ;
#       endif /* MRT_NO_NAMES */
} MRT_Instance ;
----

`classDesc`::
    A pointer to a class data structure. The class data structure contains
    information that is common to all instances of the class.
`alloc`::
    A value that shows the allocation status of the memory for the instance.
    A value of 0, means the instance memory is not in use and can allocated
    to a new instance.
    A negative value means the memory has been reserved but is not in active
    use.
    A positive value means the memory has been reserved and the instances
    is in active use.
`currentState`::
    For those classes that have a state model,
    the `currentState` member holds a small integer number indicating the
    current state in which the instance resides.
    A value of -1 is used to show that the class does not have a state model.
`refCount`::
    A counter value used to enforce referential integrity.
    At the end of a data transaction,
    this member is used as an accumulator of the number of times the
    instance is referenced in a relationship.
`name`::
    An instance may have a name that it was given during the intial instance
    population.

The `micca` code generator will facilitate this view of an arbitrary instance
by inserting this structure as the first element of the ``C'' structure
that is generated for each class.
In this manner a pointer to an arbitrary class can be cast to a
pointer to a `MRT_Instance` with impunity.

[source,c]
----
<<mrt interface simple types>>=
typedef short int AllocStatus ;
----

A class instance is in reality an element of a ``C'' array.
The size of the array, and consequently the maximum number of instances
of the class, is fixed at compile time.
The `alloc` member of the instance structure is used to keep track of the
status of the array elements as instances are created and deleted at run time.
We will also use this member to track _event in flight_ errors.
We will discuss this more below,
but we need a way to insure that events that have been signaled are not
delivered to instances that have been deleted.

[source,c]
----
<<mrt interface simple types>>=
typedef int8_t MRT_StateCode ;
----

The data type for the `currentState` member is just a small integer.
By specifying 8 bits we limit the number of states of a state model to 127.
That is an enormous number of states for a class state model.
We use negative state numbers to indicate the non-transitioning actions
that may occur when an event is dispatched.

[source,c]
----
<<mrt constants>>=
#define MRT_StateCode_IG    (-1)
#define MRT_StateCode_CH    (-2)
----

=== Class Data

All the behavior of data management and execution sequencing is
completely determined by the values contained in the data structures
supplied to the various functions of the mechanisms.
This is distinct from some software architecture mechanisms that
use _ad hoc_ generated code from a model compiler to implement
some capabilities and being completely data driven and separately
compilable is a design goal of the run time.

Since the behavior of all instances of a given class is the same,
each class has a data structure that contains all the class invariant
information.


[source,c]
----
<<mrt interface aggregate types>>=
typedef struct mrtattribute {
    MRT_AttrOffset offset ;
    MRT_AttrSize size ;

#       ifndef MRT_NO_NAMES
    char const *name ;
#       endif /* MRT_NO_NAMES */
} MRT_Attribute ;
----

`offset`::
    The offset in bytes from the beginning of the instance to the attribute.
`size`::
    The number of bytes in which the attribute is stored.
`name`::
    The name of the attribute.

When generically describing classes,
the subclasses of union based generalizations pose a special situation.
All other class instances are stored in an array.
Union subclasses are stored in the structure of their related
superclass.
The essential information for a union subclass is the class of its
ultimate superclass and the offset from the beginning of the
superclass to where the instance is located.
Note that a union subclass can be subject to repeated generalization
of another union subclass.
The ultimate superclass is the class at the top of the generalization
hierarchy.

[source,c]
----
<<mrt interface aggregate types>>=
typedef struct mrtclass {
    struct mrtinstallocblock *iab ;
    struct mrteventdispatchblock const *edb ;
    struct mrtpolydispatchblock const *pdb ;
    unsigned relCount ;
    struct mrtrelationship const * const *classRels ;
    unsigned attrCount ;
    MRT_Attribute const *classAttrs ;
    unsigned instCount ;
    struct mrtunionsuperclassrole const *containment ;

#       ifndef MRT_NO_NAMES
    char const *name ;
#       endif /* MRT_NO_NAMES */
} MRT_Class ;
----

`iab`::
    A pointer to an instance allocation block.
    The IAB is used to dynamically allocation class instances.
    For classes that are union subclasses,
    this value is set to `NULL`.
`edb`::
    A pointer to an event dispatch block.
    The EDB is used to dispatch events to a state machine.
    For classes that do not have a state model,
    this value is set to `NULL`.
`pdb`::
    A pointer to a polymorphic dispatch block.
    The PDB is used to dispatch polymorphic events.
    For classes that have no polymorphic events,
    this value is set to `NULL`.
`relCount`::
    The number of relationships in which the class participates.
`classRels`::
    A pointer an array of relationship description pointers describing
    the relationships in which the class participates.
    The array has `relCount` elements.
`attrCount`::
    The number of attributes the class contains.
`classAttrs`::
    A pointer an array of descriptions for the attributes the class contains.
    The array has `attrCount` elements.
`instCount`::
    The number of instance of the class.
`containment`::
    For classes that are union subclasses, this member points to a descriptor
    for the immediate superclass in the generalization.
    For other classes the value is `NULL`.
`name`::
    A pointer to a `NUL` terminated string containing the name of the class.

In the next section,
the instance allocation block is described as we continue to define
how data is managed by the run time.
Later, we describe the event dispatch block and polymorphic dispatch
block when we discuss event dispatch.

=== Instance Allocation

There are three ways to create an instance:

. Create an instance as part of an initial instance population.
. Create an instance synchronously to the execution of some activity by invoking
a function.
. Create an instance asynchronously to the execution of some activity by sending
an event.

Creating initial instances is handled during code generation using the
population data specified when the domain is configured.
The code generator arranges for initial instances to be initializers
of the class storage array.
In this section,
we are going to discuss synchronous instance creation.
This is instance creation by a direct function invocation and when
the function returns the instance is ready and available.
Later we will discuss asynchronous instance creation which is instance
creation by signaling an event.

=== Instance Allocation Block

The instances of a class are contained in a single array variable
which serves as the memory pool for the instances.
To support managing a pool of class instances,
an *Instance Allocation Block*, or *IAB* for short,
data structure is used to keep track of the memory pool.
What we need is a data structure that describes the properties of the
class instance memory pool.

[source,c]
----
<<mrt interface aggregate types>>=
typedef void (*InstCtor)(MRT_Instance *) ;
typedef void (*InstDtor)(MRT_Instance *) ;
----

[source,c]
----
<<mrt interface aggregate types>>=
typedef struct mrtinstallocblock {
    void *storageStart ;
    void *storageFinish ;
    void *storageLast ;
    AllocStatus alloc ;
    size_t instanceSize ;
    InstCtor construct ;
    InstDtor destruct ;
    unsigned linkCount ;
    MRT_AttrOffset const *linkOffsets ;
} MRT_iab ;
----

`storageStart`::
    A pointer to the beginning of the memory where the instance storage
    pool is located.
    This is the array allocated to hold the instances of a class.
`storageFinish`::
    A pointer to one element beyond the end of the instance storage pool
    for the class.
    This pointer may not be dereferenced, of course, but provides the
    boundary marker for the end of the pool.
`storageLast`::
    A pointer to the instance that was last allocated. This is used as
    the starting point for allocating the next instance.
`alloc`::
    The next value of the allocation counter to be assigned to a newly
    allocated instance. This member is used to give a unique number
    (modulo the maximum value that can be held in the data type)
    to each allocation of the array element where an instance is stored.
    The number is used to diagnose run time analysis errors.
`instanceSize`::
    The number of bytes of memory occupied by an instance.
`construct`::
    A pointer to a constructor function. If there is no constructor defined
    for the class, then the value of this member may be set to `NULL`.
`destruct`::
    A pointer to a destructor function. If there is no destructor defined
    for the class, then the value of this member may be set to `NULL`.
`linkCount`::
    The number of link pointer containers in the instance.
`linkOffsets`::
    A pointer to an array of offsets to the link pointer containers
    in an instance. The array contains `linkCount` elements.

Instance creation and deletion also supports a very simplified notion of
construction and destruction for the instances.
This is no where near as complicated or full featured as something in C++.
Constructors and destructors take no arguments other than a pointer to the
instance.

Constructors and destructors are primarily useful for when the instance has a
more complicated data structure as an attribute,
as might be the case if the attribute data type is user defined.
If you need to do complicated construction of instances,
the preferred method is to do that with an instance based operation
or as part of a state activity for an asynchronously created instance.

=== Finding Instance Memory

[source,c]
----
<<mrt forward references>>=
static
MRT_Instance *
mrtInstFindSlot(
    MRT_Class const *classDesc) ;
----

`classDesc`::
    A pointer to the class data for which instance memory is to be allocated.

`mrtInstFindSlot` searchs for unused instance memory in the memory pool
associated with the class described by `classDesc`.
Returns a pointer to the allocated memory if successful.
Returns `NULL` if no memory is available.

[float]
==== Implementation

The allocation algorithm is a simple linear search starting at the last
location that was allocated.

[source,c]
----
<<mrt static functions>>=
static MRT_Instance *
mrtInstFindSlot(
    MRT_Class const *classDesc)
{
    assert(classDesc != NULL) ;
    MRT_iab *iab = classDesc->iab ;
    if (iab == NULL) {
        return NULL ;
    }
    assert(iab->storageLast < iab->storageFinish) ;
    /*
     * Search for an empty slot in the pool. Start at the next location after
     * where we last allocated an instance.
     */
    MRT_Instance *inst ;
    for (inst = mrtInstNext(iab, iab->storageLast) ;
            inst->alloc != 0 && inst != iab->storageLast ;
            inst = mrtInstNext(iab, inst)) {
        // Empty
    }
    /*
     * Check if we ended up on a slot that is not allocated.
     */
    if (inst->alloc != 0) { // <1>
        return NULL ;
    }

    return inst ;

}
----
<1> If we wrap all the way around to where we started and still did not
find an instance storage element whose `alloc` member was zero,
the we have run out of space!
That condition is indicated by returning `NULL`.

Finding the next element in the instance storage array involves
performing the pointer arithmetic modulo the size of the array.
Since the pool is allocated in a contiguous block of memory,
we must wrap around the iterator when it passes the end of the
storage pool.
That is accomplished with the `mrtInstNext()` function.

[source,c]
----
<<mrt forward references>>=
static inline void *mrtInstNext(MRT_iab *iab, void *ptr) ;
----

[source,c]
----
<<mrt static functions>>=
static inline 
void *
mrtInstNext(
    MRT_iab *iab,
    void *ptr)
{
    ptr = (void *)((uintptr_t)ptr + iab->instanceSize) ; // <1>
    if (ptr >= iab->storageFinish) { // <2>
        ptr = iab->storageStart ;
    }
    return ptr ;
}
----
<1> Since the size of instance varies from class to class,
we must take over scaling the pointer arithmetic by the size of the
instance.
<2> Perform the modulus wrap around if we cross over the boundary of
the storage array.

=== Creating an Instance

The function, `mrt_CreateInstance`, is used to synchronously
create an instance of a class.

[source,c]
----
<<mrt external interfaces>>=
extern MRT_Instance *
mrt_CreateInstance(
    MRT_Class const *classDesc,
    MRT_StateCode initialState) ;
----

`classDesc`::
    A pointer to the class data for the instance to be created.
`initialState`::
    The state number into which the instance will be placed.
    For classes that do not have an associated state model this argument
    is ignored.
    If this argument is `MRT_StateCode_IG`, then the instance is
    placed in its default initial state.

`mrt_CreateInstance` allocates memory for an instance of the class
described by `classDesc` and places the instance in the state
given by `initialState`.
No state activity is run as part of synchronous instance creation.

[source,c]
----
<<mrt external functions>>=
MRT_Instance *
mrt_CreateInstance(
    MRT_Class const *classDesc,
    MRT_StateCode initialState)
{
    assert(classDesc != NULL) ;

#       ifndef NDEBUG
    if (classDesc->edb) {
        assert(initialState < classDesc->edb->stateCount) ;
    }
#       endif /* NDEBUG */

    /*
     * Search for an empty slot in the pool.
     */
    MRT_Instance *inst = mrtInstFindSlot(classDesc) ;
    if (inst == NULL) {
#           ifndef MRT_NO_NAMES
        mrtFatalError(mrtNoInstSlot, classDesc->name) ;
#           else
        mrtFatalError(mrtNoInstSlot, classDesc) ;
#           endif /* MRT_NO_NAMES */
    }
    MRT_iab *iab = classDesc->iab ;
    /*
     * Record where we left off for the next allocation attempt.
     */
    iab->storageLast = inst ;
    /*
     * Start with a zeroed out memory space.
     */
    memset(inst, 0, iab->instanceSize) ;
    inst->classDesc = classDesc ;
    /*
     * Mark the slot as in use.
     */
    inst->alloc = mrtIncrAllocCounter(iab) ;
    if (classDesc->edb != NULL) {
        inst->currentState = (initialState == MRT_StateCode_IG ||
            initialState >= classDesc->edb->stateCount) ?
                classDesc->edb->initialState : initialState ; // <1>
    } else {
        inst->currentState = MRT_StateCode_IG ; // <2>
    }
    /*
     * Initialize the link pointer containers.
     */
    MRT_AttrOffset const *offsets = iab->linkOffsets ;
    for (unsigned count = iab->linkCount ; count != 0 ; --count, ++offsets) {
        MRT_LinkRef *link = (MRT_LinkRef *)((uintptr_t) inst + *offsets) ;
        mrtLinkRefInit(link) ;
    }
    /*
     * Run the constructor if there is one.
     */
    if (iab->construct) {
        iab->construct(inst) ;
    }
    mrtMarkTransaction(classDesc->classRels, classDesc->relCount) ;

    return inst ;
}
----
<1> We use `MRT_StateCode_IG` as a special value to indicate that
we want the instance created in its default initial state.
We also protect against illegal values of the initial state and treat
them the same.
<2> If a class does not have a state model, then we ignore the
value passed in to the function and set the current state to ignored.
This is a convenient value for such a situation.

One other important point here.
There is a counter in the IAB that is incremented each time an
instance is allocated and this value is used in the `alloc`
member of the instance.
This is another part of the strategy to detect an
_event in flight_ error.
This is described further below.
The effect of running this counter is that every instance gets a
different `alloc` member value (modulo the size of the counter variable)
The increment has one little catch.
The counter is signed and we use the positive and negative values
differently.
Here we want to make sure the value remains positive.


[source,c]
----
<<mrt forward references>>=
static inline AllocStatus mrtIncrAllocCounter(MRT_iab *iab) ;
----

[source,c]
----
<<mrt static functions>>=
static inline 
AllocStatus
mrtIncrAllocCounter(
    MRT_iab *iab)
{
    /*
     * Catch any overflow
     */
    if (++iab->alloc < 0) {
        iab->alloc = 1 ;
    }
    return iab->alloc ;
}
----

=== Deleting an Instance

The function, `mrt_DeleteInstance`, is used to synchronously
destroy an instance.

[source,c]
----
<<mrt external interfaces>>=
extern void
mrt_DeleteInstance(
    MRT_Instance *inst) ;
----

`inst`::
    A pointer to an instance to be destroyed.

Just as there was a distinction between synchronous and asynchronous
instance creation,
there is a similar distinction for destruction.
Asynchronous destruction happens as a result of an instance entering
an _terminal_ state and that is discussed further below.
Here we are dealing with synchronous destruction of an instance.

[source,c]
----
<<mrt external functions>>=
void
mrt_DeleteInstance(
    MRT_Instance *inst)
{
    MRT_iab *iab = inst->classDesc->iab ;
    assert(iab != NULL) ;
    /*
     * Run the destructor, if there is one.
     */
    if (iab->destruct) {
        iab->destruct(inst) ;
    }
    /*
     * Mark the slot as free.
     */
    inst->alloc = 0 ;
    /*
     * Add the class relationships to the transaction.
     */
    mrtMarkTransaction(inst->classDesc->classRels, inst->classDesc->relCount) ;
}
----

Deleting an instance is a simple matter.
If there is a destructor, it is run.
The slot is free when its `alloc` member has a value of 0.
But beware,
for designs that have complicated relationships among the classes,
instance deletion can be very complicated, requiring much care
that the interdependencies among classes are properly preserved.
That work is not done here!
It is the responsibility of the analysis model to take any actions
necessary to preserve data integrity when deleting an instance.

== Managing Referential Integrity

When the target translation platform is based on a Relational Database
Management System (RDMS) or some other data architecture that
supports the relational model of data (_e.g._ `rosea` or TclRAL),
referential integrity checking comes with the underlying data management
facilities.

When targeting staticly typed languages such as ``C'',
translation platforms frequently do not offer any help in insuring
referential integrity of the data as the system runs.
Sometimes this limitation is understandable.
It takes more code and data space to deal with referential integrity.
For applications that do little dynamic instance creation or relationship
changes,
there is little danger of violating the integrity of the data model.

However,
in `micca` we will support detection of referential integrity violations.
As we will see,
there is considerable complexity in achieving this goal.
To be clear,
this is what `micca` supports.

* Integrity constraints implied by the associations and generalizations
supplied in the configuration DSL will be checked at run time.
* Violations of referential integrity will result in a fatal system error.
There is no support for rolling back data values to a known good state.
* Integrity constraints are checked at the end of transactions on the
data model.
The duration of the transaction is not under direct control,
but there is an ongoing
transaction when:
- A thread of control is executing.
- A domain operation is executing.

A thread of control is defined to be the duration of the dispatch
of the set of events initiated by an event signaled from outside of a
state activity or by the delivery of a delayed event.
We discuss the thread of control concept in more detail below
when we deal with managing execution.

Because of our design choice to use the address of a class instance as
an identifier,
to manage referential integrity we must supply:

* Functions to relate and unrelate class instances across the data model
relationships.
* Data structures and values that encode the specifications of the
relationships from the platform model.

In keeping with our goal that the run time be completely data driven,
the code generator will supply the necessary information about all the
associations and generalization in the domain.
This will allow us to manipulate the pointer values used in the relationships
and to check that the result does not violate any of the
multiplicity and conditionality constraints specified for the
relationship.

We will show how this is accomplished by:

. Showing the data structures used to describe relationships.
. Explaining how transactions work and how referential integrity is checked.
. Giving code to relate and unrelate instances in a relationship.

=== Describing Relationships

In this section we present the data structure that is supplied
by the code generator to describe the properties of a relationship.
You can think of this data structure as an implementation version
of the various classes in the platform model that deal with
class relationships.
The code generator takes data from the platform model population that
was created during domain configuration and generates
initialized ``C'' variables of the types described below.

From the <<relationship-subsystem,platform model>>,
we know that there are four different types of relationships.

[source,c]
----
<<mrt interface aggregate types>>=
typedef enum {
    mrtSimpleAssoc,
    mrtClassAssoc,
    mrtRefGeneralization,
    mrtUnionGeneralization
} MRT_RelType ;
----

The combination of the conditionality and multiplicity of a relationship
can be encoded in four values.

[source,c]
----
<<mrt interface aggregate types>>=
typedef enum {
    mrtAtMostOne,
    mrtExactlyOne,
    mrtZeroOrMore,
    mrtOneOrMore
} MRT_Cardinality ;
----

There are also three different ways that pointer references are stored.

[source,c]
----
<<mrt interface aggregate types>>=
typedef enum {
    mrtSingular,
    mrtArray,
    mrtLinkedList
} MRT_RefStorageType ;
----

For singular references,
a single pointer member is allocated in the class structure.

For array reference storage,
the class structure member is a counted array of the type shown below:

[source,c]
----
<<mrt interface aggregate types>>=
typedef struct mrtarrayref {
    unsigned count ;
    MRT_Instance * const *references ;
} MRT_ArrayRef ;
----

For linked list reference storage,
the referring class has a set of link pointers that serve as the
terminus for the linked list.
In addition,
the referenced class has a set of link pointers that enable it to
be linked into the list of instances headed by the referring class.

[source,c]
----
<<mrt interface aggregate types>>=
typedef struct mrtlinkref {
    struct mrtlinkref *next ;
    struct mrtlinkref *prev ;
} MRT_LinkRef ;
----

==== Association Participants

To characterize the role a participant in an association plays,
the following data is needed.

[source,c]
----
<<mrt interface aggregate types>>=
struct mrtassociationrole {
    MRT_Class const *classDesc ;
    MRT_Cardinality cardinality ;
    MRT_RefStorageType storageType ;
    MRT_AttrOffset storageOffset ;
    MRT_AttrOffset linkOffset ;
} ;
----

`classDesc`::
    A pointer to the class data for the participant.
`cardinality`::
    The encoding of the conditionality and multiplicity of the relationship.
    This encoding is from point of view of how many references to the
    participant that are made by the other participant in the relationship.
`storageType`::
    An encoding of the structure of how the reference pointers are stored.
`storageOffset`::
    The offset in bytes from the beginning of an instance to where the
    reference pointers for the relationship are stored.
`linkOffset`::
    For participants whose value of `storageType` is `mrtLinkedList`,
    this member gives the number of bytes from the beginning of the
    target participant instance where the linked list pointers are stored.
    For other values of `storageType` the value is ignored.

==== Simple Associations

Simple associations are made up of a source and target.

[source,c]
----
<<mrt interface aggregate types>>=
struct mrtsimpleassociation {
    struct mrtassociationrole source ;
    struct mrtassociationrole target ;
} ;
----

==== Class Based Associations

For class based association,
there is another role played by the associator class.
Associator classes always have two singular references to the
participant classes.

[source,c]
----
<<mrt interface aggregate types>>=
struct mrtassociatorrole {
    MRT_Class const *classDesc ;
    MRT_AttrOffset forwardOffset ;
    MRT_AttrOffset backwardOffset ;
} ;
----

`classDesc`::
    A pointer to the class data for the participant.
`forwardOffset`::
    The offset in bytes from the begining of an instance of the
    associator class to the forward reference pointer.
    The forward reference pointer refers to a class instance that
    serves as the target of the association.
`backwardOffset`::
    The offset in bytes from the begining of an instance of the
    associator class to the backward reference pointer.
    The backward reference pointer refers to a class instance that
    serves as the source of the association.

A class based association has descriptive information on all three
class roles.

[source,c]
----
<<mrt interface aggregate types>>=
struct mrtclassassociation {
    struct mrtassociationrole source ;
    struct mrtassociationrole target ;
    struct mrtassociatorrole associator ;
} ;
----

==== Reference Generalizations

For generalization relationships implemented as references,
the superclass implements its reference to a subclass using the following
data structure.

[source,c]
----
<<mrt interface aggregate types>>=
typedef struct mrtsuperclassref {
    MRT_SubclassCode subCode ;
    void *subInst ;
} MRT_SuperclassRef ;
----

`subCode`::
    An encoding of the type of the subclass to which the superclass instance
    is related.
    Subclasses are encoded using small, zero-based integers.
    This information allows the superclass instance to determine if
    the traversal of the generalization relationships to a particular
    subclass type yields an instance or is empty.
`subInst`::
    A pointer to the subclass instance that is related to the superclass
    instance.

The information needed to describe the role of the superclass in a
reference generalization is:

[source,c]
----
<<mrt interface aggregate types>>=
struct mrtrefsuperclassrole {
    MRT_Class const *classDesc ;
    MRT_AttrOffset storageOffset ;
} ;
----

`classDesc`::
    A pointer to the class data for the participant.
`storageOffset`::
    The offset in bytes from the beginning of a reference superclass
    instance to where the reference to its related subclass is stored.
    The structure member found at `storageOffset` from the beginning of
    the instance is of type `MRT_SuperclassRef`.

The information needed to describe the role of the subclass in a
reference generalization is:

[source,c]
----
<<mrt interface aggregate types>>=
struct mrtrefsubclassrole {
    MRT_Class const *classDesc ;
    MRT_AttrOffset storageOffset ;
    MRT_SubclassCode subCode ;
} ;
----

`classDesc`::
    A pointer to the class data for the participant.
`storageOffset`::
    The offset in bytes from the beginning of a reference superclass
    instance to where the reference to its related superclass is stored.
    The structure member found at `storageOffset` from the beginning of
    the instance is a pointer to the superclass instance.
`subCode`::
    The numerical encoding of the subclass type.

A reference generalization relationship can be described by its
superclass role information and the set of subclass roles for the
subclasses that participate in the generalization.
We store the subclass role set as a count and pointer to a corresponding
array.

[source,c]
----
<<mrt interface aggregate types>>=
struct mrtrefgeneralization {
    struct mrtrefsuperclassrole superclass ;
    unsigned subclassCount ;
    struct mrtrefsubclassrole const *subclasses ;
} ;
----

==== Union Generalizations

A union generalization results in subclass instances being held as a union in
the superclass instance structure.
This requires slightly different role information.

[source,c]
----
<<mrt interface aggregate types>>=
struct mrtunionsuperclassrole {
    MRT_Class const *classDesc ;
    MRT_AttrOffset subCodeOffset ;
    MRT_AttrOffset subInstOffset ;
} ;
----

`classDesc`::
    A pointer to the class data for the participant.
`subCodeOffset`::
    The offset in bytes from the beginning of a union superclass
    to where the subclass code for the related subclass instance is stored.
    The structure member at this offset is of type, `MRT_SubclassCode`.
`subInstOffset`::
    The offset in bytes from the beginning of a union superclass
    to the subclass instance union.
    The structure member at this offset is the union of
    all the subclass structures that participate in the relationship.

Subclass instances held in union generalizations do not have a
pointer back to their related superclasses.
The related superclass can be determined by pointer arithmetic
(_i.e._ subtracting `subInstOffset` from the subclass instance pointer).
So the role information for a union subclass omits this information.

[source,c]
----
<<mrt interface aggregate types>>=
struct mrtunionsubclassrole {
    MRT_Class const *classDesc ;
    MRT_SubclassCode subCode ;
} ;
----

`classDesc`::
    A pointer to the class data for the participant.
`subCode`::
    The numerical encoding of the subclass type.

Similar to the reference generalization,
the union generalization information consists of that for the
superclass an a set of subclass role information values.

[source,c]
----
<<mrt interface aggregate types>>=
struct mrtuniongeneralization {
    struct mrtunionsuperclassrole superclass ;
    unsigned subclassCount ;
    struct mrtunionsubclassrole const *subclasses ;
} ;
----

==== Relationship Properties

Finally,
the relationship data is held as a discriminated union.
There is a type field and a union of four structures for the
specific information required to describe each type of relationship.

[source,c]
----
<<mrt interface aggregate types>>=
typedef struct mrtrelationship {
    MRT_RelType relType ;
    union {
        struct mrtsimpleassociation simpleAssociation ;
        struct mrtclassassociation classAssociation ;
        struct mrtrefgeneralization refGeneralization ;
        struct mrtuniongeneralization unionGeneralization ;
    } relInfo ;

#       ifndef MRT_NO_NAMES
    char const *name ;
#       endif /* MRT_NO_NAMES */
} MRT_Relationship ;
----

`relType`::
    A value to indicate the type of the relationship.
`relInfo`::
    A union of the various types of relationship information
    giving information that describes the details of the relationship.
    The union must be interpreted according to the value of the `relType`
    member.
`name`::
    The name of the relationship.

=== Data Transactions

To check referential integrity,
it is necessary to introduce the concept of a transaction on the
domain data model.
The transaction concept is necessary because we must be able to defer
the integrity check until such time as the analysis model can insure
that the integrity constraints are met.
For example,
consider two classes in a one-to-one unconditional relationship.
If an instance of one class is created we do not want to check referential
integrity until the code has had an opportunity to create a corresponding
instance of the associated class.

The precise rules of data integrity are that each state activity must
leave the domain data in a consistent state or signal one or more events
that, when dispatched, will ultimately bring the domain data into a
consistent state.
The later phrase of this rule implies that there is a _thread of control_
which determines the boundary of when data consistency is checked.
We will describe how threads of control work later.
For now,
we are concerned data transactions as a means of deciding when
data integrity is to be verified.

Each time a relationship is manipulated, by:

* creating instances that participate in a relationship
* deleting instances that participate in a relationship
* relating instances together
* unrelating instances
* reclassifying subclass instances

the relationship pointer references must be verified.
As described below,
the run time provides functions to perform the relationship pointer
operations.
During a transaction,
we want to save a reference to the relationship information
for each relationship that is manipulated.
We save the affected relationships in the following structure.

[source,c]
----
<<mrt implementation aggregate types>>=
struct mrtTransaction {
    unsigned count ;
    MRT_Relationship const *relationships[MRT_TRANSACTIONSIZE] ;
} ;
----

Like all run time resources,
the memory allocated to them is fixed at compile time.

[source,c]
----
<<mrt constants>>=
#ifndef MRT_TRANSACTIONSIZE
#   define MRT_TRANSACTIONSIZE 64
#endif /* MRT_TRANSACTIONSIZE */
----

We use a static variable to hold the transaction relationships.

[source,c]
----
<<mrt static data>>=
static struct mrtTransaction mrtDataTransaction ;
----

During a transaction,
run time functions that either modify the relationship pointer storage
or change the number of active instances invoke
`mrtMarkTransaction` to save away the relationships that will need to
be checked at the end of the transaction.
This prevents us from have to check every relationships at the end
of every transaction.

The only complication in the marking algorithm is that we wish to
maintain the marked relationship descriptions as a set with no duplicates.
Modifying instances of relationships multiple times during the
transaction does not mean we need to evaluate the referential integrity
more than once.
We wish to save that computation and consequently will search the
marked relationships to eliminate any duplicate mark.

[source,c]
----
<<mrt static functions>>=
static inline
void
mrtMarkTransaction(
    MRT_Relationship const * const *rel,
    unsigned relCount)
{
    for ( ; relCount != 0 ; --relCount, ++rel) {
        MRT_Relationship const **marked = mrtDataTransaction.relationships ;
        for (unsigned markedCount = mrtDataTransaction.count ;
                markedCount != 0 ; --markedCount, ++marked) {
            if (*marked == *rel) {
                continue ;
            }
        }

        if (mrtDataTransaction.count >= COUNTOF(mrtDataTransaction.relationships)) {
            mrtFatalError(mrtTransOverflow) ; // <1>
        }
        mrtDataTransaction.relationships[mrtDataTransaction.count++] = *rel ;
    }
}
----
<1> As usual, exceeding resource limits is a fatal error.

At the end of a transaction,
we iterate across all the relationship descriptions that were
saved during the transaction and check the referential integrity
of the stored pointers.

[source,c]
----
<<mrt static functions>>=
static
void
mrtEndTransaction(void)
{
    MRT_Relationship const **rships = mrtDataTransaction.relationships ;
    for (unsigned count = mrtDataTransaction.count ; count != 0 ;
            --count, ++rships) {
        if (!mrtCheckRelationship(*rships)) {
            mrtFatalError(mrtRefIntegrity) ;
        }
    }
    mrtDataTransaction.count = 0 ;
}
----

==== Verifying Referential Integrity

At the end of a transaction on the data model,
`mrtEndTransaction` iterates across the set of saved relationship
descriptors and check each relationship to make sure the data model
is in a consistent state.
The design approach is to use the `refCount` member of each instance
as a place to store how many times the instance is referred to by
the other participant in the relationship.
Then knowing the cardinality of the relationship we can evaluate
the `refCount` values to determine if referential integrity has been
maintained.

The overall steps are:

. Zero out the `refCount` member of all instances of both participating
classes.
. Using the relationship description information,
find the reference pointers in the class instance that refer to the
other participating class instance and increment the `refCount` member in
the other participating instance if its pointer is found.
This is done for both participants in the relationship.
. Evaluate the `refCount` value against what the cardinality of the
relationship requires.

This algorithm must be generic and capable of operating on any class instance.
This will mean that there will be a lot of pointer arithmetic using
offsets to structure members and other
type unsafe operations happening in the code.
Sometimes ``C'' as a language is accused of being little more than a
high level assembler and it is those type unsafe facilities
that we must employ here to obtain a single body of code that can
operate on an arbitrary class instance.

[source,c]
----
<<mrt forward references>>=
static bool mrtCheckRelationship(MRT_Relationship const *rel) ;
----

The `mrtCheckRelationship` function returns a boolean value indicating
if the relationship described by `rel` has correct referential integrity.

Since there are four types of relationships in terms of how the
reference pointers are stored,
the function considers each type separately.

[source,c]
----
<<mrt static functions>>=
static
bool
mrtCheckRelationship(
    MRT_Relationship const *rel)
{
    bool result = false ;

    switch (rel->relType) {
    case mrtSimpleAssoc: {
        <<mrtCheckRelationship: simple associations>>
    }
        break ;

    case mrtClassAssoc: {
        <<mrtCheckRelationship: class based associations>>
    }
        break ;

    case mrtRefGeneralization: {
        <<mrtCheckRelationship: reference generalizations>>
    }
        break ;

    case mrtUnionGeneralization: {
        <<mrtCheckRelationship: union generalizations>>
    }
        break ;

    /*
     * N.B. no default case. We will just fail the check if
     * this happens.
     */
    }

    return result ;
}
----

For simple associations,
we zero out the `refCount` member in both participants.
The references between the class instances is tracked
and then the values of the `refCount` members are compared against
what the relationship requires.

[source,c]
----
<<mrtCheckRelationship: simple associations>>=
struct mrtsimpleassociation const *assoc = &rel->relInfo.simpleAssociation ;

mrtZeroRefCounts(assoc->source.classDesc->iab) ;
mrtZeroRefCounts(assoc->target.classDesc->iab) ;

mrtCountAssocRefs(&assoc->source, &assoc->target) ;

result =
    mrtCheckRefCounts(assoc->source.classDesc->iab, assoc->source.cardinality) &&
    mrtCheckRefCounts(assoc->target.classDesc->iab, assoc->target.cardinality) ;
----

Class based associations are more complicated.
Recall that class based associations are treated in a decomposed manner
where each side is related to the associator class and the associator
class is unconditionally and singularly related to each participant.
So we will consider each side separately.

[source,c]
----
<<mrtCheckRelationship: class based associations>>=
struct mrtclassassociation const *assoc = &rel->relInfo.classAssociation ;

result = mrtCheckAssociatorRefs(&assoc->associator) ;
if (result) {
    /*
     * On the first side, we evaluate the references from the source class
     * to the associator class.
     */
    mrtZeroRefCounts(assoc->source.classDesc->iab) ;
    mrtZeroRefCounts(assoc->associator.classDesc->iab) ;
    mrtCountClassAssocRefs(&assoc->source, assoc->associator.classDesc->iab,
            assoc->associator.backwardOffset) ;
    result = mrtCheckRefCounts(assoc->source.classDesc->iab,
                assoc->source.cardinality) &&
            mrtCheckRefCounts(assoc->associator.classDesc->iab, mrtExactlyOne) ;

    /*
     * If the first side is okay, then we can evaluate the references from the
     * target class to the associator class.
     */
    if (result) {
        mrtZeroRefCounts(assoc->target.classDesc->iab) ;
        mrtZeroRefCounts(assoc->associator.classDesc->iab) ;
        mrtCountClassAssocRefs(&assoc->target,
                assoc->associator.classDesc->iab,
                assoc->associator.forwardOffset) ;
        result = mrtCheckRefCounts(assoc->target.classDesc->iab,
                assoc->target.cardinality) &&
            mrtCheckRefCounts(assoc->associator.classDesc->iab, mrtExactlyOne) ;
    }
}
----

Since a generalization represents a disjoint union between between the
superclass and the set of subclasses,
each superclass instance must be referenced exactly once from among all
the subclasses of the generalization.
Conversely,
each subclass must reference exactly one superclass instance.
This means we will have to iterate over the subclasses as we zero out
the `refCount` member and count the references.

[source,c]
----
<<mrtCheckRelationship: reference generalizations>>=
struct mrtrefgeneralization const *gen = &rel->relInfo.refGeneralization ;

mrtZeroRefCounts(gen->superclass.classDesc->iab) ;

struct mrtrefsubclassrole const *subclass = gen->subclasses ;
for (unsigned subcount = gen->subclassCount ; subcount != 0 ;
        --subcount, ++subclass) {
    mrtZeroRefCounts(subclass->classDesc->iab) ;
}

mrtCountGenRefs(gen) ;

result = mrtCheckRefCounts(gen->superclass.classDesc->iab, mrtExactlyOne) ;
subclass = gen->subclasses ;
for (unsigned subcount = gen->subclassCount ; subcount != 0 && result ;
        --subcount, ++subclass) {
    result = mrtCheckRefCounts(subclass->classDesc->iab, mrtExactlyOne) ;
}
----

When a generalization is stored in a union,
there are no reference pointers.
However, we can still verify that the subcode field has a valid value.
This check is needed since unrelating a union generalization sets this
field to an invalid value.
We can also check each subclass instance to insure that its `alloc` field
is set correctly.

[source,c]
----
<<mrtCheckRelationship: union generalizations>>=
struct mrtuniongeneralization const *gen = &rel->relInfo.unionGeneralization ;

result = true ;
MRT_iab *super = gen->superclass.classDesc->iab ;
for (MRT_Instance *inst = (MRT_Instance *)super->storageStart ;
        inst < (MRT_Instance *)super->storageFinish ;
        inst = (MRT_Instance *)((uintptr_t)inst + super->instanceSize)) {
    if (inst->alloc > 0) {
        MRT_SubclassCode *subCode = (MRT_SubclassCode *)
                ((uintptr_t)inst + gen->superclass.subCodeOffset) ;
        if (*subCode >= gen->subclassCount) {
            result = false ;
            break ;
        }
        MRT_Instance *subInst = (MRT_Instance *)
                ((uintptr_t)inst + gen->superclass.subInstOffset) ;
        if (subInst->alloc <= 0) {
            result = false ;
            break ;
        }
    }
}
----

The first of the generic operations that must be performed on
class instances is to set the `refCount` member of the instance
structure to zero.

[source,c]
----
<<mrt forward references>>=
static void mrtZeroRefCounts(MRT_iab *iab) ;
----

Since the instance allocation block contains all the information
we need to access the instance storage,
we iterate across the class instance storage setting `refCount` to zero.

[source,c]
----
<<mrt static functions>>=
static
void
mrtZeroRefCounts(
    MRT_iab *iab)
{
    for (MRT_Instance *inst = (MRT_Instance *)iab->storageStart ;
            inst < (MRT_Instance *)iab->storageFinish ;
            inst = (MRT_Instance *)((uintptr_t)inst + iab->instanceSize)) {// <1>
        inst->refCount = 0 ;
    }
}
----
<1> Here, and in many other places below, we must perform the scaled pointer
arithmetic ourselves.

The other operation that depends only upon accessing the `refCount` member
of an instance is to evaluate the value of `refCount` against what
the cardinality of the relationship.
There are four possible values of the cardinality.
One of the values, `mrtZeroOrMore`, implies that any value of
`refCount` is satisfactory since `refCount` is defined as an unsigned
quantity and must, necessarily, be greater than or equal to zero.

For the other three values of cardinality we define functions to
perform the comparison.

[source,c]
----
<<mrt static functions>>=
static
bool
compareAtMostOne(
    unsigned refCount)
{
    return refCount <= 1 ;
}

static
bool
compareExactlyOne(
    unsigned refCount)
{
    return refCount == 1 ;
}

static
bool
compareOneOrMore(
    unsigned refCount)
{
    return refCount >= 1 ;
}
----

The reference counts are checked by iterating over the instances
and invoking the proper cardinality comparison function.
The first failure means we can stop.

[source,c]
----
<<mrt forward references>>=
static bool
mrtCheckRefCounts(MRT_iab *iab, MRT_Cardinality cardinality) ;
----

[source,c]
----
<<mrt static functions>>=
static bool
mrtCheckRefCounts(
    MRT_iab *iab,
    MRT_Cardinality cardinality)
{
    if (cardinality == mrtZeroOrMore) { // <1>
        return true ;
    }

    static bool (*const compareFuncs[])(unsigned) = {
        [mrtAtMostOne] = compareAtMostOne,
        [mrtExactlyOne] = compareExactlyOne,
        [mrtZeroOrMore] = NULL, // <2>
        [mrtOneOrMore] = compareOneOrMore
    } ;

    assert(cardinality <= mrtOneOrMore) ;
    bool (*const compareCardinality)(unsigned) = compareFuncs[cardinality] ; // <3>

    for (MRT_Instance *inst = (MRT_Instance *)iab->storageStart ;
            inst < (MRT_Instance *)iab->storageFinish ;
            inst = (MRT_Instance *)((uintptr_t)inst + iab->instanceSize)) {
        if (inst->alloc > 0 && !compareCardinality(inst->refCount)) {
            return false ; // <4>
        }
    }

    return true ;
}
----
<1> Dispense with the always true case first. There is no reason
to iterate through the instances when the result is always true.
<2> We could omit this and it would be set to zero like any other
uninitialized static variable.
We include it to make clear that that we have accounted for all the cases
and have factored out the `mrtZeroOrMore` case above.
<3> Select the comparison function based on the encoded cardinality.
A small table of pointers to the comparison functions is handy to do this.
<4> We need not go past the first failure.

The singular references made by associator classes are special in the
sense that they should never be `NULL`.
Unrelating class based associations will set those references to `NULL` and
we need to make sure that either the associator instance was reused by
relating to other instances or it was deleted.

[source,c]
----
<<mrt forward references>>=
static bool
mrtCheckAssociatorRefs(struct mrtassociatorrole const *associator) ;
----

[source,c]
----
<<mrt static functions>>=
static bool
mrtCheckAssociatorRefs(
    struct mrtassociatorrole const *associator)
{
    void **ref ;
    MRT_iab const *iab = associator->classDesc->iab ;
    for (MRT_Instance *inst = (MRT_Instance *)iab->storageStart ;
            inst < (MRT_Instance *)iab->storageFinish ;
            inst = (MRT_Instance *)((uintptr_t)inst + iab->instanceSize)) {
        if (inst->alloc > 0) {
            ref = (void **)((uintptr_t)inst + associator->forwardOffset) ;
            if (*ref == NULL) {
                return false ;
            }
            ref = (void **)((uintptr_t)inst + associator->backwardOffset) ;
            if (*ref == NULL) {
                return false ;
            }
        }
    }

    return true ;
}
----

==== Counting References

Of the four types of relationships,
three of them actually contain pointer values that refer to class instances.
The differences in the manner in which the three pointer references are
organized leads us have separate functions for each type.

First we consider counting the references in a simple association.

[source,c]
----
<<mrt forward references>>=
static
void
mrtCountAssocRefs(
    struct mrtassociationrole const *source,
    struct mrtassociationrole const *target) ;
----

The `mrtCountAssocRefs` function counts the number of times each
active instance of `source` refers to active instances of `target` and
_vice versa_.

Counting references mean understanding how the reference pointers are
stored.
There are three ways that reference pointer are stored:
single pointer, counted arrays and linked lists.
For counted arrays,
these are associated with constant populations and they are not intended
to be modified during the running of the program.
So it is always an error to modify the instances or relationships
of constant populations.
This condition is checked first.
Otherwise, we can use the knowledge of offsets in the instance to
where the pointer values are stored to access target instances.

[source,c]
----
<<mrt static functions>>=
static void
mrtCountAssocRefs(
    struct mrtassociationrole const *source,
    struct mrtassociationrole const *target)
{
    if (source->storageType == mrtArray || target->storageType == mrtArray) {
        mrtFatalError(mrtConstRelationship) ;
    }

    MRT_iab *iabSource = source->classDesc->iab ;
    MRT_iab *iabTarget = target->classDesc->iab ;

    switch (source->storageType) {
    case mrtSingular:
        mrtCountSingularRefs(iabSource, source->storageOffset, iabTarget) ;
        break ;

    case mrtLinkedList:
        mrtCountLinkedListRefs(iabSource, source->storageOffset,
                iabTarget, source->linkOffset) ;
        break ;
    }

    switch (target->storageType) {
    case mrtSingular:
        mrtCountSingularRefs(iabTarget, target->storageOffset, iabSource) ;
        break ;

    case mrtLinkedList:
        mrtCountLinkedListRefs(iabTarget, target->storageOffset,
                iabSource, target->linkOffset) ;
        break ;
    }
}
----

We will show how single and linked list references are counted now.
These functions are reused for counting classed based associations.

For singular references, the reference is a pointer to the related
class instance.

[source,c]
----
<<mrt forward references>>=
static
void
mrtCountSingularRefs(
    MRT_iab *source,
    MRT_AttrOffset offset,
    MRT_iab *target) ;
----

`source`::
    A pointer to the instance allocation block for the class instances
    that make a singular reference to target instances.
`offset`::
    The offset in bytes from the beginning of source instances to
    where the pointer to the target instance is located.
`target`::
    A pointer to the instance allocation block for the class instances
    to which the source instances refer.

The `mrtCountSingularRefs` functions iterates across all the active
`source` instances, accesses the pointer in the source instance
and increments the `refCount` member in the referenced target instance.

[source,c]
----
<<mrt static functions>>=
static void
mrtCountSingularRefs(
    MRT_iab *source,
    MRT_AttrOffset offset,
    MRT_iab *target)
{
    for (MRT_Instance *inst = (MRT_Instance *)source->storageStart ;
            inst < (MRT_Instance *)source->storageFinish ;
            inst = (MRT_Instance *)((uintptr_t)inst + source->instanceSize)) {
        if (inst->alloc > 0) { // <1>
            MRT_Instance *targetInst =
                    *(MRT_Instance **)((uintptr_t)inst + offset) ;
            if ((void *)targetInst >= target->storageStart &&
                    (void *)targetInst < target->storageFinish &&
                    targetInst->alloc > 0) { // <2>
                targetInst->refCount += 1 ;
            }
        }
    }
}
----
<1> Only consider active source instances.
<2> Validate that the reference pointer value actually points into
target instance storage. This will eliminate any NULL values also.
Note we also insist that the target instance be active.

The structure of the linked list pointers makes counting them
a bit more complicated.
We must know the offset within the source instance where the link
list terminus is located.
Since linked list point around other links and since the link pointers
in the target are embedded somewhere in the target instance structure,
we need to know the offset into the target instance that the links
point to.

[source,c]
----
<<mrt forward references>>=
static void
mrtCountLinkedListRefs(
    MRT_iab *source,
    MRT_AttrOffset refOffset,
    MRT_iab *target,
    MRT_AttrOffset linkOffset) ;
----

`source`::
    A pointer to the instance allocation block for the class instances
    that make a linked reference to target instances.
`refOffset`::
    The offset in bytes from the beginning of source instances to
    where the linked list terminus is located.
`target`::
    A pointer to the instance allocation block for the class instances
    to which the source instances refer.
`linkOffset`::
    The offset in bytes from the beginning of target instances to where
    the linked list pointers are located.

The `mrtCountLinkedListRefs` function iterates through the linked list
contained in the source instances to reference the target instances.
When a target instance is found, it's `refCount` member is incremented.

[source,c]
----
<<mrt static functions>>=
static void
mrtCountLinkedListRefs(
    MRT_iab *source,
    MRT_AttrOffset refOffset,
    MRT_iab *target,
    MRT_AttrOffset linkOffset)
{
    for (MRT_Instance *inst = (MRT_Instance *)source->storageStart ;
            inst < (MRT_Instance *)source->storageFinish ;
            inst = (MRT_Instance *)((uintptr_t)inst + source->instanceSize)) {
        if (inst->alloc > 0) {
            MRT_LinkRef *ref = (MRT_LinkRef *)((uintptr_t)inst + refOffset) ;
            if (ref->next != NULL) { // <1>
                for (MRT_LinkRef *iter = mrtLinkRefBegin(iter) ;
                        iter != mrtLinkRefEnd(iter) ; iter = iter->next) {
                    MRT_Instance *targetInst =
                        (MRT_Instance *)((uintptr_t)iter - linkOffset) ; // <2>
                    if ((void *)targetInst >= target->storageStart &&
                            (void *)targetInst < target->storageFinish &&
                            targetInst->alloc > 0) {
                        targetInst->refCount += 1 ;
                    }
                }
            }
        }
    }
}
----
<1> Guard against uninitialized link pointers.
<2> The link pointers that form the linked list of target instances are
located `linkOffset` from the beginning of the target instance.
So we need to do some pointer arithmetic to get the pointer to the beginning
of the instance.
It may be the case that the target is on several linked lists depending upon
the relationships in which it participates.

Counting class based associations uses the basic counting primatives that
we have already seen.

[source,c]
----
<<mrt forward references>>=
static void
mrtCountClassAssocRefs(
    struct mrtassociationrole const *participant,
    MRT_iab *iabAssociator,
    MRT_AttrOffset assocOffset) ;
----

To count class based associations,
we have to count the references from each participant to the associator
class.
References from the participant to the associator class can be singular
or linked.
References from the associator class back to the participant are always
singular.

[source,c]
----
<<mrt static functions>>=
static void
mrtCountClassAssocRefs(
    struct mrtassociationrole const *participant,
    MRT_iab *iabAssociator,
    MRT_AttrOffset assocOffset)
{
    if (participant->storageType == mrtArray) {
        mrtFatalError(mrtConstRelationship) ;
    }

    MRT_iab *iabPart = participant->classDesc->iab ;

    switch (participant->storageType) {
    case mrtSingular:
        mrtCountSingularRefs(iabPart, participant->storageOffset, iabAssociator) ;
        break ;

    case mrtLinkedList:
        mrtCountLinkedListRefs(iabPart, participant->storageOffset,
                iabAssociator, participant->linkOffset) ;
        break ;
    }
    mrtCountSingularRefs(iabAssociator, assocOffset, iabPart) ;
}
----

In a reference type generalization,
all of the references are always singular.
There are two differences.
First, we must verify the subclass code contained in the superclass.
This code would have been set to an invalid number when a superclass
was unrelated.
Also, we must iterate across all the subclasses
of the generalization in order to count the references that the subclasses
make back to the superclass.

[source,c]
----
<<mrt forward references>>=
static void
mrtCountGenRefs(
    struct mrtrefgeneralization const *gen) ;
----

[source,c]
----
<<mrt static functions>>=
static void
mrtCountGenRefs(
    struct mrtrefgeneralization const *gen)
{
    MRT_iab *super = gen->superclass.classDesc->iab ;
    for (MRT_Instance *inst = (MRT_Instance *)super->storageStart ;
            inst < (MRT_Instance *)super->storageFinish ;
            inst = (MRT_Instance *)((uintptr_t)inst + super->instanceSize)) {
        if (inst->alloc > 0) {
            MRT_SuperclassRef *superRef = (MRT_SuperclassRef *)
                    ((uintptr_t)inst + gen->superclass.storageOffset) ;
            if (superRef->subCode < gen->subclassCount) {
                MRT_iab *sub = gen->subclasses[superRef->subCode].classDesc->iab ;
                MRT_Instance *subInst = (MRT_Instance *)superRef->subInst ;
                if ((void *)subInst >= sub->storageStart &&
                        (void *)subInst < sub->storageFinish &&
                        subInst->alloc > 0) {
                    subInst->refCount += 1 ;
                }
            }
        }
    }

    struct mrtrefsubclassrole const *subclass = gen->subclasses ;
    for (unsigned subcount = gen->subclassCount ; subcount != 0 ;
            --subcount, ++subclass) {
        mrtCountSingularRefs(subclass->classDesc->iab, subclass->storageOffset,
                gen->superclass.classDesc->iab) ;
    }
}
----

=== Relating Instances

Since the relationship descriptions have sufficient information
to manage referential integrity,
they also can be used to do the pointer manipulations required with
class instances are related and unrelated to each other.
It is important to perform the relate and unrelate operations properly
so as to preserve the referential integrity.

Because we are using pointer values to manage instance identity and
references footnote:[as opposed to attribute values if we were doing this
using relational concepts],
we need to be clear what operations must be performed for classes
that participate in relationships.

For associations:

* Newly created instances must be related across their participating
association if the association is unconditional on the new instance side.
* When changing to which instances a given instance is related,
it is necessary to unrelate the instance and then relate it back to another
instance.
* Before deleting an instance, it should be unrelated from any associations
in which it participates.
* When relating a class based association, either an existing associator
class instance or a newly created associator class instance is required
to relate the two participating instances.
If an existing associator instance is reused, it must have be unrelated
before reuse.
* When unrelating a class based association,
the instance of the associator class must either be reused in making a
new association or deleted.

For generalizations:

* Newly created superclasses and subclasses must be related to each other.
* Reclassifying a subclass instance to a new type can be accomplished via
the supplied function.
* When deleting superclass and subclass instances, unrelating the
instances is not strictly necessary.
* For a union generalization, subclass instance may not be created directly.
It is sufficient to create the superclass instance and then migrate the
subclass to the desired type.

=== Relating Instances

The `micca` run time provides a function to relation two class instances
across a relationship.
The class instance references must be given in the correct order for the roles
played by the participating classes.
A third instance argument is only used for class based associations.

[source,c]
----
<<mrt external interfaces>>=
extern void *
mrt_Relate(
    MRT_Relationship const *rel,
    void *source,
    void *target,
    ...) ;
----

`rel`::
    A pointer to a relationship description for the relationship
    across which the relate operation is to happen.
`source`::
    A pointer to a class instance that serves the source role in the
    relationship.
`target`::
    A pointer to a class instance that serves the target role in the
    relationship.
`?associator?`::
    For simple associations and generalizations this argument may be omitted
    and, if supplied, it is ignored.
    For class based association, it is the instance reference to
    the associator class.
    In this case, if the argument is `NULL`, then a new instance of the
    associator class is created and the instance reference of the
    newly created associator instance is returned.

The return value of `mrt_Relate` is NULL except in the case of a
class based association and the `associator` argument was `NULL`.
In that case the return value is an instance reference to the newly
created association class instance.

==== Implementation

The implementation simply splits out the four cases correponding to the
four types of relationships.

[source,c]
----
<<mrt external functions>>=
void *
mrt_Relate(
    MRT_Relationship const *rel,
    void *source,
    void *target,
    ...)
{
    assert(source != NULL) ;
    assert(target != NULL) ;

    va_list ap ;
    unsigned subcount ;
    void *associator = NULL ;

    switch (rel->relType) {
    case mrtSimpleAssoc: {
        <<mrt_Relate: link simple association>>
    }
        break ;

    case mrtClassAssoc: {
        <<mrt_Relate: link class based association>>
    }
        break ;

    case mrtRefGeneralization: {
        <<mrt_Relate: link reference generalization>>
    }
        break ;

    case mrtUnionGeneralization: {
        <<mrt_Relate: link union generalization>>
    }
        break ;

    default:
        break ;
    }

    mrtMarkTransaction(&rel, 1) ;

    return associator ;
}
----

For simple association,
we need only check that the classes of the instances correpond to the
classes of the association participants.
Then we link the two instances together.

[source,c]
----
<<mrt_Relate: link simple association>>=
struct mrtsimpleassociation const *assoc = &rel->relInfo.simpleAssociation ;

if (assoc->source.classDesc != ((MRT_Instance *)source)->classDesc ||
        assoc->target.classDesc != ((MRT_Instance *)target)->classDesc) {
    mrtFatalError(mrtRelationshipLinkage) ;
}

mrtLink(&assoc->source, source, target) ;
mrtLink(&assoc->target, target, source) ;
----

Since the core of what is going on here is linking the two instances,
let's look at what `mrtLink` does.
We will use this function several more times later on.

Like most of the access to relationship pointers we have already seen,
`mrtLink` does some unsafer pointer arithmetic to find the location in the
instance where references are stored.
Then, depending upon the type of reference storage,
stores the instance pointers.

[source,c]
----
<<mrt static functions>>=
static
void
mrtLink(
    struct mrtassociationrole const *sourceRole,
    void *source,
    void *target)
{
    switch (sourceRole->storageType) {
    case mrtSingular: {
        void **ref = (void **)
                ((uintptr_t)source + sourceRole->storageOffset) ; // <1>
        *ref = target ;
    }
        break ;

    case mrtArray:
        // can't link array types
        mrtFatalError(mrtConstRelationship) ;
        break ;

    case mrtLinkedList: { // <2>
        MRT_LinkRef *sourceRef = (MRT_LinkRef *)
                ((uintptr_t)source + sourceRole->storageOffset) ;
        MRT_LinkRef *targetRef = (MRT_LinkRef *)
                ((uintptr_t)target + sourceRole->linkOffset) ;
        mrtLinkRefInsert(targetRef, sourceRef) ;
    }
        break ;

    default:
        break ;
    }
}
----
<1> For a singular pointer, the `storageOffset` is to a simple pointer
location.
<2> For linked reference storage,
we have to compute the location in the source of the link terminus
(`storageOffset`) and
the location in the target of where the linked list pointers are stored
(`linkOffset`).
The latter is necessary since a given instance may reside on many different
linked lists associated with different associations.

Linking class based associations must account for the associator class.
The class based association is treated as being decomposed into
two association, one each between the participants and the associator
class.
For a class based association,
each instance of the associator class represents an instance of the
association itself.
So we support creating the associator class instance if requested.

[source,c]
----
<<mrt_Relate: link class based association>>=
struct mrtclassassociation const *assoc = &rel->relInfo.classAssociation ;

if (assoc->source.classDesc != ((MRT_Instance *)source)->classDesc ||
        assoc->target.classDesc != ((MRT_Instance *)target)->classDesc) {
    mrtFatalError(mrtRelationshipLinkage) ;
}

va_start(ap, target) ;
associator = va_arg(ap, void *) ;
va_end(ap) ;

if (associator == NULL) { // <1>
    associator = (void *)mrt_CreateInstance(assoc->associator.classDesc,
            MRT_StateCode_IG) ;
} else if (assoc->associator.classDesc !=
        ((MRT_Instance *)associator)->classDesc) {
    mrtFatalError(mrtRelationshipLinkage) ;
}

mrtLink(&assoc->source, source, associator) ;
void **fref = (void **)
        ((uintptr_t)associator + assoc->associator.forwardOffset) ; // <2>
*fref = target ;

mrtLink(&assoc->target, target, associator) ;
void **bref = (void **)
        ((uintptr_t)associator + assoc->associator.backwardOffset) ;
*bref = source ;
----
<1> A `NULL` associator instance requests one to be created as part of the
relate operation.
Otherwise, we insist that the class of a supplied association instance be
correct.
<2> The path from the source instance to the associator class is considered
the _forward_ direction of the relationship traversal.
The link from the associator class to the participating instance is always
singular and unconditional.

When relating reference generalizations,
the reference from the subclass to the superclass is singular and
unconditional.
The reference from the superclass to the subclass is singular but also
includes an encoding of the type of the subclass.
The reference is unconditional when all the subclasses are considered.

First we have to find the subclass type of the subclass instance
(for generalizations, the subclass plays the _source_ role).

[source,c]
----
<<mrt_Relate: link reference generalization>>=
struct mrtrefgeneralization const *gen = &rel->relInfo.refGeneralization ;

struct mrtrefsubclassrole const *subclassRole =
    mrtFindRefGenSubclassRole(((MRT_Instance *)source)->classDesc,
            gen->subclasses, gen->subclassCount) ;

if (subclassRole == NULL) {
    mrtFatalError(mrtRelationshipLinkage) ;
}

if (gen->superclass.classDesc != ((MRT_Instance *)target)->classDesc) {
    mrtFatalError(mrtRelationshipLinkage) ;
}

void **subref = (void **)((uintptr_t)source + subclassRole->storageOffset) ;
*subref = target ;

MRT_SuperclassRef *superref = (MRT_SuperclassRef *)
        ((uintptr_t)target + gen->superclass.storageOffset) ;
superref->subCode = subclassRole->subCode ;
superref->subInst = source ;
----

Finding the participating subclass of the generalization is a linear search
of the subclass roles in the relationship description.

[source,c]
----
<<mrt static functions>>=
struct mrtrefsubclassrole const *
mrtFindRefGenSubclassRole(
    MRT_Class const *subclassClass,
    struct mrtrefsubclassrole const *subclasses,
    unsigned count)
{
    for ( ; count != 0 ; --count, ++subclasses) {
        if (subclassClass == subclasses->classDesc) {
            return subclasses ;
        }
    }

    return NULL ;
}
----

For generalizations stored in a union,
there are no reference pointers but we must update the
subclass encoding to reflect the newly related subclass type.

[source,c]
----
<<mrt_Relate: link union generalization>>=
struct mrtuniongeneralization const *gen = &rel->relInfo.unionGeneralization ;

struct mrtunionsubclassrole const *subclassRole =
    mrtFindUnionGenSubclassRole(((MRT_Instance *)source)->classDesc,
            gen->subclasses, gen->subclassCount) ;

if (subclassRole == NULL) {
    mrtFatalError(mrtRelationshipLinkage) ;
}

if (gen->superclass.classDesc != ((MRT_Instance *)target)->classDesc) {
    mrtFatalError(mrtRelationshipLinkage) ;
}

MRT_SubclassCode *supercode = (MRT_SubclassCode *)
        ((uintptr_t)target + gen->superclass.subCodeOffset) ;
*supercode = subclassRole->subCode ;
----

Similar to reference generalizations,
we also need to search union generalization subclasses for a role match.

[source,c]
----
<<mrt static functions>>=
struct mrtunionsubclassrole const *
mrtFindUnionGenSubclassRole(
    MRT_Class const *subclassClass,
    struct mrtunionsubclassrole const *subclasses,
    unsigned count)
{
    for ( ; count != 0 ; --count, ++subclasses) {
        if (subclassClass == subclasses->classDesc) {
            return subclasses ;
        }
    }

    return NULL ;
}
----

=== Unrelating Instances

The inverse of relating instances is to unrelate them.

[source,c]
----
<<mrt external interfaces>>=
extern void
mrt_Unrelate(
    MRT_Relationship const *rel,
    void *source,
    void *target,
    ...) ;
----

`rel`::
    A pointer to a relationship description for the relationship
    across which the relate operation is to happen.
`source`::
    A pointer to a class instance that serves the source role in the
    relationship.
`target`::
    A pointer to a class instance that serves the target role in the
    relationship.
`?associator?`::
    For simple associations and generalizations this argument may be omitted
    and, if supplied, it is ignored.
    For class based association,
    it must be supplied and is the instance reference to the associator class.

[source,c]
----
<<mrt external functions>>=
void
mrt_Unrelate(
    MRT_Relationship const *rel,
    void *source,
    void *target,
    ...)
{
    assert(source != NULL) ;
    assert(target != NULL) ;

    va_list ap ;
    unsigned subcount ;

    switch (rel->relType) {
    case mrtSimpleAssoc: {
        <<mrt_Unrelate: unlink simple association>>
    }
        break ;

    case mrtClassAssoc: {
        <<mrt_Unrelate: unlink class based association>>
    }
        break ;

    case mrtRefGeneralization: {
        <<mrt_Unrelate: unlink reference generalization>>
    }
        break ;

    case mrtUnionGeneralization: {
        <<mrt_Unrelate: unlink union generalization>>
    }
        break ;

    default:
        break ;
    }

    mrtMarkTransaction(&rel, 1) ;
}
----

To unrelate simple associations we must verify that the classes of the
instance actually participate in the association and the
perform the pointer operations to unlink the instances.

[source,c]
----
<<mrt_Unrelate: unlink simple association>>=
struct mrtsimpleassociation const *assoc = &rel->relInfo.simpleAssociation ;

if (assoc->source.classDesc != ((MRT_Instance *)source)->classDesc ||
        assoc->target.classDesc != ((MRT_Instance *)target)->classDesc) {
    mrtFatalError(mrtRelationshipLinkage) ;
}

mrtUnlink(&assoc->source, source, target) ;
mrtUnlink(&assoc->target, target, source) ;
----

The pointer operation for unlinking mirror those for linking.
For singular associations, we need only find the pointer member in the
instance structure.
For linked associations,
we must unlink the target from the list.

[source,c]
----
<<mrt static functions>>=
static
void
mrtUnlink(
    struct mrtassociationrole const *sourceRole,
    void *source,
    void *target)
{
    switch (sourceRole->storageType) {
    case mrtSingular: {
        void **ref = (void **)((uintptr_t)source + sourceRole->storageOffset) ;
        *ref = NULL ; // <1>
    }
        break ;

    case mrtArray:
        // can't unlink array types
        mrtFatalError(mrtConstRelationship) ;
        break ;

    case mrtLinkedList: {
        MRT_LinkRef *targetRef = (MRT_LinkRef *)
                ((uintptr_t)target + sourceRole->linkOffset) ;
        mrtLinkRefRemove(targetRef) ;
    }
        break ;

    default:
        break ;
    }
}
----
<1> Note that we set the pointer to `NULL` when it is unlinked.
This is essential for the referential integrity checks.
A `NULL` reference pointer means this instance does not add anything to
the reference counts.

For class based associations,
we deal with the association in two steps, between each participant and
the associator class.

[source,c]
----
<<mrt_Unrelate: unlink class based association>>=
struct mrtclassassociation const *assoc = &rel->relInfo.classAssociation ;

va_start(ap, target) ;
void *associator = va_arg(ap, void *) ;
assert(associator != NULL) ;
va_end(ap) ;

if (!(assoc->source.classDesc == ((MRT_Instance *)source)->classDesc &&
        assoc->target.classDesc == ((MRT_Instance *)target)->classDesc &&
        assoc->associator.classDesc == ((MRT_Instance *)associator)->classDesc)) {
    mrtFatalError(mrtRelationshipLinkage) ;
}

mrtUnlink(&assoc->source, source, associator) ;
void **fref = (void **)((uintptr_t)associator + assoc->associator.forwardOffset) ;
*fref = NULL ;

mrtUnlink(&assoc->target, target, associator) ;
void **bref = (void **)((uintptr_t)associator + assoc->associator.backwardOffset) ;
*bref = NULL ;
----

[source,c]
----
<<mrt_Unrelate: unlink reference generalization>>=
struct mrtrefgeneralization const *gen = &rel->relInfo.refGeneralization ;

struct mrtrefsubclassrole const *subclassRole =
    mrtFindRefGenSubclassRole(((MRT_Instance *)source)->classDesc,
            gen->subclasses, gen->subclassCount) ;

if (subclassRole == NULL) {
    mrtFatalError(mrtRelationshipLinkage) ;
}

if (gen->superclass.classDesc != ((MRT_Instance *)target)->classDesc) {
    mrtFatalError(mrtRelationshipLinkage) ;
}

MRT_SuperclassRef *superref = (MRT_SuperclassRef *)
        ((uintptr_t)target + gen->superclass.storageOffset) ;
superref->subCode = gen->subclassCount ;
superref->subInst = NULL ;

MRT_Instance **subref = (MRT_Instance **)
        ((uintptr_t)source + subclassRole->storageOffset) ;
*subref = NULL ;
----

[source,c]
----
<<mrt_Unrelate: unlink union generalization>>=
struct mrtuniongeneralization const *gen = &rel->relInfo.unionGeneralization ;

struct mrtunionsubclassrole const *subclassRole =
    mrtFindUnionGenSubclassRole(((MRT_Instance *)source)->classDesc,
            gen->subclasses, gen->subclassCount) ;

if (subclassRole == NULL) {
    mrtFatalError(mrtRelationshipLinkage) ;
}

if (gen->superclass.classDesc != ((MRT_Instance *)target)->classDesc) {
    mrtFatalError(mrtRelationshipLinkage) ;
}

MRT_SubclassCode *supercode = (MRT_SubclassCode *)
        ((uintptr_t)target + gen->superclass.subCodeOffset) ;
*supercode = gen->subclassCount ;
----

=== Reclassifying Subclasses

[source,c]
----
<<mrt external interfaces>>=
extern void *
mrt_Reclassify(
    MRT_Relationship const *rel,
    void *super,
    MRT_Class const *newSubclass) ;
----

[source,c]
----
<<mrt external functions>>=
void *
mrt_Reclassify(
    MRT_Relationship const *rel,
    void *super,
    MRT_Class const *newSubclass)
{
    if (rel->relType == mrtSimpleAssoc || rel->relType == mrtClassAssoc) {
        return NULL ;
    }

    mrtMarkTransaction(&rel, 1) ;

    unsigned subcount ;

    if (rel->relType == mrtRefGeneralization) {
        <<mrt_Reclassify: reclassify reference generalization>>
    } else if (rel->relType == mrtUnionGeneralization) {
        <<mrt_Reclassify: reclassify union generalization>>
    } else {
        mrtFatalError(mrtRelationshipLinkage) ;
    }

    return NULL ;
}
----

[source,c]
----
<<mrt_Reclassify: reclassify reference generalization>>=
struct mrtrefgeneralization const *gen = &rel->relInfo.refGeneralization ;

struct mrtrefsubclassrole const *subclassRole =
    mrtFindRefGenSubclassRole(newSubclass, gen->subclasses, gen->subclassCount) ;

if (subclassRole == NULL) {
    mrtFatalError(mrtRelationshipLinkage) ;
}

if (gen->superclass.classDesc != ((MRT_Instance *)super)->classDesc) {
    mrtFatalError(mrtRelationshipLinkage) ;
}

MRT_SuperclassRef *superref = (MRT_SuperclassRef *)
        ((uintptr_t)super + gen->superclass.storageOffset) ;
mrt_DeleteInstance(superref->subInst) ;
superref->subInst = mrt_CreateInstance(newSubclass, MRT_StateCode_IG) ;
superref->subCode = subclassRole->subCode ;

MRT_Instance **subref = (MRT_Instance **)
        ((uintptr_t)superref->subInst + subclassRole->storageOffset) ;
*subref = super ;
----

[source,c]
----
<<mrt_Reclassify: reclassify union generalization>>=
struct mrtuniongeneralization const *gen = &rel->relInfo.unionGeneralization ;

struct mrtunionsubclassrole const *subclassRole =
    mrtFindUnionGenSubclassRole(newSubclass, gen->subclasses, gen->subclassCount) ;

if (subclassRole == NULL) {
    mrtFatalError(mrtRelationshipLinkage) ;
}

if (gen->superclass.classDesc != ((MRT_Instance *)super)->classDesc) {
    mrtFatalError(mrtRelationshipLinkage) ;
}

MRT_SubclassCode *supercode = (MRT_SubclassCode *)
        ((uintptr_t)super + gen->superclass.subCodeOffset) ;
*supercode = subclassRole->subCode ;
MRT_Instance *subInst = (MRT_Instance *)
        ((uintptr_t)super + gen->superclass.subInstOffset) ;
subInst->classDesc = newSubclass ;
subInst->alloc = mrtIncrAllocCounter(newSubclass->iab) ;
subInst->currentState = newSubclass->edb ?
        newSubclass->edb->initialState : MRT_StateCode_IG ;
subInst->refCount = 0 ;
----

=== Linked List Operations

[source,c]
----
<<mrt interface static inlines>>=
static inline
MRT_LinkRef *
mrtLinkRefBegin(
    MRT_LinkRef *iter)
{
    return iter->next ;
}
static inline
MRT_LinkRef *
mrtLinkRefEnd(
    MRT_LinkRef *iter)
{
    return iter ;
}
static inline
void
mrtLinkRefInit(
    MRT_LinkRef *ref)
{
    ref->next = ref->prev = mrtLinkRefEnd(ref) ;
}
static inline
bool
mrtLinkRefEmpty(
    MRT_LinkRef *iter)
{
    return iter->next == iter ;
}
static inline
bool
mrtLinkRefNotEmpty(
    MRT_LinkRef *iter)
{
    return iter->next != iter ;
}
static inline
void
mrtLinkRefInsert(
    MRT_LinkRef *item,
    MRT_LinkRef *at)
{
    item->prev = at->prev ;
    item->next = at ;
    at->prev->next = item ;
    at->prev = item ;
}
static inline
void
mrtLinkRefRemove(
    MRT_LinkRef *item)
{
    item->prev->next = item->next ;
    item->next->prev = item->prev ;
    item->next = item->prev = NULL ;
}
----

== Managing Execution

In this section we discuss the rules and policies associated
with managing the sequencing of execution.
There are two means available to an application to control the
sequencing of execution.

* Invoke an ordinary function.
* Generate an event to the instance of a class.

Not much needs to be said about invoking functions.
Control is transferred to the entry point and runs until the function
is complete, transferring control back to next statement of the caller.
Typically, such functions are organized into those that are associated
with the domain as whole, a particular class or instances of a class.
Such organization may be helpful to the programmer,
but since they are directly supported by the implementation language,
the `micca` run time does not get involved in mediating them.

Where the run time does get involved is for those computation that must leave
off at some point,
waiting for some other action in the system or the external environment,
and then resume execution maintaining the past history.
This type of execution is implemented as a state machine.

=== State Machine Rules

Each class that has lifecycle behavior may have a state model associated
with it and each instance of that class will have a state variable.
The run time supports a Moore type state model.

In the Moore formulation of state models,
action code is associated with states and is executed
upon entry into a state.
This is distinguished from the Mealy formulation where
actions are associated with the transitions and are executed
upon exiting a state.
Much writing and discussion has been wasted attempting to
justify one type of state model over another.
What we know is they are computationally equivalent,
_i.e._ we can prove that there is no problem that you can solve
with a Moore machine that cannot also be solved with a Mealy
machine and _vice versa_.
Whether your application is easier to describe with one type rather
than the other is something that you alone may decide.
Moore machines are the traditional formulation for Executable UML
and they have the simplest implementation structures.
What we specifically reject here is any use of hierarchical state
models.
They are unnecessary and add complication that is not welcome.
The power of computation in Executable UML is derived from the
interaction of simple state machines each of which is tied to the
lifecycle of a particular class.
If you have some state model that is large and complicated where
you think some other kind of higher order structure is needed,
the usual reason is that you have multiple classes masquerading as one
and further refinement of your analysis is necessary.
That is not usually a welcome answer to the problem,
because if the analyst had been able to conceive of a better solution,
he/she would probably already have done so.

Generally, state actions affect other computations in the domain
by updating instance attribute values or by generating events to
other instances.
The important distinction here is that the application code of the
state actions does not deal with actually dispatching the events
nor does it control which event is dispatched next.

=== Event Types

There are three types of events:

. Transition events that cause transitions in state machines.
. Polymorphic events that are mapped at runtime across a generalization
hierarchy.
. Creations events that support asynchronous instance creation.

Creation events are transition events that are also associated with
an instance creation.
Our strategy for creation events is to create the instance in an inactive
state before queuing the event that will activate the instance and
cause a transition.
We will have need to distinguish between the various event types
and use an enumeration to accomplish that.

[source,c]
----
<<mrt interface simple types>>=
typedef enum {
    mrtTransitionEvent,
    mrtPolymorphicEvent,
    mrtCreationEvent
} MRT_EventType ;
----

The process of signaling an event involves the following steps:

. Obtain an *Event Control Block* (ECB) from the free pool of ECB's.
. Set the values of the fields in the ECB.
. Queue the ECB for later dispatch.

=== Event Control Block

The Event Control Block (ECB) is the primary data structure for signaling and
dispatching events.

[source,c]
----
<<mrt interface aggregate types>>=
typedef struct mrtecb {
    struct mrtecb *next ;
    struct mrtecb *prev ;
    MRT_EventCode eventNumber ;
    AllocStatus alloc ;
    MRT_EventType eventType ;
    MRT_Instance *targetInst ;
    MRT_Instance *sourceInst ;
    MRT_DelayTime delay ;
    alignas(max_align_t) MRT_EventParams eventParameters ;
} MRT_Ecb ;
----

`next`, `prev`::
    Event queuing is done by doubly linked lists
    and the links are allocated as part of the ECB as the `next` and
    `prev` members.
`eventNumber`::
    The event number.
    Events are also encoded as small zero based sequential integers
    that are unique only within the class to which they are associated.
    Event numbers are ultimately used as an array index.
`alloc`::
    The `alloc` member is yet another part of _event in flight_ detection.
    We will discuss that more below when we discuss event dispatch.
    For now, this member of the ECB holds the value of the allocation
    counter for the instance that is the target of the event.
    So when an event is generated, a copy of the current value of
    the `alloc` member of the instance is stored in the ECB.
`eventType`::
    The `eventType` member describes which of the two
    types of events this ECB is being used for.
`targetInst`::
    A pointer to the instance that is to receive the event.
`sourceInst`::
    A pointer to the instance that is the signaler of the event.
    If the event is generated outside the context of an instance
    (_e.g._ in an domain operation), then this member value is set to `NULL`.
    The `sourceInst` member also serves an important role in enforcing the rules
    for delayed events.
    More on that later.
`delay`::
    The number of milliseconds to delay before the event is posted.
`eventParameters`::
    Storage for any parameter values passed along with the event.


Event codes are captured by small integer values.

[source,c]
----
<<mrt interface simple types>>=
typedef int8_t MRT_EventCode ;
----

Delay times are in milliseconds and we wish to have a wide dynamic
range of times.

[source,c]
----
<<mrt interface simple types>>=
typedef uint32_t MRT_DelayTime ;
----

Note that there is no notion of priority contained in the ECB.
Some software architectures queue events in a priority order.
That is not supported here.
Frankly, if you need event priorities to make your system work,
then you need to revisit your design or look for a software architecture
that supports multiple threads of execution.

Like all the other data structures, there is a storage pool for ECB's
and we define a size for it here that can be overridden
on the compiler command line.
Sizing the pool for ECB's can be difficult.
It must be worst case allocation as running out of ECB's
is a fatal system error.
The pool must be sized to account for the maximum number of
events that can be in flight at the same time.
This includes delayed events, since they can be considered to be
slow flying events.

[source,c]
----
<<mrt constants>>=
#ifndef MRT_EVENTPOOLSIZE
#   define MRT_EVENTPOOLSIZE 10
#endif /* MRT_EVENTPOOLSIZE */
----

We must allocate the memory for the ECB storage.
As usual, storage is just an array of structures.

[source,c]
----
<<mrt static data>>=
static MRT_Ecb mrtECBPool[MRT_EVENTPOOLSIZE] ;
----

=== Event Parameter Storage

We need to discuss events that carry parametric data and how that will happen.
In this formulation of state machines,
events may carry additional parameters.
Space has to be allocated for that data.
The more difficult issue is to deal with the type of the parameter data.
There are a couple of solutions, neither of which is very satisfying.
We could collect all the parameters from all the state machines
in the system and create a giant union.
This would properly allocate the amount of parameter storage required
and provide a type safe manner to deal with that data.
Unfortunately, the parameters to states are scattered in very many
places in a system and gathering them together is a difficult
undertaking.

Here we take the approach of providing a fixed amount of memory and letting
state actions cast that memory into the appropriate type.
Needless to say, this can also be a source of errors, but is
much easier to manage.
This choice makes sense for many systems.
The number of states that use parametric data is usually small and using a
fixed size works better than might be expected from first considerations.
The important point here is that events can carry data with them.
Many state machine formulations don't support this
and it is very difficult to correctly manage memory lifetime
without it.
It is one of those things that you might not use very often but
it is difficult to do without when you need it.

We fix the amount of memory used for event parameter storage,
allowing it to be overridden by the defining the appropriate macro.

[source,c]
----
<<mrt constants>>=
#ifndef MRT_ECB_PARAM_SIZE
#   define MRT_ECB_PARAM_SIZE  32
#endif /* MRT_ECB_PARAM_SIZE */
----

[source,c]
----
<<mrt interface simple types>>=
typedef char MRT_EventParams[MRT_ECB_PARAM_SIZE] ;
----

The platform model has been very careful to insure the type signatures
of events and state activities.
When signaling an event,
the code generator will generate code to insert event parameters into
the data area using the signature associated with the event.
In the state activity,
the parameters will be moved into local variables according to the
signature of the state activity.

Note that the parameters are passed by value but care must be taken when
passing pointer references to data (_e.g._ `NUL` terminated strings passed as
pointers). The run time does nothing to manage the life time of the
storage when values are passed by reference.

=== Event Queues

In this run time architecture,
we do asynchronous event dispatch from an event queue.
This is one of the simplest ways to insure that we meet the
requirement that state activities run to completion.
Since a queue is used,
as a state activity executes and potentially signals other events,
we know those events will not be dispatched until after the state activity
completes.
Therefore,
there is no danger of a long complicated chain of event dispatching cycling
back around to alter the state of the instance or potentially modify some data
value that the state activity accesses after generating the event.
The guaranteed of run-to-completion for state activity execution is very
important.
We now examine the code that performs the queueing.

To serve as the head of the linked lists,
we define an event queue structure that just contains the
`next` and `prev` pointers.

[source,c]
----
<<mrt implementation aggregate types>>=
typedef struct mrteventqueue {
    MRT_Ecb *next ;
    MRT_Ecb *prev ;
} MRT_EventQueue ;
----

There are four queues that are used to manage events.

[source,c]
----
<<mrt static data>>=
static MRT_EventQueue eventQueue ;
static MRT_EventQueue tocEventQueue ;
static MRT_EventQueue delayedEventQueue ;
static MRT_EventQueue freeEventQueue ;
----

The `eventQueue` queue holds  events waiting to be dispatched.
The events in this queue are those signaled as part of an
ongoing thread of control.
The `tocEventQueue` queue holds events that start a new thread of
control.
Typically,
those are events generated outside of a domain or delayed events finally
being delivered.
The `delayedEventQueue` queue holds events that are
to be delivered by the run time at some future time.
Finally, the `freeEventQueue` queue holds those ECB's
that are not currently begin used.
From the data structures and the semantics of the queuing,
a given ECB can be on at most one of the queues at any time.
Most of the time each ECB is on exactly one of the queues,
but there are short times when ECB's are held in local variables.

The operations that are performed on event queue are associated with
adding and removing elements.
This code is very conventional and I'm sure you seen it or
something very much like it many times before.

[source,c]
----
<<mrt static functions>>=
static inline
MRT_Ecb *
mrtEventQueueBegin(
    MRT_EventQueue *queue)
{
    return queue->next ;
}
----

[source,c]
----
<<mrt static functions>>=
static inline
MRT_Ecb *
mrtEventQueueEnd(
    MRT_EventQueue *queue)
{
    return (MRT_Ecb *)queue ;
}
----

[source,c]
----
<<mrt static functions>>=
static inline
bool
mrtEventQueueEmpty(
    MRT_EventQueue *queue)
{
    return queue->next == (MRT_Ecb *)queue ;
}
----

[source,c]
----
<<mrt static functions>>=
static inline
void
mrtEventQueueInsert(
    MRT_Ecb *item,
    MRT_Ecb *at)
{
    item->prev = at->prev ;
    item->next = at ;
    at->prev->next = item ;
    at->prev = item ;
}
----

[source,c]
----
<<mrt static functions>>=
static inline
void
mrtEventQueueRemove(
    MRT_Ecb *item)
{
    item->prev->next = item->next ;
    item->next->prev = item->prev ;
    item->prev = item->next = NULL ; // <1>
}
----
<1> Although it is not strictly necessary to NULL out the pointers when
an item is removed from the queue,
it does aid in debugging to know if an ECB is being held outside of
one of the queues.

Since we have a pool of ECB's,
we need some operations to manage the pool.
We start with initialization.
This places all the ECB's in the pool onto the free event queue.

[source,c]
----
<<mrt static functions>>=
static
void
mrtInitEventPool(void)
{
    assert(MRT_EVENTPOOLSIZE >= 1) ;
    /*
     * Initialize the queue terminus structures.
     */
    eventQueue.next = eventQueue.prev = (MRT_Ecb *)&eventQueue ;
    tocEventQueue.next = tocEventQueue.prev = (MRT_Ecb *)&tocEventQueue ;
    delayedEventQueue.next = delayedEventQueue.prev = (MRT_Ecb *)&delayedEventQueue ;
    freeEventQueue.next = freeEventQueue.prev = (MRT_Ecb *)&freeEventQueue ;
    /*
     * Place all the event control blocks on the free event
     * queue.  Allocation occurs from there.
     */
    for (MRT_Ecb *ecb = mrtECBPool ;
            ecb < mrtECBPool + MRT_EVENTPOOLSIZE ; ++ecb) {
        mrtEventQueueInsert(ecb, (MRT_Ecb *)&freeEventQueue) ;
    }
}
----

Event allocation is just removing an ECB from the free list.
_N.B._ that running out of Event Control Blocks is fatal.

[source,c]
----
<<mrt static functions>>=
static inline 
MRT_Ecb *
mrtAllocEvent(void)
{
    if (mrtEventQueueEmpty(&freeEventQueue)) {
        mrtFatalError(mrtNoECB) ;
    }

    MRT_Ecb *ecb = freeEventQueue.next ;
    mrtEventQueueRemove(ecb) ;
    return ecb ;
}
----

[source,c]
----
<<mrt static functions>>=
static inline
void
mrtFreeEvent(
    MRT_Ecb *ecb)
{
    assert(ecb != NULL) ;

    mrtEventQueueInsert(ecb, (MRT_Ecb *)&freeEventQueue) ;
}
----

We will have need to find particular events in a queue.
Events are identified by the source of the event, the target of the event
and the number of the event.

[source,c]
----
<<mrt static functions>>=
static MRT_Ecb *
mrtFindEvent(
    MRT_EventQueue *queue,
    MRT_Instance *sourceInst,
    MRT_Instance *targetInst,
    MRT_EventCode event)
{
    /*
     * Simple iteration through the list of events in the queue.
     */
    for (MRT_Ecb *iter = mrtEventQueueBegin(queue) ;
            iter != mrtEventQueueEnd(queue) ;
            iter = iter->next) {
        if (iter->sourceInst == sourceInst && iter->targetInst == targetInst &&
                iter->eventNumber == event) {
            return iter ;
        }
    }
    return NULL ;
}
----

=== Event Signaling

Finally, we can get to functions that the run time provide for
a state activity to signal an event.

[source,c]
----
<<mrt external interfaces>>=
extern MRT_Ecb *mrt_NewEvent(
    MRT_EventCode event,
    MRT_EventType type,
    MRT_Instance *targetInst,
    MRT_Instance *sourceInst) ;
----

The `mrt_NewEvent` function allocates an ECB structure,
fills in the elements and returns the newly minted ECB.

[source,c]
----
<<mrt external functions>>=
MRT_Ecb *
mrt_NewEvent(
    MRT_EventCode event,
    MRT_EventType type,
    MRT_Instance *targetInst,
    MRT_Instance *sourceInst)
{
    assert(targetInst != NULL) ;
    assert(targetInst->alloc != 0) ;
    assert(targetInst->classDesc != NULL) ;

    MRT_Ecb *ecb = mrtAllocEvent() ;

    ecb->eventNumber = event ;
    ecb->alloc = targetInst->alloc ;
    ecb->eventType = type ;
    ecb->targetInst = targetInst ;
    ecb->sourceInst = sourceInst ;
    ecb->delay = 0 ;

    return ecb ;
}
----

=== Asynchronous Instance Creation

As we mentioned earlier,
asynchronous instance creation is accomplished by a combination of
creating an instance and then sending it an event.
The transition caused by the event then causes a state activity to be
executed.

[source,c]
----
<<mrt external interfaces>>=
extern MRT_Instance *mrt_CreateAsync(
    MRT_Class const *targetClass,
    MRT_EventCode event,
    MRT_Instance *sourceInst) ;
----

The `mrt_CreateAsync` function asynchronously creates an instance of the
class described by `targetClass` and arranges for `event` to be
signaled to the new instance.

[source,c]
----
<<mrt external functions>>=
MRT_Instance *
mrt_CreateAsync(
    MRT_Class const *targetClass,
    MRT_EventCode event,
    MRT_Instance *sourceInst)
{
    assert(targetClass != NULL) ;
    assert(targetClass->edb != NULL) ;
    assert(targetClass->edb->creationState >= 0) ;

    MRT_Instance *targetInst = mrt_CreateInstance(targetClass,
            targetClass->edb->creationState) ; // <1>
    targetInst->alloc = -targetInst->alloc ; // <2>

    MRT_Ecb *ecb = mrtAllocEvent() ;
    ecb->eventNumber = event ;
    ecb->alloc = targetInst->alloc ;
    ecb->eventType = mrtCreationEvent ; // <3>
    ecb->targetInst = targetInst ;
    ecb->sourceInst = sourceInst ;
    ecb->delay = 0 ;

    mrt_PostEvent(ecb) ;

    return targetInst ;
}
----
<1> We want the instance created in the pseudo-initial state.
<2> The `alloc` member is made negative for instances that are awaiting
the dispatch of a creation event.
Effectively the negative `alloc` value signals that the memory is reserved
but the instance is not yet active.
During event dispatch, this value will be turned back into a positive one.
<3> We mark this as a creation event so that some additional processing
can be done before the event is dispatched.

=== Posting an Event

Once you have obtained an ECB initialized for the proper type of the
event, then you need to fill in any event parameter data.
Frequently, there are none.
Then the ECB is ready to be placed on a queue.
As mentioned before, there is a distinction between events an
instance sends to itself and those that an instance sends to a different
instance.
Self directed events are placed on the front of the event queue
so that they are dispatched in preference to the non-self directed events.
This is one of the fundamental execution rules.
Posting an event involves both determining the correct queue to which the
event is to be placed and determining the correct place in the queue
for the ECB.
The decisions can be made based on the ECB content.

[source,c]
----
<<mrt external interfaces>>=
extern void
mrt_PostEvent(
    MRT_Ecb *ecb) ;
----

[source,c]
----
<<mrt external functions>>=
void
mrt_PostEvent(
    MRT_Ecb *ecb)
{
    assert(ecb != NULL) ;

    if (ecb->sourceInst == NULL) { // <1>
        mrtEventQueueInsert(ecb, (MRT_Ecb *)&tocEventQueue) ;
    } else if (ecb->sourceInst == ecb->targetInst) {
        /*
         * For self directed events, we insert the event in the front of
         * the event queue, but behind any other self directed events.
         */
        MRT_Ecb *iter ;
        for (iter = mrtEventQueueBegin(&eventQueue) ;
                iter != mrtEventQueueEnd(&eventQueue) ;
                iter = iter->next) {
            if (iter->sourceInst != iter->targetInst) {
                break ;
            }
        }
        mrtEventQueueInsert(ecb, iter) ;
    } else { // <2>
        mrtEventQueueInsert(ecb, (MRT_Ecb *)&eventQueue) ;
    }
}
----
<1> All events that are signaled outside of a state activity start a
new thread of control.
<2> Ordinary transitioning events directed between distinct instances
are queued to the end of the event queue.
This is the most frequent case.

=== Delayed Events

The concept of a delayed event is to request the run time to post
an event at some time in the future.
This implies that the run time has access to some type of timing
facility by which it can know that a given amount of time has elapsed
and this implies that the run time will hold on to the ECB until
that future time has arrived.

There is one significant XUML rule associated with delayed events.
There can be only one outstanding delayed event of a given event
type between any sending / receiving pair of instances
(which may be the same instance).
This is another way of stating that delayed events are identified by
their event name (or numerical encoding), the target instance
and the source instance.
There are a number of ways to interpret an attempt to generate
what amounts to a duplicate delayed event.
It could be considered an error, but that is inconvenient
and goes against the grain of our attempts to minimize run-time errors.
So the run time regards an attempt to generate a delayed event
of the same name between the same sending and receiving pair as
a request to cancel the original event and create the new one
at its newly given time.
This turns out to be very convenient in practice, eliminating the
need to perform checks.
Cancelling and reinstating a new event turns out to be what is
desired in most circumstances.

To understand the implementation of delayed events,
it is necessary to understand the way the delayed event queue
is maintained.
The run time has a delayed event queue where ECB's are placed awaiting
to be posted.
In servicing the delayed events,
we are particularly trying to avoid doing any periodic computation.
For example, we could treat the delayed event queue as a simple list
and wake up periodically and run down the list decrementing time values
and checking if any events have expired.
Such a scheme is easy to implement, but in highly embedded and power
sensitive application,
periodic activity of this type is wasteful and deemed inappropriate.

In this implementation, we keep the delayed event queue in time relative
order.
This design meets two important criteria; only a single source of timing
is used and there is no periodic execution activity.
The cost of meeting these criteria is the price paid
to find the appropriate place in the delayed event queue when a
delayed event is requested.

There are three functions supplied for dealing with delayed events:

. Post a delayed event.
. Cancel a delayed event.
. Query the remaining time for a delayed event.

The unit of time for delayed events is milliseconds.

[source,c]
----
<<mrt external interfaces>>=
extern void
mrt_PostDelayedEvent(
    MRT_Ecb *ecb,
    MRT_DelayTime time) ;
----

The `mrt_PostDelayedEvent` function requests that the event given by
`ecb` be dispatched no sooner than `time` milliseconds from now.
The value of the `time` argument may be 0,
in which case the event is posted for dispatch immediately.
All delayed events start a new thread of control.

[source,c]
----
<<mrt external functions>>=
void
mrt_PostDelayedEvent(
    MRT_Ecb *ecb,
    MRT_DelayTime time)
{
    assert(ecb != NULL) ;

    ecb->delay = time ;
    if (time != 0) {
        mrtPostDelayedEvent(ecb) ;
    } else {
        mrtEventQueueInsert(ecb, (MRT_Ecb *)&tocEventQueue) ;
    }
}
----

==== Posting Delayed Events

Posting delayed events involves finding the correct spot in the
time relative delayed event queue to place the new event.

[source,c]
----
<<mrt static functions>>=
static
void
mrtPostDelayedEvent(
    MRT_Ecb *ecb)
{
    ecb->delay = mrtMsecToTicks(ecb->delay) ;
    /*
     * Stop the timing queue so we may examine it.
     */
    mrtStopDelayedQueueTiming() ;
    /*
     * If the event already exists, remove it.
     */
    MRT_Ecb *prevEvent = mrtFindEvent(&delayedEventQueue,
            ecb->sourceInst, ecb->targetInst, ecb->eventNumber) ;
    if (prevEvent) {
        mrtRemoveDelayedEvent(prevEvent) ;
    }
    /*
     * Insert the new event.
     */
    mrtInsertDelayedEvent(ecb) ;
    assert(!mrtEventQueueEmpty(&delayedEventQueue)) ;
    /*
     * Start the timer to expire for the first event
     * on the queue.
     */
    mrtStartDelayedQueueTiming() ;
}
----

There are five main actions of this function.

. Convert the delay value from millisecond units to
units of `ticks`.
A tick is platform specific.
Computers often don't typically keep time in conventional human units.
However, we would like to run the delayed event queue in system
specific units to avoid as much unnecessary conversion as we can.
This conversion will be described below for each supported platform.
. Stop the timing of the delayed event queue.
More on this later but the goal of stopping the delayed event
queue timing is to freeze the state of the queue so that we
may operate on it.
. Determine if there is already an event matching the one begin posted.
This enforces the rule about not having two delayed events of the
same type between the same sending / receiving pair.
If one is found then it is removed.
. Assured of no duplicates, the new event can be inserted into the timing
queue.  We will see how that happens below.
. Finally, the timing of the delayed queue is started.


==== Canceling Delayed Events

Cancelling a delayed event is one of the more complicated delayed event
operations.
We must account for the various places where a delayed event may be queued.

A delayed event may be in one of two places:

. In the delayed event queue awaiting either waiting for its time to expire
or having already been marked as expired.
. In the thread of control event queue awaiting dispatch.

We will have more to say about event dispatch below,
but it is possible to try to cancel an event after its time has
expired but before it has been delivered to the target instance.
The mechanisms make the guarantee that after invoking
`mrt_EventDelayCancel`
the application can be assured that the event will *not* be
delivered until such time when it is posted again.
Note that it is possible to attempt to cancel a delayed event after
it has already been delivered.
This is not an error.
Unfortunately, the run time code cannot turn time backwards.

[source,c]
----
<<mrt external interfaces>>=
extern void
mrt_CancelDelayedEvent(
    MRT_EventCode event,
    MRT_Instance *targetInst,
    MRT_Instance *sourceInst) ;
----

`event`::
    The number of the event.
`targetInst`::
    A pointer to the instance structure that is to receive the event.
`sourceInst`::
    A pointer to the instance structure that is sending the event.
    Events generated outside of a class instance set this argument to `NULL`.

[source,c]
----
<<mrt external functions>>=
void
mrt_CancelDelayedEvent(
    MRT_EventCode event,
    MRT_Instance *targetInst,
    MRT_Instance *sourceInst)
{
    assert(targetInst != NULL) ;
    /*
     * Stop delayed queue so that we may examine it.
     */
    mrtStopDelayedQueueTiming() ;
    /*
     * Search for the event in the delayed event queue.
     */
    MRT_Ecb *foundEvent = mrtFindEvent(&delayedEventQueue, sourceInst,
            targetInst, event) ;
    if (foundEvent) {
        /*
         * Removing from the delayed queue requires additional processing of
         * the delay times.
         */
        mrtRemoveDelayedEvent(foundEvent) ;
    } else {
        /*
         * If the event is not in the delayed queue, then search the thread of
         * control event queue. The timer could have expired and the event
         * placed in the queue.
         */
        foundEvent = mrtFindEvent(&tocEventQueue, sourceInst, targetInst, event) ;
        if (foundEvent) {
            mrtEventQueueRemove(foundEvent) ;
            mrtFreeEvent(foundEvent) ;
        }
        /*
         * We can get here, without finding the event in the delayed queue or
         * the thread of control event queue.  That's okay, it just amounts to
         * an expensive no-op and implies that the event has expired, was
         * queued and has already been dispatched or had never been generated
         * at all.
         */
    }
    mrtStartDelayedQueueTiming() ;
}
----

Like all operations dealing with the delayed event queue,
we must first put the queue in a state that we
can examine it without asynchronous timing services
modifying its state.
Then we search the delayed event queue for the event to cancel.
The only complication in the implementation is the need to search the thread of
control event queue should the ECB have already been expired off of the delayed
queue.

==== Time Remaining for a Delayed Event

The last provided operation on delayed events is to query the amount
of time remaining for a particular delayed event.
Since we hold the delayed events in sorted order of time differences,
the task of determining the amount of remaining time involves
traversing the queue and summing the time increments of all the
events in front of the event of interest.
The only special case here is what to do if we don't find the
delayed event at all.
In that case, zero is returned.

[source,c]
----
<<mrt external interfaces>>=
extern MRT_DelayTime
mrt_RemainingDelayTime(
    MRT_EventCode event,
    MRT_Instance *targetInst,
    MRT_Instance *sourceInst) ;
----

`event`::
    The number of the event.
`targetInst`::
    A pointer to the instance structure that is to receive the event.
`sourceInst`::
    A pointer to the instance structure that is sending the event.
    Events generated outside of a class instance set this argument to `NULL`.

The algorithm for computing the remaining time is to simply walk the
delayed event queue from the beginning, summing up the
set of time delays until we reach the ECB of delayed event.

[source,c]
----
<<mrt external functions>>=
MRT_DelayTime
mrt_RemainingDelayTime(
    MRT_EventCode event,
    MRT_Instance *targetInst,
    MRT_Instance *sourceInst)
{
    assert(targetInst != NULL) ;

    mrtStopDelayedQueueTiming() ;
    /*
     * Iterate through the delayed event time and sum all the delay times to
     * give the total amount of time remaining for the found event.
     */
    MRT_DelayTime remain = 0 ;
    MRT_Ecb *iter ;
    MRT_Ecb *endOfQueue = mrtEventQueueEnd(&delayedEventQueue) ;
    for (iter = mrtEventQueueBegin(&delayedEventQueue) ; iter != endOfQueue ;
            iter = iter->next) {
        remain += iter->delay ;
        if (iter->sourceInst == sourceInst && iter->targetInst == targetInst &&
                iter->eventNumber == event) {
            break ;
        }
    }
    mrtStartDelayedQueueTiming() ;
    /*
     * Return the amount of time remaining for the event.  If we didn't find
     * the event, the just return 0.
     */
    return iter == endOfQueue ? 0 : mrtTicksToMsec(remain) ;
}
----

Note that zero is returned if we did not find the event on the
delayed queue.
Returning zero does _not_ tell us if the event has already been
dispatched or might be still in flight on the event queue.

==== Delayed Event Queue Operations

In this section we will look at the operations on the delayed
event queue itself.
As we have seen above,
the events in the delayed event queue are ordered by relative time.
Inserting and removing from the queue must keep the ECB's
in time relative order.

[source,c]
----
<<mrt forward references>>=
static void mrtInsertDelayedEvent(MRT_Ecb *ecb) ;
----

[source,c]
----
<<mrt static functions>>=
static
void
mrtInsertDelayedEvent(
    MRT_Ecb *ecb)
{
    /*
     * We walk down the queue to find the correct slot.  That slot is the first
     * place in the queue where our delay value is less than the delay value at
     * that place in the queue.  As we walk the queue, we subtract the delay
     * value of each entry we pass since that entry will have expired before
     * the one being inserted.
     */
    MRT_Ecb *iter ;
    for (iter = mrtEventQueueBegin(&delayedEventQueue) ;
            iter != mrtEventQueueEnd(&delayedEventQueue) ;
            iter = iter->next) {
        /*
         * By keeping this comparison to be strictly less than, we preserve the
         * order of event dispatch to match that of event generation.
         */
        if (ecb->delay < iter->delay) {
            /*
             * We are going to insert before the entry pointed to by "iter".
             * Therefore, we need to decrease its delay value by the amount of
             * time that will have elapsed after the entry we are about to
             * insert expires.
             */
            iter->delay -= ecb->delay ;
            break ;
        } else {
            ecb->delay -= iter->delay ;
        }
    }
    /*
     * At this point we have found our place in the queue.  Either we are
     * between entries or this delay was longer than the cumulative delays of
     * all the ECB's in the queue. Insert the ECB.
     */
    mrtEventQueueInsert(ecb, iter) ;
}
----

Removing an entry from the queue is much simpler.
The only job here is to account for the time that the entry would
have consumed had it been left in the queue.
That time must be added to its next neighbor (if there is one).

[source,c]
----
<<mrt forward references>>=
static void mrtRemoveDelayedEvent(MRT_Ecb *ecb) ;
----

[source,c]
----
<<mrt static functions>>=
static void
mrtRemoveDelayedEvent(
    MRT_Ecb *ecb)
{
    /*
     * If we are not at the end of the queue, all the delay from the removed
     * entry is added onto the next entry in the queue.
     */
    if (ecb->next != mrtEventQueueEnd(&delayedEventQueue)) {
        ecb->next->delay += ecb->delay ;
    }
    /*
     * Remove the ECB from the delayed queue.
     */
    mrtEventQueueRemove(ecb) ;
    /*
     * Return the ECB back to the pool.
     */
    mrtFreeEvent(ecb) ;
}
----

When the delay time expires there are several ways to deal with the events
that need to be dispatched.
One temptation would be to simply sync to the background and let code
run there to remove expired events from the delayed event queue
and restart the timer.
Unfortunately, that would introduce considerable jitter into the timing.
We need to deal with the expired events and restart the timer quickly
and in a deterministic way.
This design chooses to mark the events in the delayed event queue as
expired and that provides a means of knowing which events in the delayed
queue are active.
Since a delay value of 0 is meaningful, we use a delay value of
the maximum for a delay time as the expired marker.

[source,c]
----
<<mrt implementation constants>>=
#define MRT_DELAY_EXPIRED  UINT32_MAX
----

The `mrtExpireDelayedEvents` function is run to traverse the delayed event
queue and mark any events that have a delay value of 0 as expired.
It is used both in the delayed event timer service as well as in the background
processing of the delayed event queue.
The return value is pointer to an ECB.
This will be `NULL` if there are no other events in the delayed queue that
require timing.
Otherwise,
the returned ECB pointer will reference the first unexpired,
non-zero delay event.
The semantics are a bit strained,
but the function is used for two distinct purposes.

[source,c]
----
<<mrt forward references>>=
static MRT_Ecb *mrtExpireDelayedEvents(void) ;
----

[source,c]
----
<<mrt static functions>>=
static
MRT_Ecb *
mrtExpireDelayedEvents(void)
{
    /*
     * Iterate along the delayed event queue.
     */
    for (MRT_Ecb *iter = mrtEventQueueBegin(&delayedEventQueue) ;
            iter != mrtEventQueueEnd(&delayedEventQueue) ;
            iter = iter->next) {
        if (iter->delay == 0) {
            /*
             * Mark all the events that have zero delay time as expired.
             */
            iter->delay = MRT_DELAY_EXPIRED ;
        } else if (iter->delay != MRT_DELAY_EXPIRED) {
            /*
             * Stop at the first non-zero delay time.  This marks the boundary
             * of events that need additional delay time.  The first such event
             * is the next amount of time to delay.
             */
            return iter ;
        }
        /*
         * else ... Skip any events that might already be expired.
         */
    }
    /*
     * We have run the queue without finding an unexpired event.
     */
    return NULL ;
}
----

The function below is then run in the background to re-queue the
expired events.

[source,c]
----
<<mrt static functions>>=
static void
mrtTransferExpiredEvents(void)
{
    /*
     * Iterate through the delayed event queue looking for those entries that
     * have been marked as expired.
     */
    for (MRT_Ecb *iter = mrtEventQueueBegin(&delayedEventQueue) ;
            iter != mrtEventQueueEnd(&delayedEventQueue) &&
            iter->delay == MRT_DELAY_EXPIRED ; /* empty 3rd expression */) {
        /*
         * Advance the iterator here, because we are about to invalidate it by
         * removing the entry from the queue.
         */
        MRT_Ecb *ecb = iter ;
        iter = iter->next ;
        /*
         * Remove the ECB from the delayed queue and insert it into the thread
         * of control event queue for dispatch.
         */
        mrtEventQueueRemove(ecb) ;
        mrtEventQueueInsert(ecb, (MRT_Ecb *)&tocEventQueue) ;
    }
}
----

The concept of starting the delayed event queue timing is
associated with starting the timing resource with the delay time of the
event on the front of the delayed queue.
We move the delay value from the head of the delayed event queue
into the timer and zero the delay member.

[source,c]
----
<<mrt forward references>>=
static void mrtStartDelayedQueueTiming(void) ;
----

[source,c]
----
<<mrt static functions>>=
static void
mrtStartDelayedQueueTiming(void)
{
    if (!mrtEventQueueEmpty(&delayedEventQueue)) {
        MRT_Ecb *ecb = mrtEventQueueBegin(&delayedEventQueue) ;
        assert(ecb->delay != 0) ;
        mrtSysTimerStart(ecb->delay) ;
        ecb->delay = 0 ;
    }
}
----

An analogous operation is needed to stop the queue timing.
Any remaining time is set back into the first entry on the queue.
This puts the queue into a state where ECB's can be inserted,
deleted or summed to find the time remaining for an event.

[source,c]
----
<<mrt forward references>>=
static void mrtStopDelayedQueueTiming(void) ;
----

[source,c]
----
<<mrt static functions>>=
static void
mrtStopDelayedQueueTiming(void)
{
    /*
     * Avoid the whole thing if there is nothing in the delayed event queue.
     */
    if (!mrtEventQueueEmpty(&delayedEventQueue)) {
        /*
         * Stop the timer, obtaining the residual time.
         */
        MRT_DelayTime remain = mrtSysTimerStop() ;
        /*
         * There are two cases here. It is possible for the remaining time
         * returned from mrtSysTimerStop() to be zero. This can happen if the
         * physical timing resource (which might be running asynchronously to
         * the processor) happens to expire within a single tick as we are
         * stopping it.
         */
        if (remain == 0) {
            /*
             * Since the timer has expired we must mark any events with a zero
             * delay time value as expired and, since we are running in the
             * background here, transfer the expired events to be dispatched.
             */
            mrtExpireDelayedEvents() ;
            mrtTransferExpiredEvents() ;
            /*
             * At this point, either the delayed event queue is empty, or the
             * event at the head of the queue has a non-zero delay time.
             */
        } else {
            /*
             * It is possible that the timing resource expired and its
             * interrupt service ran just before we could get the timer
             * stopped. That would mean that there are expired events on the
             * delayed queue at this point and we need to transfer them off the
             * delayed queue to be dispatched.
             */
            mrtTransferExpiredEvents() ;
            /*
             * If any events expired, the delayed event queue might now be
             * empty. However, if the queue is not empty, we must make sure the
             * entry at the head preserves the remaining amount of time that
             * needs to elapse.
             */
            if (!mrtEventQueueEmpty(&delayedEventQueue)) {
                MRT_Ecb *ecb = mrtEventQueueBegin(&delayedEventQueue) ;
                assert(ecb->delay == 0) ;
                ecb->delay = remain ;
            }
        }
    }
}
----

Conceptually, starting and stopping the queue timing moves the time value
of the first ECB on the delay queue into and out of the real timing
resource (whatever that may be).
So when the the delayed event queue timing is running,
at least the first ECB on the queue will have a zero delay time.
When it is stopped, we must insure that the first queued ECB has a non-zero
delay time.

There is a race condition between the background code executing
`mrtStopDelayedQueueTiming()` and
the timer services that may run asynchronously as an interrupt.
After the return from `mrtSysTimerStop()` the timer will have been stopped
and will not cause any interrupt.
However, at any time previous to that the timer interrupt might have gone off
and expired one or more events.
Although a sync function will have been posted,
it will *not* have had an opportunity to run.
So we must make sure to transfer any expired events to the event queue.
This insures that the event generation does not get out of order.

The other complication here is that we might stop the timer just the instant
before it expired.
In this case the underlying timer services might think that there is no
time left on the timer, but the timer interrupt did not actually occur.
This is the case where we just win the race as opposed to the previous
situation where we just lost the race.
So, just in case, we transfer any events on the delay queue that happen
to show zero delay times to the event queue.

==== Expired Events in the Delayed Event Queue

One could simply expire the timer,
notify the background via a sync function
and then allow background processing to remove the expired entries
from the delayed event queue directly to the main event queue for
dispatching.
After the expired entries are queued, then the timer would be restarted
for the next expiration time.

Such a design is subject to problematic, unpredictable timing skew.
After the timer source has expired and posted the synchronization request,
the background may not execute immediately.
Either a currently executing state action or a previously queued
sync function would delay the transfer of expired events from the delayed
queue to the event queue.
If there if another delayed event to expire,
we would like to start that expiration without inserting some
unpredictable time in between.
Essentially, we would like to overlap the timing of the next delayed
event with the time it takes to complete the current activities and
execute the timer sync request.

The question then is how to signify that an event in the delayed event queue
has expired.
We mark its `delay` member with a special value to indicated that
it has expired but not yet been removed from the delayed event queue.
This allows us to keep track of the state of the ECB in the delayed
event queue and still find the next timer interval during the timer
interrupt service routine.

The `mrt_TimerExpireService` function is provided
for the asynchronous timer execution to call that performs task of expiring
events and finding the next time that needs to be placed in the timer.

[source,c]
----
<<mrt external interfaces>>=
/*
 * Must be invoked from interrupt service level only!
 */
extern MRT_DelayTime mrt_TimerExpireService(void) ;
----

[source,c]
----
<<mrt external functions>>=
MRT_DelayTime
mrt_TimerExpireService(void)
{
    /*
     * Sync to the background to request the expired events be transferred to
     * the event queue.
     */
    mrt_SyncRequest(mrtExpiredEventService) ;
    /*
     * Mark the delayed events as expired, returning a pointer to the first
     * unexpired event.
     */
    MRT_Ecb *unexpired = mrtExpireDelayedEvents() ;
    MRT_DelayTime nextTime ;
    if (unexpired) {
        /*
         * If there is an unexpired event, then its delay time is the next time
         * to expire. We return that time and zero out the delay time.
         */
        assert(unexpired->delay != 0) ;
        nextTime = unexpired->delay ;
        unexpired->delay = 0 ;
    } else {
        /*
         * Otherwise, there is nothing else to time.
         */
        nextTime = 0 ;
    }

    return nextTime ;
}
----

. The function assumes it is called from interrupt service level,
_i.e._ it assumes that it may touch the delayed
event queue with impunity since it cannot be interrupted by other
code that might manipulate the state of those queues.
. The function returns the next time to expire.
The caller is responsible for placing that time into the
timer facility if it is non-zero.
If the returned time is zero,
then the timer facility is not currently needed and should
remain stopped.

Notice that the function `mechExpiredEventService` is queued
as as sync function to perform the last step of moving
the expired events to the event queue.
The mechanisms use their own internal facilities to post this
function as a sync function.
This insures that delayed event posting is no different than
any other interrupt synchronization and preserves the notion that the event
queues are not accessed by asynchronous execution.

[source,c]
----
<<mrt static functions>>=
static void
mrtExpiredEventService(
    MRT_SyncParams const *params) /* Not used */
{
    /*
     * Since the expired event queue is accessed here, we must make sure that
     * the timer interrupt does not go off.
     */
    mrtSysTimerMask() ;
    mrtTransferExpiredEvents() ;
    mrtSysTimerUnmask() ;
}
----

==== Timing Considerations

With timing being such a common activity in programming,
there are very many system specific situations that arise in
obtaining timing services on any particular platform.
When running on top of an operating system,
it will provide the necessary timing services.
Unfortunately, the interface to those services varies from OS to OS.
On bare metal platforms,
generally you will have to get timer peripherals and interrupts
involved.
We will do what we can here to factor away the essential logic
from the platform specific,
but note that getting delayed event services running on any particular
platform will require some additional work.

We will try to make as few assumptions about the available timing services
of the platform as we can.
Here are the constraints on the timing services:

* The is only a single source of timing.
    That timing source allows us to specify some time value to it
    and it will respond with some notification when the given time
    has elapsed.
* It is possible to stop the timing and determine how much time
    remains before it expires.
* It is not acceptable to execute code periodically that does nothing.
    This is to account for battery powered devices that cannot afford to
    wake up and check a timing queue only to find out that there is nothing
    to do.
    Activity must be strictly event driven and that implies that
    we can get positive notification when a time period has elapsed.

=== Event Dispatch

Finally, we arrive at the point where we can discuss event dispatching.
Up until this time,
we have been concerned with signaling events,
_i.e._ queuing events to be delivered.
Now we examine the means by which events are delivered to target instances.


[source,c]
----
<<mrt static functions>>=
static
bool
mrtDispatchOneEvent(void)
{
    MRT_EventQueue *queue ;

    if (!mrtEventQueueEmpty(&eventQueue)) {
        queue = &eventQueue ;
    } else {
        mrtEndTransaction() ;
        if (!mrtEventQueueEmpty(&tocEventQueue)) {
            queue = &tocEventQueue ;
        } else {
            return false ;
        }
    }

    MRT_Ecb *ecb = queue->next ;
    mrtEventQueueRemove(ecb) ;
    mrtDispatchEvent(ecb) ;
    /*
     * Return the ECB to the pool.
     */
    mrtFreeEvent(ecb) ;

    return true ;
}
----

As we discussed above,
there are three types of events.
We provide separate functions to dispatch each type of event.

[source,c]
----
<<mrt forward references>>=
static void mrtDispatchTransitionEvent(MRT_Ecb *ecb) ;
static void mrtDispatchPolymorphicEvent(MRT_Ecb *ecb) ;
static void mrtDispatchCreationEvent(MRT_Ecb *ecb) ;
----

We use a table to resolve the function selection at run time.

[source,c]
----
<<mrt static data>>=
static void (* const mrtDispatchFuncs[])(MRT_Ecb *) = {
    [mrtTransitionEvent] = mrtDispatchTransitionEvent,
    [mrtPolymorphicEvent] = mrtDispatchPolymorphicEvent,
    [mrtCreationEvent] = mrtDispatchCreationEvent
} ;
----

The general function to dispatch an event just selects the specific
dispatch function based on the event type using the above table.

[source,c]
----
<<mrt forward references>>=
static inline void mrtDispatchEvent(MRT_Ecb *ecb) ;
----

[source,c]
----
<<mrt static functions>>=
static inline
void
mrtDispatchEvent(
    MRT_Ecb *ecb)
{
    assert(ecb != NULL) ;
    assert(ecb->targetInst != NULL) ;
    assert(ecb->targetInst->classDesc != NULL) ;
    assert(ecb->eventType < COUNTOF(mrtDispatchFuncs)) ;

    mrtDispatchFuncs[ecb->eventType](ecb) ;
}
----

In the sections below,
we consider the dispatch of each particular event type.

=== Transition Event Dispatch

Far and away the most common activity is to dispatch a transitioning event
to a state machine.
We refer to these event types, _transition_, only to distinguish them from the
more complicated and less frequent polymorphic and creation event types.

Dispatching an event in its simplest terms involves using the
current state of the instance and the event number contained in
an ECB as indices into the transition matrix.
The transition matrix is the same for all instances of a class.
The entry in the transition matrix is the new state to which a
transition is to be made.
There are a few complications such as the need to
account for _ignored_ and _can't happen_ events.

Ignored events cause no transition.
Events that are ignored can be thought of as an optimization
on the state transition graph.
Ignored events could be handled by adding a new state to which
the ignored event makes a transition and that new state
has all the other outbound transitions that the original state had.
Clearly, having the concept of ignored events saves much clutter
in the state transition graph.

When the analyst considers a transition to be a logical impossibility,
then it is declared as a can't happen event.
In the micca run time,
a can't happen transition is treated as a fatal system error.
This is a policy decision of the architecture,
so don't assume that _can't happen_ means
_shouldn't happen_ or _has a low probability of happening_.
In this architecture, can't happen means absolutely impossible to
happen and if it does happen then there has been a tear in the
space / time continuum and the only course available is to
give up and declare a fatal error.

The data structure used for transitioning event dispatch
is called an *Event Dispatch Block* (EDB).
The code generator supplies an EDB for each class that has a state model.
Below we will see how all this ties together.
For now, we discuss the data structure and how it is used.

[source,c]
----
<<mrt interface aggregate types>>=
typedef struct mrteventdispatchblock {
    MRT_DispatchCount stateCount ;
    MRT_DispatchCount eventCount ;
    MRT_StateCode initialState ;
    MRT_StateCode creationState ;
    MRT_StateCode const *transitionTable ;
    PtrActivityFunction const *activityTable ;
    bool const *terminalStates ;

#       ifndef MRT_NO_NAMES
    char const *const *stateNames ;
    char const *const *eventNames ;
#       endif /* MRT_NO_NAMES */
} MRT_edb ;
----

`stateCount`::
    The number of states in the transition matrix.
`eventCount`::
    The number of events in the transition matrix.
`initialState`::
    The number of the state that is the default state when an
    instance is created synchronously.
`creationState`::
    The number of the state that is the default state when an
    instance is created asynchronously.
`transitionTable`::
    A pointer to the transition matrix.
`activityTable`::
    A pointer to the state activities.
`terminalStates`::
    A pointer to a boolean array that determines if a state is a
    terminal state.
`stateNames`::
    A pointer to an array of character pointers to the names of the
    class states.
    This information is used in tracing event dispatch.
`eventNames`::
    A pointer to an array of character pointers to the names of the
    class events.
    This information is used in tracing event dispatch.

The dimensions of the state transition matrix are `stateCount` rows
by `eventCount` columns.
The counts are held as small integers.

[source,c]
----
<<mrt interface simple types>>=
typedef uint8_t MRT_DispatchCount ;
----

The transition table is in state major order,
_i.e._ the current state is used to index conceptual rows and the event number
is used to index conceptual columns.
The dimensions are captured in the EDB to allow run time bounds checking
during event dispatch.

The basic transition algorithm is to use the current state of an instance and
the event number of an event as the indices into the transition matrix.
The entry in the transition matrix is the new state.
Notice the very simple data structures required for Moore state machines.

The new state is used as an index into the `activityTable`.
The action table is an array of function pointers to the activity associated
with each state.

[source,c]
----
<<mrt interface simple types>>=
typedef void ActivityFunction(void *const, void const *const) ;
typedef ActivityFunction *PtrActivityFunction ;
----

Since Moore state machines associate the activity with the state,
that code segment is supplied as a function matching the prototype above.
The first argument is a pointer to the instance receiving the event.
It is `void` typed and state activities are expected to recover
the correct type by casting the pointer to the be of the proper
instance data structure.
The second argument is a pointer to the event parameters.
Again, the correct type is recovered in the state activity to match
the parameter signature of the activity.
Notice that assigning back into event parameters does not make any sense as the
parameter values are discarded after the state action completes.

One other feature of the state machine dispatch rules regards terminal states.
A state may be marked as terminal and if so,
then the run time will cause the instance to be destroyed when the state action
is completed.
The `terminalStates` member points to an array, indexed by state number,
that specifies if a particular state is indeed a terminal state.
As is frequently the case, the class may have no terminal states.
In this case, `terminalState` member may be set to `NULL` to
indicate this fact and save the storage of the final state booleans
(_i.e._ there is no need to have an array of `false` values).

[source,c]
----
<<mrt static functions>>=
static void
mrtDispatchTransitionEvent(
    MRT_Ecb *ecb)
{
    MRT_Instance *targetInst = ecb->targetInst ;
    MRT_edb const *edb = targetInst->classDesc->edb ;
    assert(edb != NULL) ;

    /*
     * Test for corruption of the current state or event number.
     */
    assert(edb->stateCount > targetInst->currentState) ;
    assert(edb->eventCount > ecb->eventNumber) ;
    /*
     * Check for the "event-in-flight" error. This occurs when an instance is
     * deleted while there is an event for that instance in the event queue.
     * For this architecture, such occurrences are considered as run-time
     * detected analysis errors.
     */
    if (targetInst->alloc != ecb->alloc) {
#           ifndef MRT_NO_NAMES
        mrtFatalError(mrtEventInFlight,
                ecb->sourceInst ? ecb->sourceInst->name : "",
                ecb->sourceInst ? ecb->sourceInst->name : "none",
                targetInst->classDesc->edb->eventNames[ecb->eventNumber],
                targetInst->classDesc->name,
                targetInst->name ? targetInst->name : "unknown") ;
#           else
        mrtFatalError(mrtEventInFlight, ecb->sourceInst, ecb->eventNumber,
                targetInst) ;
#           endif /* MRT_NO_NAMES */
    }
    /*
     * Fetch the new state from the transition table.
     */
    MRT_StateCode newState = *(edb->transitionTable +
            targetInst->currentState * edb->eventCount + ecb->eventNumber) ;

#       ifndef MRT_NO_TRACE
    /*
     * Trace the transition.
     */
    mrtTraceTransitionEvent(ecb->eventNumber, ecb->sourceInst,
            ecb->targetInst, targetInst->currentState, newState) ;
#       endif /* MRT_NO_TRACE */

    /*
     * Check for a can't happen transition.
     */
    if (newState == MRT_StateCode_CH) {
#           ifndef MRT_NO_NAMES
        mrtFatalError(mrtCantHappen, targetInst->classDesc->name,
                targetInst->name ? targetInst->name : "unknown",
                targetInst->classDesc->edb->stateNames[targetInst->currentState],
                targetInst->classDesc->edb->eventNames[ecb->eventNumber]) ;
#           else
        mrtFatalError(mrtCantHappen, targetInst, targetInst->currentState,
                ecb->eventNumber) ;
#           endif /* MRT_NO_NAMES */
    } else if (newState != MRT_StateCode_IG) {
        /*
         * Check for corrupt transition table.
         */
        assert(newState < edb->stateCount) ;
        /*
         * We update the current state to reflect the transition before
         * executing the activity for the state.
         */
        targetInst->currentState = newState ;
        /*
         * Invoke the state activity if there is one.
         */
        PtrActivityFunction activity = edb->activityTable[newState] ;
        if (activity) {
            activity(targetInst, &ecb->eventParameters) ;
        }
        /*
         * Check if we have entered a terminal state. If so, the instance is
         * deleted.
         */
        if (edb->terminalStates && edb->terminalStates[newState]) {
            mrt_DeleteInstance(targetInst) ; // <1>
        }
    }
}
----
<1> This is where asynchronous instance deletion occurs.
If the state is designated as terminal,
then the run time deletes the instance after its state activity completes.

The processing for dispatching a transition event follows directly from
the definitions.
After the check for an event-in-flight error,
we perform the indexing into the transition matrix.
The indexing expression results from the need to treat a linear
set of bytes as a two dimensional matrix.
We can't type it any differently since we have different sized
transition matrices for each different state model.
After obtaining the new state,
we must determine if we are actually going to make a transition
or if the event is to be ignored or considered a fatal error.
Assuming that we are transitioning,
then the associated state action is found and executed.
Note that empty state actions may be dispensed with and a `NULL`
inserted into the action table.
After the action, we check if the instance entered a final state.

We are finally in a position to explain the event-in-flight error
in detail.
The mechanisms detect only one analysis error at run time,
the delivery of an event to an instance that has been deleted.
Because events are queued,
it is possible for an event to be generated for an instance and then
while the event is on the queue awaiting to be delivered,
the target instance is deleted by some other action code executing.
For a single threaded architecture,
this is considered an analysis error.
Deliverying events to deleted instances should never happen!
The model is responsible for insuring that instance deletion is accomplished
only after there are no events awaiting to be delivered.
However, it can happen and the mechanisms detect and catch this.

A significant difficulty arises in systems that use distinct memory pools
for the instances of each class.
If an instance is destroyed and another one created, they may very
well end up in exactly the same array slot and therefore have exactly
the same instance pointer value.
So, a pathological case where an event is generated for an instance,
the instance is deleted and then re-created while the event is queued
could end up delivering the event to the newly recreated instance.
Quite the wrong thing to do.

The strategy used here is to vary the number in the
`alloc` field of the instance each time it is allocated.
Then a copy of the `alloc` field is placed in the ECB
when the event is queued.
When dispatched, the values of the `alloc` fields in the
two structures must match or else the target instance has
been destroyed and re-created in the same memory slot.
Of course, the observant reader will have seen that in the case where
the target instance is destroyed and recreated 16,000 times while the event
is queued will result in the event being dispatched to the wrong
instance.
This is considered such a remote possibility as to be of no practical concern.

=== Polymorphic Event Dispatch

Polymorphic events in their full generality can be complex,
but they are based on a simple idea.
In fact, there is nothing going on in the dispatch of polymorphic events
that could not otherwise be handled in the action code of a state.
So, polymorphic events must be considered an optimization, but a
very convenient and significant one.
Previously,
we have described the rules concerning polymorphic events.

When a polymorphic event is dispatched,
we must traverse the generalization from the superclass to the subclass
to determine the type of the subclass.
Conceptually, determining which subclass is related to a particular
instance of a superclass is not difficult.
There are two fundamental steps in dispatching a polymorphic event:

. Determining which subtype instance is currently related to a supertype
instance.
. Mapping the polymorphic event encoding in the supertype to an event encoding
in the subtype.

In order to accomplish the first step,
the run time has know how the generalization relationship is stored in the
instances.
The run time supports two different schemes of storing the generalization
relationship,
either as a pointer reference or as a union.

Both relationship storage techniques have their uses and we will not
discuss the pros and cons of one choice over another here.
If the generalization relationship is stored as a reference,
then the superclass instances will contain an instance pointer to a subtype.
If the generalization relationship is stored as a union,
then the superclass structure will a member that is a union of the data types
of all the subtypes of the generalization hierarchy.
This distinction is an attribute of the class and is encoded in an
enumerated data type.

[source,c]
----
<<mrt interface simple types>>=
typedef enum {
    mrtPolyReference,
    mrtPolyUnion
} MRT_PolyStorageType ;
----

It is also necessary to store in the superclass instance some encoding
of the subclass to which it is currently related.
This is just a simple zero based, sequential number that is associated
with the subclasss of the hierarchy.

[source,c]
----
<<mrt interface simple types>>=
typedef uint8_t MRT_SubclassCode ;
----

As we will see,
if we can locate where in the superclass instance structure
the subclass encoding and the subclass reference or union are located,
then we can determine the type of the subclass instance to which 
a particular superclass instance is related.
To do that we assume that the there is a data type that can hold
the byte offset from the beginning of the superclass instance structure
to the required information.
As you can probably imagine,
this will be a tricky piece of code since it must pick out
information from an arbitrary data structure in a generic fashion.

[source,c]
----
<<mrt interface simple types>>=
typedef size_t MRT_AttrOffset ;
----

==== Polymorphic Event Mapping

We now turn our attention to the actual mapping of polymorphic events.
The mapping is analogous to the mapping of current state and event to
a new state for normal event dispatch.
For polymorphic events,
the mapping is from subclass code of the currently related subclass and
polymorphic event number to a new event.
The data structure required for this is given by:

[source,c]
----
<<mrt interface aggregate types>>=
typedef struct mrtgendispatchblock {
    MRT_PolyStorageType refStorage ;
    MRT_AttrOffset subCodeOffset ;
    MRT_AttrOffset subInstOffset ;
    MRT_DispatchCount subclassCount ;
    struct mrtpolyeventmap const *eventMap ;

#       ifndef MRT_NO_NAMES
    char const *const *subclassNames ;
#       endif /* MRT_NO_NAMES */
} MRT_gdb ;
----

`refStorage`::
    The `refStorage` member determines if the generalization
    relationship is stored in reference form or in union form.
`subCodeOffset`::
    The `subCodeOffset` member holds the byte offset from
    the beginning of the instance structure where the encoding
    for the currently related subclass is held.
`subInstOffset`::
    The `subInstOffset` member holds the byte offset from
    the beginning of the instance structure where either a pointer
    to a subclass is stored or the union for the subclasss is located.
`subclassCount`::
    The `subclassCount` member holds the number of subclasses defined for this
    generalization relationship.
    This value is used for run-time checks.
`eventMap`::
    The `eventMap` member is a pointer to the mapping
    of polymorphic events for the generalization.
    This mapping is indexed in major order by subclass code and in
    minor order by polymorphic event number.
`subclassNames`::
    A pointer to an array of names of the subclasses of generalization.
    The array is of length, `subclassCount`.

A key realization here is that as we are mapping along a generalization
a given polymorphic event may be mapped into a normal event where it
will be consumed by the state machine of the class or
it may be delegated further down the hierarchy.
To be further delegated implies that a polymorphic event will be mapped
into yet another polymorphic event to be further mapped in a subsequent
dispatch.
Thus the entries in the `eventMap` matrix contain both a new
event number and an indication of the type of the new event.

[source,c]
----
<<mrt interface aggregate types>>=
typedef struct mrtpolyeventmap {
    MRT_EventCode event ;
    MRT_EventType eventType ;
} MRT_PolyEventMap ;
----

Now we can tie it all together.
A superclass class that has associated polymorphic events must
supply a Polymorphic Dispatch Block (PDB) to direct the mechanisms
as to how to perform the mapping of polymorphic events to normal events.

[source,c]
----
<<mrt interface aggregate types>>=
typedef struct mrtpolydispatchblock {
    MRT_DispatchCount eventCount ;
    MRT_DispatchCount genCount ;
    struct mrtgendispatchblock const *genDispatch ;

#       ifndef MRT_NO_NAMES
    char const *const *eventNames ;
    char const *const *genNames ;
#       endif /* MRT_NO_NAMES */
} MRT_pdb ;
----

`eventCount`::
    The `eventCount` member holds the number of polymorphic
    events associated with the superclass.
    Like transition events, polymorphic events are encoded as zero based
    sequential integers so they may be used as array indices in the
    mapping process.
`genCount`::
    The `genCount` member holds the number of generalization
    that originate at the superclass class.
`genDispatch`::
    The `genDispatch` member holds a pointer to an array of
    Generalization Dispatch Blocks.
    The array contains `genCount` elements.
`eventNames`::
    A pointer to an array of polymorphic event names.
    The array is of length, `eventCount`.
`genNames`::
    A pointer to an array of generalization relationship names.
    The array is of length, `genCount`.

Now we can give the code for polymorphic event dispatch.

[source,c]
----
<<mrt static functions>>=
static void
mrtDispatchPolymorphicEvent(
    MRT_Ecb *ecb)
{
    MRT_pdb const *pdb = ecb->targetInst->classDesc->pdb ;

    assert(pdb != NULL) ;
    assert(ecb->eventNumber < pdb->eventCount) ;
    assert(pdb->genCount > 0) ;

    /*
     * Save the original event number and target instance pointer.  We intend
     * to reuse the same ECB for each event we dispatch and will need these
     * values should there be more than one generalization associated with this
     * superclass.
     */
    MRT_EventCode origEvent = ecb->eventNumber ;
    MRT_Instance *origTarget = ecb->targetInst ;
    /*
     * Each generalization that originates at the superclass has an event
     * generated down that generalization to one of the subclasss.
     */
    MRT_gdb const *sdb = pdb->genDispatch ;
    for (unsigned gnum = 0 ; gnum < pdb->genCount ; ++sdb, ++gnum) {
        MRT_SubclassCode type = *(MRT_SubclassCode *)
                ((uintptr_t)origTarget + sdb->subCodeOffset) ;

        assert(type < sdb->subclassCount) ;
        MRT_PolyEventMap const *pem = sdb->eventMap +
                (type * pdb->eventCount + origEvent) ;

#           ifndef MRT_NO_TRACE
        /*
         * Trace the transition.
         */
        mrtTracePolyEvent(origEvent, ecb->sourceInst, ecb->targetInst,
                type, gnum, pem->event, pem->eventType) ;
#           endif /* MRT_NO_TRACE */

        ecb->eventNumber = pem->event ;
        ecb->eventType = pem->eventType ;

        void *subTypeRef = (void *)((uintptr_t)ecb->targetInst +
                sdb->subInstOffset) ;
        ecb->targetInst = sdb->refStorage == mrtPolyReference ?
            /*
             * When the generalization is implemented via a pointer, we need an
             * extra level of indirection to fetch the address of the subclass.
             */
            *(MRT_Instance **)subTypeRef :
            /*
             * When the generalization is implemented by a union, we need only
             * point to the address of the subclass as it is contained in the
             * superclass.
             */
            (MRT_Instance *)subTypeRef ;

        ecb->alloc = ecb->targetInst->alloc ;
        assert(ecb->alloc != 0) ;

        mrtDispatchEvent(ecb) ; // <1>
    }
}
----
<1> Since a polymorphic event may map to either another polymorphic event
or to a transition event, we will use the general dispatch function
to recursively dispatch the mapped event.

The code loops through all of the generalizations for which the `targetInst`
is a superclass.
The vast majority of the time there is only one generalization.
The strategy used here is to reuse the ECB that was carrying the polymorphic
event as the ECB for the remapped events.
The mapping of a polymorphic event is a function of the superclass target
and the polymorphic event number.
So we hold them in local variables as we overwrite the necessary fields
in the ECB to hold the mapped event information.

The core of the algorithm is to fetch the subclass code from the superclass
instance and use that as the row index into the polymorphic event map for the
generalization.
The event number is then used as the column index to find the mapping
entry.
That mapping entry contains a new event number and event type.
The new target of the event is then the currently related subclass instance.
As we have discussed,
this may be a stored as a pointer or may be a union member of the superclass
instance structure.
For the pointer case,
we fetch the pointer from its location in the superclass structure.
For the union case,
the location in the superclass structure is the
beginning of the union, _i.e._ we down cast to the subclass member.
We fill in the `alloc` field to enable the event in
flight detection just in case the mapped event causes a transition.
Finally the newly minted ECB is recursively dispatched and the
next generalization is considered.
Recursively dispatching the event preserves the order of delivery of
the events.

=== Creation Event Dispatch

Fortunately, creation events are much simpler than polymorphic events.
Creation event dispatch is the simple combination of instance allocation
and normal event dispatch.
No additional data structures are required.
The code below shows how it is done.

[source,c]
----
<<mrt static functions>>=
static void
mrtDispatchCreationEvent(
    MRT_Ecb *ecb)
{
#       ifndef MRT_NO_TRACE
    /*
     * Trace the transition.
     */
    mrtTraceCreationEvent(ecb->eventNumber, ecb->sourceInst, ecb->targetInst,
            ecb->targetInst->classDesc) ;
#       endif /* MRT_NO_TRACE */

    assert(ecb->alloc == ecb->targetInst->alloc) ;
    assert(ecb->alloc < 0) ;
    assert(ecb->targetInst->alloc < 0) ;
    assert(ecb->targetInst->currentState == 0) ;

    /*
     * Negate the alloc member to show that the instance is now active.
     */
    ecb->alloc = ecb->targetInst->alloc = -ecb->targetInst->alloc ;
    /*
     * Change the event type to represent a transition event.
     */
    ecb->eventType = mrtTransitionEvent ;
    /*
     * Dispatch the event.
     */
    mrtDispatchTransitionEvent(ecb) ;
}
----

== Bridging Domains

All but the simplest of systems will contain more that one domain.
A domain represent a coherent subject matter with its own set of rules
and policies.
Domains are also the unit of encapsulation and reuse.

Consider a simple example of a domain that controls a chemical reaction
vessel.
One aspect of synthesizing something in a reaction vessel
is controlling the temperature of the vessel.
Such systems typically delegate control to another domain so that
a Reaction Management domain would delegate setting and maintaining
the reaction vessel temperature to a Signal I/O domain.

From the point of view of Reaction Management, the reaction vessel has
heaters, coolers, pumps, valves and such things and it is its responsibility
to sequence the vessel operations to accomplish the synthesis.
Reaction Management does not know the details of what it is controlling.
It wants to set the vessel temperature to 57C and maintain it there
for some time period.
How that happens in terms of heaters, thermal load and other such
physical considerations is delegated.

From the point of view of Signal I/O,
it knows that it is controlling output actuators with input sensors
as feed back.
That output point number 57 corresponds to a reactor vessel is not in
its scope of concern.

The concept of a domain is very much related to the concept of
_separation of concerns_.
But that which is separated must be combined if we are to obtain a
useful system.
The difference in the semantic points of view of domains must be
bridged by translating the requirements and dependencies of one domain
into the services provided by other domains.

There are several approaches to bridging.
The most elegant approach is related to _aspect oriented programming_ concepts.
In this style of bridging,
we would use a separate means to describe how operations in one domain
would be mapped to side effects in another domain.
For example, we would want to be able to state that
when the state activity in the Reaction Management domain updates
the reactor vessel set point attribute we would want the temperature
to be transferred to output point number 57 of the Signal I/O domain.
The advantage of this type of bridging is that the individual domains are
not modified and the domain semantics are not disturbed.
The bridge interactions are defined outside of the domain implementation.
It is then a code generator's task to generate the domain code so that
the bridge mapping is implemented.
The disadvantage of this type of bridging is that it is very difficult
to implement such a code generator.

Another approach to bridging is termed, _explicit bridging_.
In this form,
a domain makes explicit invocations to an _external entity_.
The invocations demonstrate the explicit requirements that the domain
delegates and the service it requires.
Bridges then map the external entity invocations to domain operations
of the domain that will service the requirements.
Explicit bridging is a workable technique but can lead to
a large number of domain operations being needed to service a client
domain's requirements.
Often,
a client domain and service domain will have _counterpart classes_.
These are classes that represent different aspects of the same entity
but do so in the semantics of the individual domains.
In such cases,
model level operations in the client domain, _e.g._ updating an attribute
value, are bridged to a similar model operations in the service domain,
_e.g_ updating the counterpart class attribute with a scaled value.
If it is necessary to code a domain operation for each such model level
operation,
the service domain will be unnecessarily complicated and its reuse will
be limited since the details of how model level actions need to take place
will very much depend upon the context in which the service domain is used.

Making available the ability to do some model level operations such as
updating attributes or signaling event from outside of the domain
can make explicit bridging much easier and prevent cluttering the
external interfaces of service domains with domain operations specifically
built to support the use of the service domain in one particular system.
Doing so breaks the encapsulation of the domain,
albeit in a very controlled manner.

`Micca` takes the follow view of bridging:

* Domain designs should provide domain operations for those computations that
must be accomplished as a transaction or that involve navigating relationship
or other more complicated activities.
* The `micca` code generator provides the means to break encapsulation
of a domain for simple model level actions such as signaling an event
or reading a class instance attribute.
* A domain must be populated before it can be bridged.
* Bridge operation code is manually coded to map the semantics of one
domain onto another and, in general, is _not_ reusable.
The context of how domains interact is specific to the use of the domains
in building the overall system.
* Dynamic activity in one domain may have to be reflected in the bridge.
For example, instance creation in one domain may have to result in
creating an instance of a counterpart class in a service domain.
In such cases, the bridge itself may have to track the dynamics of the
two domains.

These consideration make domain bridging abstract and complicated.
Sadly, the methodological fundamentals of bridging seem to be lacking
and much of what is done to build systems from bridged domains smacks of
being _ad hoc_.
There is much more that could be said about bridging that space does not
allow for here.
Projects are cautioned that bridging domains can be a significant
activity for which plans need to be made.

In this section,
we discuss the facilities provide by `micca` to perform operations on a
domain from outside the domain itself.
These facilities are intended to be used by bridge operation code.
Conceptually,
`micca` builds a _portal_ into the domain and supplies a set of functions
that will reach through the portal and perform operations in the domain.
The set of operations that can be performed is very limited but is a useful
set for implementing bridge operations.

=== Portal Data Structures

Internally,
a `micca` generated domain uses pointers to refer to instances, class
descriptors and other essential data.
We do _not_ want to expose addresses of the internals of a domain
to the outside.
Since all class instances are really elements of the class storage array,
the index of an instance in the storage array serves as a convenient
external identifier.
The `micca` code generator will place a set of ``C'' preprocessor
definitions in the generated header file to numerically encode
the classes, instances and attributes.
It is these small integer numbers that will serve as identifiers outside of the
domain and which we will use as array indices (with appropriate bounds
checking) inside the domain.

[source,c]
----
<<mrt interface simple types>>=
typedef unsigned short MRT_ClassId ;
typedef unsigned short MRT_InstId ;
typedef unsigned short MRT_AttrId ;
typedef size_t MRT_AttrSize ;
----

A `micca` domain only exposes domain operations as externally scoped names.
To operate on the internals of a domain requires a data structure
that maps the numerically encoded identifiers to the internals
of domain.

[source,c]
----
<<mrt interface aggregate types>>=
typedef struct mrtdomainportal {
    unsigned classCount ;
    MRT_Class const *classes ;

#       ifndef MRT_NO_NAMES
    char const *name ;
#       endif /* MRT_NO_NAMES */
} MRT_DomainPortal ;
----

`classCount`::
    The count of classes in the domain.
`classes`::
    A pointer to an array of class portal descriptions. The array contains
    `classCount` elements.
`name`::
    A pointer to a NUL terminated character array giving the name of the domain.

The domain portal is a collection of class descriptions.
Note that relationships will not be accessible via the portal.

Foreach domain,
the code generator will create an externally scoped variable of the
above type.
This variable forms the _portal_ into the domain and below we
describe the operations on the domain that are available via the portal.

=== Portal Access Functions

In this section we describe the set of operations that are avaiable
through the portal.
All the portal access functions return an integer value.
Negative return values indicate errors as described below.

[source,c]
----
<<mrt constants>>=
     // No such class.
#define MICCA_PORTAL_NO_CLASS       (-1)
     // No such instance.
#define MICCA_PORTAL_NO_INST        (-2)
     // No such attribute.
#define MICCA_PORTAL_NO_ATTR        (-3)
     // Instance slot is not in use.
#define MICCA_PORTAL_UNALLOC        (-4)
     // Class does not have a state model.
#define MICCA_PORTAL_NO_STATE_MODEL (-5)
     // No such event for the class.
#define MICCA_PORTAL_NO_SUCH_EVENT  (-6)
     // Bad event type parameter
#define MICCA_PORTAL_BAD_EVENT_TYPE (-7)
     // Class does not support dynamic instances.
#define MICCA_PORTAL_NO_DYNAMIC     (-8)
----

Internally,
the portal access functions often need to find a class instance.
We have factored that into a static fukction.

[source,c]
----
<<mrt static functions>>=
static int
mrtPortalGetInstRef(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_InstId instId,
    MRT_Instance **ref)
{
    int result ;

    if (classId < portal->classCount) {
        MRT_Class const *pclass = portal->classes + classId ;
        if (instId < pclass->instCount) {
            uintptr_t inst ;

            if (pclass->containment) { // <1>
                MRT_Class const *usuper ;
                struct mrtunionsuperclassrole const *next = pclass->containment ;
                do {
                    usuper = next->classDesc ;
                    next = next->classDesc->containment ;
                } while (next != NULL) ;

                MRT_iab *iab = usuper->iab ;
                assert(iab != NULL) ;
                inst = (uintptr_t)iab->storageStart +
                        instId * iab->instanceSize +
                        pclass->containment->subInstOffset ;
            } else {
                MRT_iab *iab = pclass->iab ;
                assert(iab != NULL) ;
                inst = (uintptr_t)iab->storageStart +
                        instId * iab->instanceSize ;
            }
            if (ref) {
                *ref = (MRT_Instance *)inst ;
            }
            result = 0 ;
        } else {
            result = MICCA_PORTAL_NO_INST ;
        }
    } else {
        result = MICCA_PORTAL_NO_CLASS ;
    }
}
----
<1> Here we have to account for union subclasses.
For ordinary classes, the instance allocation block provides what is needed
to where the instance is located in memory.
For union subclasses, it is the instance allocation block of the
ultimate superclass that determines where the subclass is stored
and there is an additional offset from the beginning of the superclass
instance to the location of the subclass.

Ther is one case where we expose some internal pointer information
and this is for attributes.
Some attributes just don't pass well by value in ``C''.
Obtaining a reference to the attribute is often the best way to
pass its value around.

[source,c]
----
<<mrt external interfaces>>=
extern int
mrt_PortalGetAttrRef(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_InstId instId,
    MRT_AttrId attrId,
    void **pref,
    MRT_AttrSize *size) ;
----

`portal`::
    A pointer to the portal structure for the domain.
`classId`::
    The number of the class. This number is generated by micca and placed in
    the domain header file.
`instId`::
    The number of the instance. Instance numbers are consecutive non-negative
    integers up to the maximum number of instances defined for the class.
`attrId`::
    The number of the attribute to be read. This number is generated by micca
    and placed in the domain header file.
`pref`::
    A pointer to a memory pointer where the attribute reference is placed.
    If this argument is `NULL` then no reference is returned.
`size`::
    A pointer to where the size of the attribute is placed.
    If this argument is `NULL` then no size information is returned.

`mrt_GetAttrRef` obtains a pointer to the storage location for an
attribute and the size of that storage location.
The return value is 0, if the attribute storage could be found.
Negative numbers indicate an error occurred.

[source,c]
----
<<mrt external functions>>=
int
mrt_PortalGetAttrRef(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_InstId instId,
    MRT_AttrId attrId,
    void **pref,
    MRT_AttrSize *size)
{
    int result ;
    MRT_Instance *instref ;

    result = mrtPortalGetInstRef(portal, classId, instId, &instref) ;
    if (result == 0) {
        MRT_Class const *class = portal->classes + classId ;
        if (attrId < class->attrCount) {
            MRT_Attribute const *attr = class->classAttrs + attrId ;
            if (instref->alloc != 0) {
                if (pref) {
                    *pref = (void *)((uintptr_t)instref + attr->offset) ;
                }
                if (size) {
                    *size = attr->size ;
                }
            } else {
                result = MICCA_PORTAL_UNALLOC ;
            }
        } else {
            result = MICCA_PORTAL_NO_ATTR ;
        }
    }

    return result ;
}
----

==== Reading Attributes

[source,c]
----
<<mrt external interfaces>>=
extern int
mrt_PortalReadAttr(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_InstId instId,
    MRT_AttrId attrId,
    void *dst,
    MRT_AttrSize dstSize) ;
----

`portal`::
    A pointer to the portal structure for the domain.
`classId`::
    The number of the class. This number is generated by micca and placed in
    the domain header file.
`instId`::
    The number of the instance. Instance numbers are consecutive non-negative
    integers up to the maximum number of instances defined for the class.
`attrId`::
    The number of the attribute to be read. This number is generated by micca
    and placed in the domain header file.
`dst`::
    A pointer to memory where the attribute value is placed.
`dstSize`::
    The number of bytes pointed to by `dst`.

`mrt_PortalReadAttr` reads an attribute value from a domain.
No more than `dstSize` bytes will be placed in the memory pointed to by
`dst`.
If the return value is non-negative, then it represents the actual number of
bytes read.
Negative numbers indicate an error occurred.

[source,c]
----
<<mrt external functions>>=
int
mrt_PortalReadAttr(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_InstId instId,
    MRT_AttrId attrId,
    void *dst,
    MRT_AttrSize dstSize)
{
    assert(dst != NULL) ;

    void *src ;
    MRT_AttrSize srcSize = 0 ;
    int copied = 0 ;

    int result = mrt_PortalGetAttrRef(portal, classId, instId, attrId, &src,
            &srcSize) ;
    if (result == 0) {
        assert(src != NULL) ;
        copied = dstSize < srcSize ? dstSize : srcSize ;
        memcpy(dst, src, copied) ;
    }

    return copied ;
}
----

==== Updating Attributes

[source,c]
----
<<mrt external interfaces>>=
extern int
mrt_PortalUpdateAttr(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_InstId instId,
    MRT_AttrId attrId,
    void const *src,
    MRT_AttrSize srcSize) ;
----

`portal`::
    A pointer to the portal structure for the domain.
`classId`::
    The number of the class. This number is generated by micca and placed in
    the domain header file.
`instId`::
    The number of the instance. Instance numbers are consecutive non-negative
    integers up to the maximum number of instances defined for the class.
`attrId`::
    The number of the attribute to be updated.
    This number is generated by micca and placed in the domain header file.
`src`::
    A pointer to memory from where the attribute value is taken.
`srcSize`::
    The number of bytes pointed to by `src`.

`mrt_PortalUpdateAttr` updates an attribute value in a domain.
If the return value is non-negative,
then it represents the actual number of bytes copied into the attribute
storage location.
Negative numbers indicate an error occurred.

[source,c]
----
<<mrt external functions>>=
int
mrt_PortalUpdateAttr(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_InstId instId,
    MRT_AttrId attrId,
    void const *src,
    MRT_AttrSize srcSize)
{
    assert(src != NULL) ;

    void *dst ;
    MRT_AttrSize dstSize = 0 ;
    int copied = 0 ;

    int result = mrt_PortalGetAttrRef(portal, classId, instId, attrId, &dst,
            &dstSize) ;
    if (result == 0) {
        assert(dst != NULL) ;
        MRT_Class const *class = portal->classes + classId ;
        copied = dstSize < srcSize ? dstSize : srcSize ;
        memcpy(dst, src, copied) ;
    }

    return copied ;
}
----

==== Signaling Events

[source,c]
----
<<mrt external interfaces>>=
extern int
mrt_PortalSignalEvent(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_InstId instId,
    MRT_EventType eventType,
    MRT_EventCode eventNumber,
    MRT_EventParams eventParameters) ;
----

`portal`::
    A pointer to the portal structure for the domain.
`classId`::
    The number of the class. This number is generated by micca and placed in
    the domain header file.
`instId`::
    The number of the instance. Instance numbers are consecutive non-negative
    integers up to the maximum number of instances defined for the class.
`eventType`::
    The type of the event to generate. This should be either
    `mrtTransitionEvent` or `mrtPolymorphicEvent`. Creation events are
    not signaled by this function.
`eventNumber`::
    The event number of the event to signal.
`eventParameters`::
    A pointer to the supplemental event parameters. This may be set to `NULL`
    if there are not parameters for the event.

`mrt_PortalSignalEvent` signals an ordinary or polymorphic event to the given
instance.
The return value is 0 upon success.
Negative numbers indicate an error occurred.

[source,c]
----
<<mrt external functions>>=
int
mrt_PortalSignalEvent(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_InstId instId,
    MRT_EventType eventType,
    MRT_EventCode eventNumber,
    MRT_EventParams eventParameters)
{
    int result ;
    MRT_Ecb *ecb ;

    result = mrtPortalNewECB(portal, classId, instId, eventType, eventNumber,
            eventParameters, &ecb) ;
    if (result == 0) {
        mrt_PostEvent(ecb) ;
    }

    return result ;
}
----

[source,c]
----
<<mrt static functions>>=
int
mrtPortalNewECB(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_InstId instId,
    MRT_EventType eventType,
    MRT_EventCode eventNumber,
    MRT_EventParams eventParameters,
    MRT_Ecb **ecbRef)
{
    int result ;
    MRT_Instance *instref ;

    result = mrtPortalGetInstRef(portal, classId, instId, &instref) ;
    if (result == 0) {
        if (instref->alloc > 0) {
            MRT_Class const *classDesc = portal->classes + classId ;
            MRT_Ecb *ecb = NULL ;
            MRT_DispatchCount eventCount ;

            if (eventType == mrtTransitionEvent) {
                if (classDesc->edb != NULL) {
                    eventCount = classDesc->edb->eventCount ;
                } else {
                    return MICCA_PORTAL_NO_SUCH_EVENT ;
                }
            } else if (eventType == mrtPolymorphicEvent) {
                if (classDesc->pdb != NULL) {
                    eventCount = classDesc->pdb->eventCount ;
                } else {
                    return MICCA_PORTAL_NO_SUCH_EVENT ;
                }
            } else {
                return MICCA_PORTAL_BAD_EVENT_TYPE ;
            }

            if (eventNumber < eventCount) {
                ecb = mrt_NewEvent(eventNumber, eventType, instref, NULL) ;
                if (eventParameters) {
                    memcpy(ecb->eventParameters, eventParameters,
                        sizeof(ecb->eventParameters)) ;
                }
                if (ecbRef) {
                    *ecbRef = ecb ;
                }
                result = 0 ;
            } else {
                result = MICCA_PORTAL_NO_SUCH_EVENT ;
            }
        } else {
            result = MICCA_PORTAL_UNALLOC ;
        }
    }

    return result ;
}
----

[source,c]
----
<<mrt external interfaces>>=
extern int
mrt_PortalSignalDelayedEvent(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_InstId instId,
    MRT_EventType eventType,
    MRT_EventCode eventNumber,
    MRT_EventParams eventParameters,
    MRT_DelayTime delay) ;
----

[source,c]
----
<<mrt external functions>>=
int
mrt_PortalSignalDelayedEvent(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_InstId instId,
    MRT_EventType eventType,
    MRT_EventCode eventNumber,
    MRT_EventParams eventParameters,
    MRT_DelayTime delay)
{
    int result ;
    MRT_Ecb *ecb ;

    result = mrtPortalNewECB(portal, classId, instId, eventType, eventNumber,
            eventParameters, &ecb) ;
    if (result == 0) {
        mrt_PostDelayedEvent(ecb, delay) ;
    }

    return result ;
}
----

[source,c]
----
<<mrt external interfaces>>=
extern int
mrt_PortalCancelDelayedEvent(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_InstId instId,
    MRT_EventCode eventNumber) ;
----

[source,c]
----
<<mrt external functions>>=
int
mrt_PortalCancelDelayedEvent(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_InstId instId,
    MRT_EventCode eventNumber)
{
    int result ;
    MRT_Instance *instref ;

    result = mrtPortalGetInstRef(portal, classId, instId, &instref) ;
    if (result == 0) {
        mrt_CancelDelayedEvent(eventNumber, instref, NULL) ;
    }

    return result ;
}
----

[source,c]
----
<<mrt external interfaces>>=
extern int
mrt_PortalRemainingDelayTime(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_InstId instId,
    MRT_EventCode eventNumber,
    MRT_DelayTime *delayRef) ;
----

[source,c]
----
<<mrt external functions>>=
int
mrt_PortalRemainingDelayTime(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_InstId instId,
    MRT_EventCode eventNumber,
    MRT_DelayTime *delayRef)
{
    int result ;
    MRT_Instance *instref ;

    result = mrtPortalGetInstRef(portal, classId, instId, &instref) ;
    if (result == 0) {
        MRT_DelayTime delay = mrt_RemainingDelayTime(eventNumber, instref, NULL) ;
        if (delayRef) {
            *delayRef = delay ;
        }
    }

    return result ;
}
----

[source,c]
----
<<mrt external interfaces>>=
extern int
mrt_PortalCreateInstance(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_StateCode initialState) ;
----

[source,c]
----
<<mrt external functions>>=
int
mrt_PortalCreateInstance(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_StateCode initialState)
{
    int result ;

    if (classId < portal->classCount) {
        MRT_Class const *class = portal->classes + classId ;
        if (class->containment == NULL) {
            MRT_Instance *inst = mrt_CreateInstance(class, initialState) ;
            assert(inst != NULL) ;
            MRT_iab *iab = class->iab ;
            assert(iab != NULL) ;
            assert(iab->storageStart != NULL) ;
            result = ((uintptr_t)inst - (uintptr_t)iab->storageStart) /
                    iab->instanceSize ;
        } else {
            result = MICCA_PORTAL_NO_DYNAMIC ;
        }
    }

    return result ;
}
----

[source,c]
----
<<mrt external interfaces>>=
extern int
mrt_PortalCreateAsync(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_EventCode eventNumber) ;
----

[source,c]
----
<<mrt external functions>>=
int
mrt_PortalCreateAsync(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_EventCode eventNumber)
{
    int result ;

    if (classId < portal->classCount) {
        MRT_Class const *class = portal->classes + classId ;
        if (class->containment == NULL) {
            MRT_Instance *inst = mrt_CreateAsync(class, eventNumber, NULL) ;
            assert(inst != NULL) ;
            MRT_iab *iab = class->iab ;
            assert(iab != NULL) ;
            assert(iab->storageStart != NULL) ;
            result = ((uintptr_t)inst - (uintptr_t)iab->storageStart) /
                    iab->instanceSize ;
        } else {
            result = MICCA_PORTAL_NO_DYNAMIC ;
        }
    }

    return result ;
}
----

[source,c]
----
<<mrt external interfaces>>=
extern int
mrt_PortalDeleteInstance(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_InstId instId) ;
----

[source,c]
----
<<mrt external functions>>=
int
mrt_PortalDeleteInstance(
    MRT_DomainPortal const *portal,
    MRT_ClassId classId,
    MRT_InstId instId)
{
    int result ;
    MRT_Instance *inst ;

    result = mrtPortalGetInstRef(portal, classId, instId, &inst) ;
    if (result == 0) {
        mrt_DeleteInstance(inst) ;
    }

    return result ;
}
----

== Asynchronous Execution

When the main loop was discussed,
we made a brief mention of asynchronous execution in the context
of executing synchronization functions.
It is now time to discuss how the mechanisms deal with asynchronous
execution.
First we discuss some background and then present the means used by
the mechanisms to synchronize the two execution contexts.

Until now, the discussion of data management and execution
sequencing have assumed that we have a single execution context.
However,
all modern computer architectures support the concept of an interrupt.
An interrupt signaled by some external hardware causes the processor
to stop executing and transfer control to a different section of code
so that immediate action can be taken on the cause of the interrupt.
After the external condition is handled,
execution can resume where it was interrupted.
The need for asynchronous execution was recognized early in computer
architecture design as interaction with the external environment is much
of what makes a computer a useful machine.

The exact details of how this happens is different for every computer
architecture.
Some computers offer very sophisticated schemes that include arbitrating
the priority of multiple competing interrupt sources.
Most offer only a single priority of interrupt processing or place the
burden of prioritization on the programmer or external hardware.
The `micca` run time is intended for highly embedded systems and,
in such systems, achieving the low execution overhead is of great value.
So the model of asynchronous execution used by the run time mirrors that which
is provided directly by the hardware architecture.
Techniques for having multiple, scheduled execution contexts are very
well known.
None of them is used here.
Here we are only interested in a very simple model of asynchronous execution
that closely mirrors what is provided by the computing hardware.
Amazingly, this is much less restrictive than might be first imagined.

Nesting interrupts is not forbidden, but is definitely not encouraged.
No restriction is put on what may happen at interrupt service.
This is usually a potential source of error in many systems.
Because the execution is asynchronous to domain model execution,
any access to the domain data structures from interrupt service
*must not* be attempted.
It is ultimately unsafe and results in horribly difficult to detect
timing windows being generated wherein things will mysteriously and
irreproducibly fail.

However, it is usually necessary for an interrupt to communicate
back to the domain models.
Usually, the interrupt signals some change of condition
in the environment that has been detected by the hardware.
The interrupt may be able to do everything required to handle the situation and
frequently additional computation is required to resolve what has happened.
So the mechanisms provide a way for an interrupt to request
synchronization with the running background.
This is accomplished by having the interrupt service code
perform a synchronization request.

[source,c]
----
<<mrt external interfaces>>=
extern MRT_SyncParams *mrt_SyncRequest(MRT_SyncFunc) ;
----

That request is in the form of a function with optional parameters
that is to be executed at the first `safe` opportunity.
As we saw before,
the synchronization functions are executed in between state actions
to insure that the domain data are in a coherent state.

The mechanisms provide a sync queue where interrupts may place
their requests for background synchronization execution.
We do this with a simple queue that is implemented in an array.
Like all resources in the mechanisms,
the storage required for the queue is fixed at compile time.

[source,c]
----
<<mrt constants>>=
#ifndef MRT_SYNCQUEUESIZE
#   define MRT_SYNCQUEUESIZE 10
#endif /* MRT_SYNCQUEUESIZE */
----

The number of queue entries can be sized appropriately for the system.
Generally, the number of queue slots must be sized to handle
any cluster of interrupts that go off at nearly the same time.

It is necessary to provide interrupts the ability to pass parameters
to the background sync functions.
This is often data that must be sampled coincident with the interrupt
in order to capture the correct external state.
To avoid problems with variable life times,
data is passed by copying it into a parameter area.
Clearly, this is not a good strategy for passing a large amount of
data.
In those cases, it is necessary to manage memory between the
background and the interrupts.
No facilities are provided by the mechanisms to do this as it usually
must to be constructed _ad hoc_ to suit the particular needs of the
data transfer.
Usually it is sufficient to manage a pool in the background and use
the synchronization mechanism to allow interrupt service to return memory
to the pool when it is no longer needed.

The architypical example is communications buffers.
Background code can manage a buffer pool.
When outgoing messages are transmitted,
synchronization to the background can be used to return the buffer to
the pool.
Incoming messages can be placed in pre-queued buffers and when the message
is complete, synchronizing to the background pass buffer pointers
to be processed and returned to the pool.

For our purposes here, it is only necessary to define some data structure
that can be used by the interrupt service code to place data that
will be delivered to the background function.
The same considerations that were discussed for event
parameters apply for sync parameters.
So we use the same strategy.

[source,c]
----
<<mrt interface aggregate types>>=
typedef MRT_EventParams MRT_SyncParams ;
----

And so we can define the prototype for a sync function.

[source,c]
----
<<mrt interface aggregate types>>=
typedef void (*MRT_SyncFunc)(MRT_SyncParams const *) ;
----

Each element of the sync queue is a pointer to the sync function
and a place where the interrupt service code may place the values
of the parameters.

[source,c]
----
<<mrt implementation aggregate types>>=
typedef struct mrtsyncblock {
    MRT_SyncFunc function ;
    alignas(max_align_t) MRT_SyncParams params ;
} MRT_SyncBlock ;
----

The sync queue is stored in an array and we use a couple of
pointers to keep track of the head and tail.

[source,c]
----
<<mrt implementation aggregate types>>=
typedef struct mrtsyncqueue {
    MRT_SyncBlock *head ;
    MRT_SyncBlock *tail ;
} MRT_SyncQueue ;
----

Following our usual pattern,
we allocate storage for the sync queue entries as an array and
for the control structure that tracks the queue boundaries within
the sync queue entry array.

[source,c]
----
<<mrt static data>>=
static MRT_SyncBlock mrtSyncQueueStorage[MRT_SYNCQUEUESIZE] ;
static MRT_SyncQueue mrtSyncQueue = {
    .head = mrtSyncQueueStorage,
    .tail = mrtSyncQueueStorage,
} ;
----

There are only three operations on the sync queue.
First we must be able to determine if the queue is empty or not.
Emptiness is determined when the queue head is equal to the queue tail.
For this type of queue operation,
the head is where the next entry is removed and the tail is where the
next entry is inserted.

[source,c]
----
<<mrt forward references>>=
static inline bool mrtSyncQueueEmpty(void) ;
----

[source,c]
----
<<mrt static functions>>=
static inline
bool
mrtSyncQueueEmpty(void)
{
    return mrtSyncQueue.head == mrtSyncQueue.tail ;
}
----

Inserting a function into the synchronization queue is an activity
that may only be performed from interrupt service level.
*N.B.* that this function does *not* implement a critical section
around access to the sync queue.

[source,c]
----
<<mrt forward references>>=
static inline MRT_SyncParams *mrtSyncQueuePut(MRT_SyncFunc f, bool fatal) ;
----

[source,c]
----
<<mrt static functions>>=
static inline
MRT_SyncParams *
mrtSyncQueuePut(
    MRT_SyncFunc f,
    bool fatal)
{
    MRT_SyncBlock *tail = mrtSyncQueue.tail ;
    if (++mrtSyncQueue.tail >=
            mrtSyncQueueStorage + MRT_SYNCQUEUESIZE) {
        mrtSyncQueue.tail = mrtSyncQueueStorage ;
    }
    if (mrtSyncQueueEmpty()) {
        if (fatal) {
            mrtFatalError(mrtSyncOverflow) ;
        }
        return NULL ;
    }

    tail->function = f ;
    return &tail->params ;
}
----

Insertion happens at the tail.
Incrementing the tail pointer must account for wrapping around the array
boundary.
Overflow is detected as the queue being empty after the insertion is made.
This logic has the effect of consuming one of the queue storage slots 
in order to detect overflow and
this will need to be accounted for in sizing the sync queue storage.
The `fatal` argument determines if queue overflow is a fatal system error
or not.
This allow for dealing with sync requests that can be ignored if it would
cause a sync queue overflow.
Note that the sync queue slot is not modified until after
overflow is detected.
This insures that should an error happen during development,
the queue can be examined and will be in a consistent state.

The consumer of the sync queue entries is the main loop.

[source,c]
----
<<mrt forward references>>=
static inline MRT_SyncBlock *mrtSyncQueueGet(void) ;
----

[source,c]
----
<<mrt static functions>>=
static inline
MRT_SyncBlock *
mrtSyncQueueGet(void)
{
    MRT_SyncBlock *head ;

    beginCriticalSection() ;
    if (mrtSyncQueueEmpty()) {
        head = NULL ;
    } else {
        head = mrtSyncQueue.head ;
        if (++mrtSyncQueue.head >=
                mrtSyncQueueStorage + MRT_SYNCQUEUESIZE) {
            mrtSyncQueue.head = mrtSyncQueueStorage ;
        }
    }
    endCriticalSection() ;

    return head ;
}
----

Since the main loop runs with interrupts enabled,
obtaining a sync queue entry must be done in a critical section.
We remove entries from the head of the queue.
Otherwise, the only complexity in the code is to account for
the array storage wrap around.

=== Dispatching Synchronization Functions

The event loop we saw above performed the background synchronization
before dispatching a single event.
For most processor architectures,
that code appears as below:

[source,c]
----
<<EventLoop: background sync>>=
#   ifndef __ARM_ARCH_7M__
while (mrtInvokeOneSyncFunction()) {
    ; /* empty */
}
#   endif
----

We execute in a loop, invoking one sync function until there are no
more queued up.
It turns out we can do something a bit better for the ARM v7-M
architecture.
We will discuss that below when we consider the platform specific code.

[source,c]
----
<<mrt forward references>>=
static inline bool mrtInvokeOneSyncFunction(void) ;
----

Invoking a sync function is a simple matter of pulling it off the
sync queue and passing a pointer to the parameters to it.
We return a value indicating if a function was called.

[source,c]
----
<<mrt static functions>>=
static inline
bool
mrtInvokeOneSyncFunction(void)
{
    bool didOne ;

    MRT_SyncBlock const *blk = mrtSyncQueueGet() ;
    if (blk != NULL && blk->function != NULL) {
        blk->function(&blk->params) ;
        didOne = true ;
    } else {
        didOne = false ;
    }

    return didOne ;
}
----

For the ARM v7-M processor,
we can execute the sync functions in a service handler and then there
is no burden to the event loop to constantly test if any synchronization
need to be performed.
The process will handle vectoring to this code when necessary.

[source,c]
----
<<ARM 7M components>>=
void
PendSV_Handler(void)
{
    for (MRT_SyncBlock *blk = mrtSyncQueueGet() ; blk != NULL ;
            blk = mrtSyncQueueGet()) {
        if (blk->function) {
            blk->function(&blk->params) ;
        }
    }
}
----

== Event Dispatch Tracing

Debugging event driven, callback, state machine based applications can be
rather more complicated than conventional, linear flow code.
When class instances generate events to other instances and it can
be hard to determine the exact sequence of execution by simply
examining the source code.
Indeed, part of the intent here is to factor away from the application
the details of sequencing execution.
Setting a breakpoint in the action of a state is easy enough,
the difficulties arise when trying to determine where to set a breakpoint
to catch the results of the next event dispatch.
Given that many events will be flying around a given program,
it is very useful to be able to extract the set of event dispatches
in chronological order.

To help in debugging,
the run time can be conditionally compiled to support tracing the event
dispatch.
After the code is properly compiled,
a pointer to a trace callback function may be registered and
then each event dispatched will result in the function being called
with the information about the dispatch.

It should be noted that dealing with trace information can be
very difficult.
For small embedded systems,
there may not be sufficient space to store the strings that give
names to states and events (the `MRT_NO_NAMES` macro can be defined
to remove the string information).
This means that only numbers are available to the tracing code
and there is substantial effort required to back
translate the numbers into strings that are meaningful to a human.

Because tracing also affects the performance of the run time code,
it may also be excluded by defining the `MRT_NO_TRACE` macro.


=== Trace Information

Since there are three types of events,
there are three distinct sets of information generated when
an event is dispatched.
There is information common to all events and information
specific to each event type.

[source,c]
----
<<mrt trace aggregate types>>=
typedef struct mrttraceinfo {
    MRT_EventType eventType ;
    MRT_EventCode eventNumber ;
    MRT_Instance *sourceInst ;
    MRT_Instance *targetInst ;
    union {
        struct transitiontrace {
            MRT_StateCode currentState ;
            MRT_StateCode newState ;
        } transitionTrace ;
        struct polytrace {
            MRT_SubclassCode subcode ;
            MRT_DispatchCount genNumber ;
            MRT_EventCode mappedEvent ;
            MRT_EventType mappedType ;
        } polyTrace ;
        struct creationtrace {
            MRT_Class const *targetClass ;
        } creationTrace ;
    } info ;
} MRT_TraceInfo ;
----

Data common to all event dispatch traces.

`eventType`::
    The type of the event that was dispatched.
`eventNumber`::
    The number of the event that was dispatched.
`sourceInst`::
    A pointer to the instance that was the source of the dispatched event.
`targetInst`::
    A pointer to the instance that was the target of the dispatched event.

`transitionTrace`::
    Data for transition event dispatch traces.
`currentState`:::
    The current state of the instance before the event dispatch.
`newState`:::
    The new state entered as a result of the transition.

`polyTrace`::
    Data for polymorphic event dispatch traces.
`subcode`:::
    The subclass code of the currently related instance.
`genNumber`:::
    The number of the generalization down which the event was dispatched.
`mappedNumber`:::
    The new event number to which the polymorphic event mapped.
`mappedType`:::
    The new event type corresponding to `mappedNumber`.

`creationTrace`::
    Data for creation event dispatch traces.
`targetClass`:::
    A pointer to the class structure for the target of the
    creation event.

=== Access to Trace Information

Event tracing information is passed out of the run time by
having the application register a callback function.
That function takes a pointer to the trace information as its
argument.

[source,c]
----
<<mrt trace aggregate types>>=
typedef void (*MRT_TraceHandler)(MRT_TraceInfo const *) ;
----

The function is registered with the mechanisms by invoking:

[source,c]
----
<<mrt trace external interfaces>>=
extern MRT_TraceHandler mrt_RegisterTraceHandler(MRT_TraceHandler) ;
----

The trace callback function is supplied as the argument and the
previous value of the callback is returned.
Tracing can be turned off by invoking `mrt_RegisterTraceHandler` with `NULL`.

[source,c]
----
<<mrt trace static data>>=
static MRT_TraceHandler mrtTraceHandler ;
----

[source,c]
----
<<mrt trace external functions>>=
MRT_TraceHandler
mrt_RegisterTraceHandler(
    MRT_TraceHandler handler)
{
    MRT_TraceHandler oldhandler = mrtTraceHandler ;
    mrtTraceHandler = handler ;
    return oldhandler ;
}
----

The implementation of registering a handler is simply to record the
function pointer in a variable.

For each type of event dispatch,
the mechanisms call a specific function to determine if tracing
is enabled and to marshal the trace information into the proper
data structure.

[source,c]
----
<<mrt trace static functions>>=
static inline 
void
mrtTraceTransitionEvent(
    MRT_EventCode event,
    MRT_Instance *source,
    MRT_Instance *target,
    MRT_StateCode currentState,
    MRT_StateCode newState)
{
    if (mrtTraceHandler) {
        MRT_TraceInfo trace ;

        trace.eventType = mrtTransitionEvent ;
        trace.eventNumber = event ;
        trace.sourceInst = source ;
        trace.targetInst = target ;
        trace.info.transitionTrace.currentState = currentState ;
        trace.info.transitionTrace.newState = newState ;

        mrtTraceHandler(&trace) ;
    }
}
----

[source,c]
----
<<mrt trace static functions>>=
static inline 
void
mrtTracePolyEvent(
    MRT_EventCode event,
    MRT_Instance *source,
    MRT_Instance *target,
    MRT_SubclassCode subclass,
    MRT_DispatchCount genNumber,
    MRT_EventCode newEvent,
    MRT_EventType newEventType)
{
    if (mrtTraceHandler) {
        MRT_TraceInfo trace ;

        trace.eventType = mrtPolymorphicEvent ;
        trace.eventNumber = event ;
        trace.sourceInst = source ;
        trace.targetInst = target ;
        trace.info.polyTrace.subcode = subclass ;
        trace.info.polyTrace.genNumber = genNumber ;
        trace.info.polyTrace.mappedEvent = newEvent ;
        trace.info.polyTrace.mappedType = newEventType ;

        mrtTraceHandler(&trace) ;
    }
}
----

[source,c]
----
<<mrt trace static functions>>=
static inline 
void
mrtTraceCreationEvent(
    MRT_EventCode event,
    MRT_Instance *source,
    MRT_Instance *target,
    MRT_Class const *class)
{
    if (mrtTraceHandler) {
        MRT_TraceInfo trace ;

        trace.eventType = mrtCreationEvent ;
        trace.eventNumber = event ;
        trace.sourceInst = source ;
        trace.targetInst = target ;
        trace.info.creationTrace.targetClass = class ;

        mrtTraceHandler(&trace) ;
    }
}
----

=== Tracing Strategies

Clearly,
tracing can generate data at a rather high rate and can be
rather intrusive upon the execution of the system.
Several strategies may be used to deal with the trace data.
If possible,
all the trace data can be dumped in a raw form out a communications
interface and let some other program decode and display it.
That may still be too intrusive and sometimes it is best to
filter the trace data based on the target instance pointer value.
In this way you may trace the event dispatches on only a subset of
instances.
Several different filtering schemes, such as source instance or classes,
can be envisioned.

Another possibility is to store trace information in a memory
area in some sort of circular queue arrangement.
Then it is possible for the application to start and stop such tracing
and achieve ``logic analyzer'' type triggering functionality.
The trace information can then be extracted from memory and analyzed.

When running in a POSIX environment,
one can assume reasonable I/O facilities.
The POSIX version of the run time includes default trace handling to
timestamp and print the trace data in human readable form.

You will also note that the trace information has no timing data associated
with it.
This type of data is so system specific that it is left to the
tracing callback to supply.
If you have a free running cycle counter in your system,
this can be a good indicator of relative time and the trace callback
function can add this to the data set supplied by the mechanisms.
Your system may also have source of clocked timing data that can also
be used as a timing reference.
In either case, augmenting the trace data with some sort of relative
time information is very valuable.

Tracing can also be used as a framework for testing.
If a domain is built to run in a testing framework where tracing is enabled,
then recording all the trace information allows one to determine
the amount of \emph{transition} coverage a test set causes.
The goal is to develop test sets that
drive the domain by invoking the domain interface functions with
appropriate data so that all state transitions are taken.
Tracing allows the recording of what transitions a given thread of control
causes.
Since in most well designed state machines,
state action code is small and does not contain complicated or intricate
internal program flow,
causing all state actions to be executed is often close to complete
statement coverage.
As an added benefit,
state machines can be considered as directed graphs.
A depth first traversal of a directed graph can be be used to determine
a spanning tree for the graph.
Traversing a spanning tree for a graph insures that all nodes in the graph
are visited and the event sequence given by the spanning tree
can guide the generation of test set data and can help to minimize the
number of test cases required to ensure adequate coverage.

== Error Handling

Until now we have glossed over the subject of how to handle errors
in the `micca` run time.
In XUML,
the domains assume a perfect architecture in the sense that
no formal mechanism is provided to signal architectural errors back to
the application domains.
This makes sense because the application models are meant to be implementation
independent and able to be run on a variety of underlying platforms.
However,
an error policy, in much the same terms as data and execution policies,
must be put into place.
The details of the error handling policy will vary between
software architectures, so it is important to state them clearly.
For the `micca` run time, the following principles guide error handling.

* To that extent possible, the mechanisms operations should not report
errors back to the application.
For implementation languages that do not support exception handling,
the usual technique of returning error codes is not very effective.
Either by accident or sloth, many error codes are not checked.
Even then the error code is checked, there is little recovery
recourse for the application.
For example,
it does little good to know that we are unable to generate an
event because we do not have sufficient ECB resources when there
is nothing a state action can do to free up the required resources.
* Errors that result from exhausted resources or analysis errors
detected at run time are *fatal*.
Exactly how fatal errors are acted upon is platform dependent and may
result in terminating a program or completely resetting the system.
Regardless of the consequence of a fatal error, the assumption is
that the program can no longer continue to run.

With these principles in mind, we define a set of error conditions
that are detected by the mechanism.
All these conditions are fatal and are handled by invoking a fatal
error handler.

[source,c]
----
<<mrt interface simple types>>=
typedef enum {
    mrtCantHappen = 1,
    mrtEventInFlight,
    mrtNoECB,
    mrtNoInstSlot,
    mrtSyncOverflow,
    mrtRefIntegrity,
    mrtTransOverflow,
    mrtConstRelationship,
    mrtRelationshipLinkage,

#       ifdef _POSIX_C_SOURCE
    mrtTimerOpFailed,
    mrtSignalOpFailed,
    mrtSelectWaitFailed,
#       endif /* _POSIX_C_SOURCE */
} MRT_ErrorCode ;
----

We will need a string representation of the error codes to
make human readable messages.

[source,c]
----
<<mrt static data>>=
static char const * const errMsgs[] = {
    [0] = "no error",     /* place holder */
    [mrtNoECB] = "no available Event Control Blocks\n",
    [mrtSyncOverflow] = "synchronization queue overflow\n",
    [mrtRefIntegrity] = "referential integrity check failed\n",
    [mrtTransOverflow] = "transaction markings overflow\n",
    [mrtConstRelationship] = "attempt to modify constant relationship",
    [mrtRelationshipLinkage] = "attempt to link non-participant",

#       ifndef MRT_NO_NAMES
    [mrtCantHappen] = "can't happen transition: %s.%s: %s - %s -> CH\n",
    [mrtEventInFlight] = "event in flight error: %s.%s - %s -> %s.%s\n",
    [mrtNoInstSlot] = "no available instance slots: %s\n",
#       else
    [mrtCantHappen] = "can't happen transition: %p: %u - %u -> CH\n",
    [mrtEventInFlight] = "event in flight error: %p - %u -> %p\n",
    [mrtNoInstSlot] = "no available instance slots: %p\n",
#       endif /* MRT_NO_NAMES */

#       ifdef _POSIX_C_SOURCE
    [mrtTimerOpFailed] = "interval timer operation failed: %s\n",
    [mrtSignalOpFailed] = "signal operation failed: %s\n",
    [mrtSelectWaitFailed] = "blocking on pselect() failed: %s\n",
#       endif /* _POSIX_C_SOURCE */
} ;
----

Everywhere else the mechanisms operations have been crafted to
avoid error possibilities.
For example, as discussed in delayed event generation,
we interpret the attempt to generate a duplicate delayed event
as wishing to cancel the existing one and instantiate a new one.
This semantic interpretation avoids generating an error and avoids
all the additional code require in state actions that generate
delayed events.

Exactly how fatal errors are handled will depend upon the specifics
of how the platform handles errors.
We define an interface for a fatal error handler.

[source,c]
----
<<mrt interface aggregate types>>=
typedef void (*MRT_FatalErrHandler)(MRT_ErrorCode, char const *, va_list) ;
----

The interface is patterned after `vprintf`,
giving a format string and a pointer to a variable length argument list.

[source,c]
----
<<mrt forward references>>=
static void
mrtDefaultFatalErrorHandler(
    MRT_ErrorCode errNum,
    char const *fmt,
    va_list ap) ;
----

The system provides a default fatal error handler.
Assuming that standard I/O is included, we print a message to the
standard error.

[source,c]
----
<<mrt static functions>>=
static void
mrtDefaultFatalErrorHandler(
    MRT_ErrorCode errNum,
    char const *fmt,
    va_list ap)
{
    vfprintf(stderr, errMsgs[errNum], ap) ;
}
----

A pointer to the fatal error handler is initialized with the default one.

[source,c]
----
<<mrt static data>>=
static MRT_FatalErrHandler mrtErrHandler = mrtDefaultFatalErrorHandler ;
----

Because fatal error handling is usually so platform specific and
because of the need to test fatal error paths,
we provide the ability to delegate the consequence of the
fatal error.

[source,c]
----
<<mrt external interfaces>>=
extern MRT_FatalErrHandler
mrt_SetFatalErrHandler(
    MRT_FatalErrHandler newHandler) ;
----

[source,c]
----
<<mrt external functions>>=
MRT_FatalErrHandler
mrt_SetFatalErrHandler(
    MRT_FatalErrHandler newHandler)
{
    MRT_FatalErrHandler prevHandler = mrtErrHandler ;
    if (newHandler) {
        mrtErrHandler = newHandler ;
    }
    return prevHandler ;
}
----

The mechanisms internally call `mrtFatalError`.
This function is presented next.

[source,c]
----
<<mrt forward references>>=
static void mrtFatalError(MRT_ErrorCode errNum, ...) ;
----

[source,c]
----
<<mrt static functions>>=
static void
mrtFatalError(
    MRT_ErrorCode errNum,
    ...)
{
    va_list ap ;
    /*
     * All hope is lost here. Make sure we don't
     * execute any asynchronous code.
     */
    beginCriticalSection() ;

    assert(mrtErrHandler != NULL) ;
    assert(errNum < COUNTOF(errMsgs)) ;

    va_start(ap, errNum) ;
    mrtErrHandler(errNum, errMsgs[errNum], ap) ;
    /*
     *  If the handler does return, we insist that all errors
     *  are fatal. So we abort().
     */
    abort() ;
}
----

As we see in the code,
we insist that there is an error handler.
There is always the default one and a different handler can be specified
if necessary.
Finally,
`abort()` is called should the error handler return.

== Avoiding Fatalities

In this error handling strategy,
every mechanism detected error is fatal.
Although the details of the processing for fatal errors can be delegated,
in most systems of the class we consider here,
fatal errors usually result in a system reset.
Under the vast majority of circumstances,
that is the desired behavior.
However,
there are some particular circumstances where causing a fatal
error is not the desired behavior.

Consider the case where some external stimulus results in an event
being generated.
If the stimulus occurs more frequently than events can be processed,
then the mechanisms will run out of event control blocks causing a
fatal error.
As an example,
consider the arrival of a communications packet.
If somewhere during the processing of the packet an event is generated,
then if packets arrive too fast a fatal error can be generated.
In effect it would provide a means for an external stimulus to cause the
system to crash.
Certainly for the case of a communications packet,
the preferred behavior would be to drop the packet and let higher level
protocol deal with the necessary retries, etc.
It is then necessary to be able to determine if generating an event
would be successful.

In this section we describe functions that can be used to avoid mechanisms
requests that would exhaust an underlying resource and therefore
cause a fatal system error.
It should be emphasized that these functions are *not*
intended for ordinary or casual use.
Under the vast majority of circumstances,
such as when one state machine generates an event to another state
machine,
event generation and other such activities should continue to assume
that there are no resources that can be consumed.
System analysis and testing should then determine the appropriate sizing
for the various resource pools.
The capability described in this section is to handle unusual and
extraordinary circumstances where hardware failure or failure to
abide by communications protocols could force the system into a
fatal error situation.

Note also that the alternative provided here causes the external stimulus
that would cause the fatal error condition effectively to be ignored.
For some system requirements that is not an acceptable solution.
For example,
consider a digital input line that is used to generate an interrupt
and that interrupt signals an external condition monitored by hardware,
say the maximum extent of motion of physical robot arm.
If this interrupt arrives at a very fast rate,
one might conclude the hardware has failed.
Ignoring the interrupt might do little other than mask a problem that should
cause a fatal error condition and potentially reset the system.
The conclusion is that providing a means of avoiding fatal error conditions
is not intented to serve as an overall error handling policy.
Careful analysis and consideration is still required.
If an interrupt arrives faster than expected and,
because of what the interrupt represents, it cannot be ignored,
that fact and the response to it must be deduced by the interrupt service
code (_e.g._ by determining the interrupt frequency) and actions
appropriate to the system must be taken.
It can be a difficult problem to solve and the functions provided here
are too generic to be used indescrimately.

There are three internal mechanisms resources that can be exhausted.

* Class instances can be dynamically created and each class has its own instance
pool.
* Event control blocks are used for generating and dispatching state machine
events.
* The foreground / background synchronization queue has a fixed number
of slots and excessive synchronization requests from interrupt service
routines can fill the queue.

=== Checking for Available Instance Space

The `mrt_InstanceAvailable()` function provides a means determine if there
is space available to create a new instance of a class.

(((micca,Run Time,mrt_InstanceAvailable)))
[source,c]
----
<<mrt external interfaces>>=
extern bool
mrt_InstanceAvailable(
    MRT_Class const *classDesc) ;
----

`classDesc`::
    A pointer to the class data for which the space check is made.

`mrt_InstanceAvailable` returns `true` if there at least one instance
of `classDesc` may be created without exhausting the memory pool
of instances for the class.

[source,c]
----
<<mrt external functions>>=
bool
mrt_InstanceAvailable(
    MRT_Class const *classDesc)
{
    assert(classDesc != NULL) ;

    /*
     * Search for an empty slot in the pool.
     */
    return mrtInstFindSlot(classDesc) != NULL ;
}
----

=== Checking for Event Blocks

[source,c]
----
<<mrt external interfaces>>=
extern bool
mrt_EventAvailable(void) ;
----

[source,c]
----
<<mrt external functions>>=
bool
mrt_EventAvailable(void)
{
    return !mrtEventQueueEmpty(&freeEventQueue) ;
}
----

=== Non-Fatal Background Synchronization

[source,c]
----
<<mrt external interfaces>>=
MRT_SyncParams *
mrt_TrySyncRequest(
    MRT_SyncFunc f) ;
----

== POSIX Specific Code

At this point we have reached the end of the generic
code and must now begin to account for the platform differences
in the way timing and asynchronous execution is handled.
This software architecture can be run on a conventional POSIX platform.
This includes Linux, Mac OS X and even Cygwin.
The primary purpose of making the mechanisms run in a POSIX environment
is simulation.
Often, a domain can be executed for testing and simulation purposes on
a conventional computer more easily than in the target environment.
With I/O and disk storage, testing and tracing logic is often much easier.

[source,c]
----
<<posix includes>>=
#include <signal.h>
#include <errno.h>
#include <sys/select.h>
#include <sys/time.h>
#include <time.h>
----

=== POSIX Critical Sections

We start with a discussion of how to implement a critical section
in POSIX.
In POSIX,
the `signal` is the mechanism of asynchronous execution.
There are times when we must insure that execution is _not_
interrupted by asynchronous signal execution.
The functions in this section accomplish that.

The technique here is to maintain a signal mask of all the signals
that are under control of the mechanisms.
This signal mask can then be used to control signal execution as necessary.
Note that an application can call low level signal handling primitives
and manage subsets of signals outside of the mechanisms.
This is definitely discouraged.

[source,c]
----
<<posix static data>>=
static sigset_t mrtSigMask ;
----

It is necessary to initialize our managed signal mask to be empty.

[source,c]
----
<<posix static functions>>=
static inline
void
initCriticalSection(void)
{
    sigemptyset(&mrtSigMask) ;
}
----

Starting a critical section just means that we must block all the managed
signals.

[source,c]
----
<<posix static functions>>=
static inline
void
beginCriticalSection(void)
{
    if (sigprocmask(SIG_BLOCK, &mrtSigMask, NULL) != 0) {
        mrtFatalError(mrtSignalOpFailed, strerror(errno)) ;
    }
}
----

The end of a critical section is equally easily accomplished by unblocking
the managed signals.

[source,c]
----
<<posix static functions>>=
static inline
void
endCriticalSection(void)
{
    if (sigprocmask(SIG_UNBLOCK, &mrtSigMask, NULL) != 0) {
        mrtFatalError(mrtSignalOpFailed, strerror(errno)) ;
    }
}
----

=== POSIX Timing Interfaces

In this section we present the timing interface for POSIX systems.
In this timing scheme,
the interval timer that measures real time
is used and notifications of elapsed time arrive via SIGALRM.

In an embedded system,
time is usually measured in units of clock ticks,
where the amount of real time represented by a clock tick will vary
from system to system.
It is useful then to run the delayed event queue in hardware device
units rather than a conventional time measure so that we may avoid
the conversion computation each time the delayed event queue timing
is started or stopped.

So, we introduce a couple of functions to convert between clock ticks
and milliseconds and _vice versa_.
Since the POSIX interface operates at a higher level, in the POSIX
case there is no transformation.
Note that there is a bit of data type slight of hand going on here.
We use the `MRT_DelayTime` type to hold values of milliseconds
and clock ticks.
In practice this is not a problem, but the type will have to be
chosen to account for the largest values held either of the uses
of the data type.

[source,c]
----
<<posix static functions>>=
static inline
MRT_DelayTime
mrtMsecToTicks(
    MRT_DelayTime msec)
{
    return msec ;
}
----

[source,c]
----
<<posix static functions>>=
static inline
MRT_DelayTime
mrtTicksToMsec(
    MRT_DelayTime ticks)
{
    return ticks ;
}
----

[source,c]
----
<<posix static functions>>=
static void
mrtSysTimerMask(void)
{
    /*
     * Make sure SIGALRM does not go off.
     */
    sigset_t mask ;
    sigemptyset(&mask) ;
    sigaddset(&mask, SIGALRM) ;
    if (sigprocmask(SIG_BLOCK, &mask, NULL) != 0) {
        mrtFatalError(mrtSignalOpFailed, strerror(errno)) ;
    }
}
----

[source,c]
----
<<posix static functions>>=
static void
mrtSysTimerUnmask(void)
{
    /*
     * Allow SIGALRM to notify us.
     */
    sigset_t mask ;
    sigemptyset(&mask) ;
    sigaddset(&mask, SIGALRM) ;
    if (sigprocmask(SIG_UNBLOCK, &mask, NULL) != 0) {
        mrtFatalError(mrtSignalOpFailed, strerror(errno)) ;
    }
}
----

To start a timer we supply the number of ticks we want to expire
before we are notified.

[source,c]
----
<<posix static functions>>=
static void
mrtSysTimerStart(
    MRT_DelayTime time)
{
    struct itimerval delayedEventTimer ;

    delayedEventTimer.it_interval.tv_sec = 0 ;
    delayedEventTimer.it_interval.tv_usec = 0 ;
    delayedEventTimer.it_value.tv_sec = time / 1000 ;
    delayedEventTimer.it_value.tv_usec = (time % 1000) * 1000 ;

    if (setitimer(ITIMER_REAL, &delayedEventTimer, NULL) != 0) {
        mrtFatalError(mrtTimerOpFailed, strerror(errno)) ;
    }
    mrtSysTimerUnmask() ;
}
----

The code initializes the *real* interval timer to use in servicing the
delayed event queue.
We set the `it_interval` member,
which represents the next value to be loaded into the timer,
to 0.
Then when the time given by the `it_value` member
expires the timer is stopped.
The system timer is specified in microseconds and our time value is in
milliseconds,
so some conversion must be performed.
Upon expiration, SIGALRM is generated.
Notice that we exit the function with SIGALRM unblocked.

Stopping the timer returns the amount of time that had not elapsed.

[source,c]
----
<<posix static functions>>=
static MRT_DelayTime
mrtSysTimerStop(void)
{
    mrtSysTimerMask() ;
    /*
     * Fetch the remaining time.
     */
    struct itimerval delayedEventTimer ;
    if (getitimer(ITIMER_REAL, &delayedEventTimer) != 0) {
        mrtFatalError(mrtTimerOpFailed, strerror(errno)) ;
    }
    /*
     * Convert the returned time into milliseconds.
     */
    MRT_DelayTime remain =
            delayedEventTimer.it_value.tv_sec * 1000 +
            delayedEventTimer.it_value.tv_usec / 1000 ;
    /*
     * Set the current timer value to zero to turn it off.
     */
    memset(&delayedEventTimer, 0, sizeof(delayedEventTimer)) ;
    if (setitimer(ITIMER_REAL, &delayedEventTimer, NULL) != 0) {
        mrtFatalError(mrtTimerOpFailed, strerror(errno)) ;
    }

    return remain ;
}
----

Stopping the timer must make sure that SIGALRM
does not expire during the process of getting things stopped.

Since the timing services use SIGALRM, the signal registration function
is used to insure that SIGALRM is serviced.

[source,c]
----
<<posix static functions>>=
static void
mrtSysTimerExpire(
    int signum)
{
    MRT_DelayTime nextTime = mrt_TimerExpireService() ;
    if (nextTime != 0) {
        mrtSysTimerStart(nextTime) ;
    }
}
----


[source,c]
----
<<posix static functions>>=
static void
mrtInitSysTimer(void)
{
    mrt_RegisterSignal(SIGALRM, mrtSysTimerExpire) ;
}
----

=== POSIX Async Execution Interface

The POSIX view of a process includes the notion of _signals_.
Signals are a form of asynchronous execution,
and reasonably correspond to the interrupts of a bare metal system.
As we have seen in the timer services above,
we can use signals to access a variety of services on a POSIX system.

In this section we fill out the asynchronous execution interfaces
using signals.
As we will see,
POSIX systems also require that you deal with their I/O interface in order to
properly handle execution sequencing.
For now, we present an interface that allows an application to
deal with the asynchronous aspects of signals.
As expected,
the interface allows an application to register a sync function
that will be executed at the first safe opportunity after the signal
has expired.

[source,c]
----
<<posix external functions>>=
MRT_SyncParams *
mrt_SyncRequest(
    MRT_SyncFunc f)
{
    return mrtSyncQueuePut(f, true) ;
}
----

The alternate interface is also easily implemented.

[source,c]
----
<<posix external functions>>=
MRT_SyncParams *
mrt_TrySyncRequest(
    MRT_SyncFunc f)
{
    return mrtSyncQueuePut(f, false) ;
}
----

Applications can register a signal function that will be
called ultimately be called after the signal triggers.

[source,c]
----
<<posix external interfaces>>=
typedef void (*MRT_SignalFunc)(int) ;

extern void
mrt_RegisterSignal(
    int sigNum,
    MRT_SignalFunc func) ;
----

The arguments are simply, `sigNum`, the number of the signal
being registered and `func`, a pointer to a sync function that will
be called.
If `func` is `NULL`, then the signal's behavior is reset
to its default behavior.

[source,c]
----
<<posix external functions>>=
void
mrt_RegisterSignal(
    int sigNum,
    MRT_SignalFunc func)
{
    assert(sigNum > 0) ;

    struct sigaction action ;
    if (func) {
        action.sa_handler = func ;
        sigaddset(&mrtSigMask, sigNum) ;
    } else {
        action.sa_handler = SIG_DFL ;
        sigdelset(&mrtSigMask, sigNum) ;
    }
    sigfillset(&action.sa_mask) ;
    action.sa_flags = 0 ;

    int sigresult = sigaction(sigNum, &action, NULL) ;
    if (sigresult != 0) {
        mrtFatalError(mrtSignalOpFailed, strerror(errno)) ;
    }
}
----

We set up signal handlers to run uninterrupted by other signals.
This is accomplished by filling the `sa_mask` member of the
`sigaction` structure.
This is simplifies keeping track of what is going on.

=== POSIX I/O Interface

On POSIX platforms,
the mechanisms must also supply services to handle I/O.
The reason for this is that there are two means of awakening a sleeping
process, receiving a signal and servicing a I/O file
descriptor.:footnote:[ There are other ways to integrate signals and I/O in
POSIX systems.  The use of a `pselect` based approach is a design decision.]
On bare metal systems,
I/O is frequently accomplished on an `ad hoc` basis
and the single mechanism of the sync queue is usually sufficient.
However, POSIX makes a distinction between signals and I/O operations on
file descriptors and an interface needs to be provided to deal with
servicing file descriptors that require attention.

We model this interface after the one for signals.
The idea is that a set of callback functions can be registered
on a file descriptor for reading, writing or an exception.
When the condition is satisfied the callback is invoked.
So we must define an I/O callback function as:

[source,c]
----
<<posix external interfaces>>=
typedef void (*MRT_FDServiceFunc)(int) ;
----

When the callback is invoked,
it is passed the value of the file descriptor that requires service.

The mechanisms provide two functions for I/O.
One registers the callbacks for a file descriptor and the other removes 
a file descriptor from consideration.

[source,c]
----
<<posix external interfaces>>=
extern void
mrt_RegisterFDService(
    int fd,
    MRT_FDServiceFunc readService,
    MRT_FDServiceFunc writeService,
    MRT_FDServiceFunc exceptService) ;
----

`fd`::
    A file descriptor as returned from `open`, `socket`
    or any other system calls that create file descriptors.
`readService`::
    A pointer to a callback function that will be registered for the file
    descriptor and invoked when the file descriptor is readable
    or `NULL` if no callback is registered.
`writeService`::
    A pointer to a callback function that will be registered for the file
    descriptor and invoked when the file descriptor is writable
    or `NULL` if no callback is registered.
`exceptService`::
    A pointer to a callback function that will be registered for the file
    descriptor and invoked when the file descriptor is in an exception
    condition or `NULL` if no callback is registered.
    In practice, exception conditions are used only for reading
    OOB (out of bands) data on a TCP socket.

The corresponding remove function has the following interface.

[source,c]
----
<<posix external interfaces>>=
extern void
mechRemoveFDService(
    int fd,
    bool rmRead,
    bool rmWrite,
    bool rmExcept) ;
----

`fd`::
    A file descriptor as returned from `open`, `socket`
    or any other system calls that create file descriptors.
`rmRead`::
    A boolean indicated whether or not the file descriptor should
    have its read callback unregistered.
`rmWrite`::
    A boolean indicated whether or not the file descriptor should
    have its write callback unregistered.
`rmExcept`::
    A boolean indicated whether or not the file descriptor should
    have its exception callback unregistered.

The implementation of these two functions requires some internal
data structures to track the file descriptor sets.
File descriptor sets are handed to `pselect` to indicate how a process
is to be awakened for I/O servicing.

To track the callback functions we need a data structure.

[source,c]
----
<<posix implementation aggregate types>>=
typedef struct mrtfdservicemap {
    bool set ;
    MRT_FDServiceFunc read ;
    MRT_FDServiceFunc write ;
    MRT_FDServiceFunc except ;
} MRT_FDServiceMap ;
----

`set`::
    A boolean indicating whether or not the entry is in use.
`read`::
    A pointer to the read callback registered for the file descriptor
    or `NULL` if no callback is registered.
`write`::
    A pointer to the write callback registered for the file descriptor
    or `NULL` if no callback is registered.
`except`::
    A pointer to the exception callback registered for the file descriptor
    or `NULL` if no callback is registered.

Following our familiar pattern,
we define an array of mapping entries that defines a pool for storing
the entries that map file descriptor state to callbacks.
This array is indexed by file descriptor value.

[source,c]
----
<<posix static data>>=
static struct mrtfdservicemap mrtFDServicePool[FD_SETSIZE] ;
----

The value of `FD_SETSIZE` is determined by the system and is the
maximum number of file descriptors that can be in a `fd_set` given
to `select`.

One complication of using `pselect` as a means of registering intent
on multiple file descriptors is that you must keep track of the largest
value of a file descriptor in the set handed to `pselect`.
This is an argument to `pselect` (and `select`).
Fortunately, UNIX file descriptors operate in a rather predictable manner.
Each process has file descriptors 0, 1, and 2 open when the process is
started.
Creating a new file descriptor (_e.g._ by opening a file) will allocate
the next largest unused file descriptor number.
This rule applies to the three file descriptors opened by default for a process.
So, for example, closing file descriptor 2 and then opening a new file
will result in file descriptor 2 being reused.
All this makes tracking the maximum file descriptor number relatively easy.
We only need a single integer variable.

[source,c]
----
<<posix static data>>=
static int mrtMaxFD = -1 ;
----

Since `mrtMaxFD` holds the maximum value of the file descriptors
that have been registered, the value -1 indicates that there are no
registered file descriptors.

We need variables to hold the three sets of file descriptors needed
by `pselect`.

[source,c]
----
<<posix static data>>=
static fd_set mrtReadFDS ;
static fd_set mrtWriteFDS ;
static fd_set mrtExceptFDS ;
----

Finally, we can talk about the implementation of the I/O registration
functions.

[source,c]
----
<<posix external functions>>=
void
mrt_RegisterFDService(
    int fd,
    MRT_FDServiceFunc readService,
    MRT_FDServiceFunc writeService,
    MRT_FDServiceFunc exceptService)
{
    assert(fd >= 0 && fd < FD_SETSIZE) ;
    MRT_FDServiceMap *fds = mrtFDServicePool + fd ;

    fds->read = readService ;
    if (readService) {
        FD_SET(fd, &mrtReadFDS) ;
        fds->set = true ;
    } else {
        FD_CLR(fd, &mrtReadFDS) ;
    }

    fds->write = writeService ;
    if (writeService) {
        FD_SET(fd, &mrtWriteFDS) ;
        fds->set = true ;
    } else {
        FD_CLR(fd, &mrtWriteFDS) ;
    }

    fds->except = exceptService ;
    if (exceptService) {
        FD_SET(fd, &mrtExceptFDS) ;
        fds->set = true ;
    } else {
        FD_CLR(fd, &mrtExceptFDS) ;
    }

    if (fds->read == NULL && fds->write == NULL && fds-> except == NULL) {
        if (fds->set && fd >= mrtMaxFD) {
            --mrtMaxFD ;
        }
        fds->set = false ;
    } else if (fds->set && fd > mrtMaxFD) {
        mrtMaxFD = fd ;
    }
}
----

The function simply tests the various callback functions and if
they are not `NULL`,
then the file descriptor is added to the appropriate set.
As written,
`mrt_RegisterFDService` may be used to modify file descriptors already
registered.
The last bit of logic is there in case `mrt_RegisterFDService` is used
to effectively remove the file descriptor by supplying three `NULL`
callback function pointers.
We must also account for the maximum file descriptor value that
has been registered.

Removing a file descriptor from consideration is also straight forward.

[source,c]
----
<<posix external functions>>=
void
mrt_RemoveFDService(
    int fd,
    bool rmRead,
    bool rmWrite,
    bool rmExcept)
{
    assert(fd >= 0 && fd < FD_SETSIZE) ;
    MRT_FDServiceMap *fds = mrtFDServicePool + fd ;

    if (rmRead) {
        fds->read = NULL ;
        FD_CLR(fd, &mrtReadFDS) ;
    }

    if (rmWrite) {
        fds->write = NULL ;
        FD_CLR(fd, &mrtWriteFDS) ;
    }

    if (rmExcept) {
        fds->except = NULL ;
        FD_CLR(fd, &mrtExceptFDS) ;
    }

    if (fds->read == NULL && fds->write == NULL && fds-> except == NULL &&
            fd >= mrtMaxFD) {
        mrtMaxFD = fd - 1 ;
    }
}
----

We also need something to initialize the file descriptor sets that we
are maintaining.

[source,c]
----
<<posix static functions>>=
static void
mrtInitFDService(void)
{
    FD_ZERO(&mrtReadFDS) ;
    FD_ZERO(&mrtWriteFDS) ;
    FD_ZERO(&mrtExceptFDS) ;
}
----

=== POSIX Suspending Execution

The main loop detects when there is nothing left to do and
suspends execution.
Here we present how that suspension happens for the POSIX version of the
mechanisms.

This design is based on using `pselect` to suspend a process until
either a signal occurs or a file descriptor requires service.
The `mechWait` function is called by the main loop when there is no
work currently to be done.
It is invoked inside of a critical section.
This is an important entry condition for `mechWait`.
In the POSIX case,
this means that `mechWait` must be invoked with all the registered
signals blocked.
We then use `pselect` to atomically enable all signals and block the process.

[source,c]
----
<<posix static functions>>=
static
void
mrtWait(void)
{
    beginCriticalSection() ;
    if (mrtSyncQueueEmpty()) {
        /*
         * Copy the file descriptor sets since "pselect" modifies them in place
         * upon return.
         */
        fd_set readfds ;
        memcpy(&readfds, &mrtReadFDS, sizeof(readfds)) ;
        fd_set writefds ;
        memcpy(&writefds, &mrtWriteFDS, sizeof(writefds)) ;
        fd_set exceptfds ;
        memcpy(&exceptfds, &mrtExceptFDS, sizeof(exceptfds)) ;
        /*
         * Allow all the signals during the select.
         */
        sigset_t mask ;
        sigemptyset(&mask) ;
        /*
         * "mrtMaxFD" holds the maximum value of any registered file
         * descriptor. We must add one to get the number of file descriptors
         * "pselect" is to consider.
         */
        int r = pselect(mrtMaxFD + 1, &readfds, &writefds,
                &exceptfds, NULL, &mask) ;
        if (r == -1) {
            if (errno != EINTR) {
                mrtFatalError(mrtSelectWaitFailed, strerror(errno)) ;
            }
            /*
             * Got a signal while waiting. We go back to the main loop on the
             * assumption that something has been placed in the sync queue.
             */
        } else {
            /*
             * Dispatch the service functions for the file descriptors.
             */
            MRT_FDServiceMap *s = mrtFDServicePool ;
            for (int fd = 0 ; r > 0 && fd <= mrtMaxFD ;
                    ++fd, ++s) {
                /*
                 * Do exceptions first. This is only important for sockets, but
                 * without going first the OOB data processing won't work.
                 */
                if (FD_ISSET(fd, &exceptfds)) {
                    assert(s->except != NULL) ;
                    s->except(fd) ;
                    --r ;
                }
                if (FD_ISSET(fd, &readfds)) {
                    assert(s->read != NULL) ;
                    s->read(fd) ;
                    --r ;
                }
                if (FD_ISSET(fd, &writefds)) {
                    assert(s->write != NULL) ;
                    s->write(fd) ;
                    --r ;
                }
            }
        }
    }
    endCriticalSection() ;
}
----

By far, most of the work in `mechWait` is to deal with the
file descriptor status changes.
The file descriptor sets
must be copied before being handed to `pselect` since it modifies
them in place.
After we determine that it was a file descriptor status change that
caused us to wake up,
we must go through and find all file descriptors that had a status
change and invoke the callback function.

The way that we are using `pselect` in this circumstance may seem
a bit backwards.
Upon entry to `mechWait`,
we start a critical section where
the registered signals are blocked.
The signal mask given to `pselect` is empty, meaning that `pselect`
will allow all signals while the process sleeps.
Upon the return from `pselect` we will be back to the state where
the registered signals are blocked.
Thus we avoid the race condition where
we have determined that the sync queue is empty, but
asynchronous execution that might affect the
sync queue arrives before we can put the process to sleep.
This is exactly the type of race condition `pselect` is used to prevent.

It is also worth noting we do _not_ use any time out in the
`pselect` invocation.
All timing is done via delayed events, and they are signalled via
`SIGALRM` and managed on the delayed event queue as discussed before.

=== POSIX Tracing

[source,c]
----
<<posix static functions>>=
#   ifndef MRT_NO_NAMES
static
void
mrtPrintTraceInfo(
    MRT_TraceInfo const *traceInfo)
{
    static char const * const eventTypeNames[] = {
        [mrtTransitionEvent] = "Transition",
        [mrtPolymorphicEvent] = "Polymorphic",
        [mrtCreationEvent] = "Creation"
    } ;

    char const *sourceName ;
    char const *sourceClassName ;

    if (traceInfo->sourceInst == NULL) {
        sourceName = "none" ;
        sourceClassName = "" ;
    } else {
        if (traceInfo->sourceInst->name == NULL) {
            sourceName = "unknown" ;
        } else {
            sourceName = traceInfo->sourceInst->name ;
        }
        sourceClassName = traceInfo->sourceInst->classDesc->name ;
    }
    
    char const *targetName = traceInfo->targetInst->name ?
            traceInfo->targetInst->name : "unknown" ;

    switch (traceInfo->eventType) {
    case mrtTransitionEvent:
        printf("%s: Transition: %s.%s - %s -> %s.%s: %s ==> %s\n",
            mrtTimestamp(), sourceClassName, sourceName,
            traceInfo->targetInst->classDesc->edb->eventNames[
                traceInfo->eventNumber],
            traceInfo->targetInst->classDesc->name, targetName,
            traceInfo->targetInst->classDesc->edb->stateNames[
                traceInfo->info.transitionTrace.currentState],
            traceInfo->targetInst->classDesc->edb->stateNames[
                traceInfo->info.transitionTrace.newState]) ;
        break ;

    case mrtPolymorphicEvent:
        printf("%s: Polymorphic: %s.%s - %s -> %s.%s: %s ==> %s(%u) %s\n",
            mrtTimestamp(), sourceClassName, sourceName,
            traceInfo->targetInst->classDesc->pdb->eventNames[
                traceInfo->eventNumber],
            traceInfo->targetInst->classDesc->name, targetName,
            traceInfo->targetInst->classDesc->pdb->genNames[
                traceInfo->info.polyTrace.genNumber],
            eventTypeNames[traceInfo->info.polyTrace.mappedType],
            traceInfo->info.polyTrace.mappedEvent,
            traceInfo->targetInst->classDesc->pdb->genDispatch[
                traceInfo->info.polyTrace.genNumber].subclassNames[
                traceInfo->info.polyTrace.subcode]) ;
        break ;

    case mrtCreationEvent:
        printf("%s: Creation: %s.%s - %s -> %s ==> %s\n",
            mrtTimestamp(), sourceClassName, sourceName,
            traceInfo->targetInst->classDesc->edb->eventNames[
                traceInfo->eventNumber],
            traceInfo->info.creationTrace.targetClass->name,
            targetName) ;
        break ;

    default:
        printf("%s: Unknown trace event type, \"%u\"",
                mrtTimestamp(), traceInfo->eventType) ;
        break ;
    }
}
#   else  /* MRT_NO_NAMES is defined */
static
void
mrtPrintTraceInfo(
    MRT_TraceInfo const *traceInfo)
{
    switch (traceInfo->eventType) {
    case mrtTransitionEvent:
        printf("%s: Transition: %p - %u -> %p: %u ==> %u\n",
                mrtTimestamp(), traceInfo->sourceInst, traceInfo->eventNumber,
                traceInfo->targetInst,
                traceInfo->info.transitionTrace.currentState,
                traceInfo->info.transitionTrace.newState) ;
        break ;

    case mrtPolymorphicEvent:
        printf("%s: Polymorphic: %p - %u -> %p: %u ==> %u(%u) %p\n",
                mrtTimestamp(), traceInfo->sourceInst, traceInfo->eventNumber,
                traceInfo->targetInst,traceInfo->info.polyTrace.genNumber,
                traceInfo->info.polyTrace.mappedType,
                traceInfo->info.polyTrace.mappedEvent,
                traceInfo->info.polyTrace.subcode) ;
        break ;

    case mrtCreationEvent:
        printf("%s: Creation: %p - %u -> %p ==> %p\n",
                mrtTimestamp(), traceInfo->sourceInst, traceInfo->eventNumber,
                traceInfo->info.creationTrace.targetClass,
                traceInfo->targetInst) ;
        break ;

    default:
        printf("%s: Unknown trace event type, \"%u\"",
                mrtTimestamp(), traceInfo->eventType) ;
        break ;
    }
}
#   endif /* MRT_NO_NAMES */
----

[source,c]
----
<<posix forward references>>=
static char const *mrtTimestamp(void) ;
----

[source,c]
----
<<posix static functions>>=
static
char const *
mrtTimestamp(void)
{
    static char timestamp[128] ;

    struct timeval now ;
    if (gettimeofday(&now, NULL) != 0) {
        return "unknown" ;
    }

    struct tm *ltime ;
    ltime = localtime(&now.tv_sec) ;
    if (ltime == NULL) {
        return strerror(errno) ;
    }

    int tlen = strftime(timestamp, sizeof(timestamp), "%FT%T", ltime) ;
    if (tlen == 0) {
        return strerror(errno) ;
    }

    int flen = snprintf(timestamp + tlen, sizeof(timestamp) - tlen,
            ".%03u.%03u", (unsigned)(now.tv_usec / 1000),
            (unsigned)(now.tv_usec % 1000)) ;
    if (flen > (sizeof(timestamp) - tlen)) {
        return "too big" ;
    }

    return timestamp ;
}
----

=== POSIX Initialization

Here we present the POSIX version of the required internal initialization.

[source,c]
----
<<posix external functions>>=
void
mrt_Initialize(void)
{
    mrtInitEventPool() ;
    mrtInitSysTimer() ;
    mrtInitFDService() ;
    mrt_RegisterTraceHandler(mrtPrintTraceInfo) ;
}
----

== Code Organization

[source,c]
----
<<micca_rt_posix.h>>=
/*
<<copyright info>>
*/

#ifndef MICCA_RT_H_
#define MICCA_RT_H_

/*
 * Standard Includes
 */
<<standard includes>>

/*
 * Constants
 */
<<mrt constants>>

/*
 * Data Types
 */
<<mrt interface simple types>>
<<mrt interface aggregate types>>

#   ifndef MRT_NO_TRACE
<<mrt trace aggregate types>>
#   endif /* MRT_NO_TRACE */

/*
 * Static Inline Functions
 */
<<mrt interface static inlines>>


/*
 * External Functions
 */
#   ifndef MRT_NO_TRACE
<<mrt trace external interfaces>>
#   endif /* MRT_NO_TRACE */

<<mrt external interfaces>>
<<posix external interfaces>>

#endif /* MICCA_RT_H_ */
----

[source,c]
----
<<standard includes>>=
#include <stdlib.h>
#include <stddef.h>
#include <stdint.h>
#include <stdbool.h>
#include <stdarg.h>
#include <stdio.h>
#include <stdalign.h>
----

[source,c]
----
<<common includes>>=
#include <string.h>
#include <assert.h>
#include "micca_rt.h"
----

[source,c]
----
<<common defines>>=
#ifndef COUNTOF
#define COUNTOF(a)  (sizeof(a) / sizeof(a[0]))
#endif /* COUNTOF */
----

[source,c]
----
<<micca_rt_arm7m.c>>=
/*
<<copyright info>>
*/

<<common includes>>
----

[source,c]
----
<<micca_rt_msp430.c>>=
/*
<<copyright info>>
*/

<<common includes>>
----

[source,c]
----
<<micca_rt_posix.c>>=
/*
<<copyright info>>
*/

<<common includes>>
<<posix includes>>
<<common defines>>

/*
 * Constants
 */
<<mrt implementation constants>>

/*
 * Data Types
 */
<<mrt implementation simple types>>
<<mrt implementation aggregate types>>
<<posix implementation aggregate types>>

/*
 * Forward References
 */
<<mrt forward references>>
<<posix forward references>>

/*
 * Static Data
 */
#   ifndef MRT_NO_TRACE
<<mrt trace static data>>
#   endif /* MRT_NO_TRACE */

<<mrt static data>>
<<posix static data>>

/*
 * Static Functions
 */
#   ifndef MRT_NO_TRACE
<<mrt trace static functions>>
#   endif /* MRT_NO_TRACE */

<<posix static functions>>
<<mrt static functions>>

/*
 * External Functions
 */
#   ifndef MRT_NO_TRACE
<<mrt trace external functions>>
#   endif /* MRT_NO_TRACE */

<<posix external functions>>
<<mrt external functions>>
----
