== Model marking

When a language compiler transforms source code into something that
is executable,
it typically is structured to analyze the code in a series of
phases on the path to producing something executable by a computer.
The techniques used are many and varied.
Some compilers produce machine specific assembly code or even skip
the assembly step and produce machine code directly.
Other compilers are targeted at virtual machines and produce code
that is then interpreted (or further compiled) at run time to
execute the program.
The many different approaches all have trade-offs,
yielding different characteristics,
that make them more or less suitable for a particular problem.

Most compilers use a semantic checking and analysis phase.
During this phase the compiler insures that language statements,
which are syntactically correct,
are actually meaningful within the rules of the way the language works.
In all language systems,
it is possible to have correct statements in the language that have
no meaning.
For example,
if the language requires that variables be declared before they are used,
an expression that refers to an undeclared variable has no meaning
even if that expression was correctly composed of valid language tokens.

Language compilers also typically examine the execution characteristics
of the program being compiled.
Internally, a flow graph of execution is often generated and many of
the optimizations performed by a compiler are operations that transform
a flow graph into a semantically equivalent one that minimizes
some aspect of the resulting code.
For example, it is possible to examine the flow graph of a function
that contains a loop construct and determine that some code piece
may be _lifted_ outside of the loop and still achieve the same result.

It should come as no surprise that
translating an XUML model requires analogous examination.
Fortunately,
the situation is much simpler for a model than a compiled language.
For the case of a model,
a single pass over the processing description of the activities
is sufficient to generate the introspection we need.
We call this analysis of the model processing with the goal of
characterizing the operation of the model as _marking the model_.

=== Semantic considerations

It is important to understand the purpose of the model marking.
The first step of model translation is to cast the platform
independent model into a platform dependent model.
`Micca` operates off of a platform dependent specification of
the domain properties
and supplies a specific set of mechanisms by which model semantics
may be realized as an actual implementation targeted at a
specific type of computing platform.
In the process of transforming the model into a platform specific
description,
logical aspects of the model must be made concrete in terms
supported by the platform specific model.

For example,
models specify the data types of attributes as a set of values.
In platform specific terms,
we must decide how that value set can be represented as a ``C''
data type, since our platform programming language is ``C''.
Usually the decision is easy and obvious, and
we choose a data type that can represent the platform independent
value set.

It is also the case,
that most models do not make full use of all the capablities
implied by the platform independent modeling language.
This creates situations where optimizations are available to meet
the specific use case of the model rather than necessarily providing
a general capability that would support any model.
For example,
if the model activities never access the referential attributes
of a class in a descriptive manner,
then such attributes need not be stored since the underlying
platform specifics supplied by `micca` handle implementing
the referential implications of an XUML model.

The importance of model marking is then to gather the information
about what the activities of the model actually do so as to make
informed decisions about how to map those activities onto the
platform specific mechanisms provide by `micca`.

=== Model metadata

The purpose of closely examining the processing performed by a model
is to characterize the computations the model actually performs
as opposed to the those computations that the modeling language
might support.
In this section,
we specify the model metadata that needs to be collected during the model
marking phase.

==== Class metadata

For classes, we are interested in determining if any activity in the
model does the following:

* Create an instance, either synchronously or asynchronously via a
  creation event.
* Delete an instance either synchronously or asynchronously as a result
  of entering a final state.
* Query the set of class instances based solely upon the values of identifying
  attributes.
* Query the set of class instances based upon the values of non-identifying
  attributes.

==== Attribute metadata

For class attributes,
we wish to know:

* Any attribute that is read.
* Any attribute whose value is updated.
* Any mathematically dependent attribute that is updated
  (this is an analysis error).

==== Relationship metadata

For relationships,
we are interested in the navigation of relationships by the activities
in the model. Specifically:

* Creating, deleting or updating the instances of a relationship.
    This includes subtype migration of one subtype into being instance of a
    different subtype.
* The direction of navigation of a relationship between the participating
  classes.
* Navigating generalization relationships from supertype to some subtype.
* Navigating generalization relationships from a subtype instance to
  its corresponding supertype instance.

=== Marking mechanics

The following is the suggested way to obtain and record the model metatdata
is:

* Start with a clean printout of the class diagram of the model on the
  largest size sheet of paper that can be conveniently obtained.
  Class diagrams for a cleanly presented model should be partitioned
  into smaller subsystems if the number of classes in the domain
  will not fit on readily available paper sizes.
  In practice, Letter size of A size paper is the most readily available
  and model drawings should take that into account.
* Read the action language or data flow diagrams of every processing
  activity in the model.
* While reading the model activities,
  annotate the class diagram with the information previously presented.
  For example,
  when action language statement reads an attribute, place an *R* next to the
  attribute's name.
  Similarly, attribute updates can be marked with a *U* or *W* character.
  The direction of relationship traversal can be annotated as an
  arrow pointing in the direction of the navigation and parallel to the
  relationship line on the class diagram.

The precise details of the notation used for the marking is not as important
as insuring that the previously mentioned information is gathered
and clearly indicated.
A project may choose to standarize the notation.
Do not hesitate to make notes on the diagram.
The results of this model marking analysis directly feeds the next steps in the
translation process.


// vim:syntax=asciidoc:
